{"meta":{"title":"Zhao","subtitle":"waiting","description":"技术和生活，融为一体","author":"赵鑫涛","url":"http://yoursite.com","root":"/"},"pages":[{"title":"404 Not Found","date":"2019-08-21T07:59:02.711Z","updated":"2019-08-21T06:37:13.678Z","comments":true,"path":"404.html","permalink":"http://yoursite.com/404.html","excerpt":"","text":"404 Not Found **很抱歉，您访问的页面不存在** 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2019-08-21T13:32:00.985Z","updated":"2019-08-21T11:48:49.817Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"一个努力的程序猿，在线分享自己学习以及工作的心得，希望能与大家一起交流，共同进步！"},{"title":"","date":"2019-08-21T13:35:00.103Z","updated":"2019-08-21T12:42:35.599Z","comments":true,"path":"projects/index.html","permalink":"http://yoursite.com/projects/index.html","excerpt":"","text":""},{"title":"我的朋友们","date":"2019-08-21T13:31:48.690Z","updated":"2019-08-21T13:31:48.690Z","comments":true,"path":"friends/index.html","permalink":"http://yoursite.com/friends/index.html","excerpt":"","text":""},{"title":"","date":"2019-08-21T11:36:09.246Z","updated":"2019-08-21T11:36:09.246Z","comments":true,"path":"blog/archives/index.html","permalink":"http://yoursite.com/blog/archives/index.html","excerpt":"","text":""},{"title":"","date":"2019-08-21T11:33:39.255Z","updated":"2019-08-21T11:33:39.255Z","comments":true,"path":"blog/mylist/index.html","permalink":"http://yoursite.com/blog/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2019-08-21T07:59:15.792Z","updated":"2019-08-21T06:40:20.856Z","comments":true,"path":"blog/tags/index.html","permalink":"http://yoursite.com/blog/tags/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2019-08-21T08:53:32.192Z","updated":"2019-08-21T06:39:15.328Z","comments":true,"path":"blog/categories/index.html","permalink":"http://yoursite.com/blog/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Storm高级以及优化","slug":"Storm高级","date":"2019-04-01T10:32:45.000Z","updated":"2019-08-21T11:45:50.545Z","comments":true,"path":"2019/04/01/Storm高级/","link":"","permalink":"http://yoursite.com/2019/04/01/Storm高级/","excerpt":"Storm高级Storm核心之流分组 stream grouping 分类","text":"Storm高级Storm核心之流分组 stream grouping 分类 Shuffle Grouping：随机分组。将stream中的tuple缓存后随机发放给所有bolt，可以使每个bolt中的数据量大致相等（可以较好的实现负载均衡） Fields Grouping：按字段分组，例如按groupID字段进行分组，将同一个分组的tuple分到统一任务中 All Grouping:广播发送，每一个tuple都会发送到所有任务中，所以每一个bolt都会有所有的tuple Global Grouping：全局分组，这个tuple会被分配到storm中的某一个bolt,具体一点就是分配到ID值最小的一个bolt之中 Non Grouping：随机分派，效果和shuffle一样 Direct Grouping：直接分组，将tuple发送给制定好的任务中 localOrShuffleGrouping：指如果目标Bolt 中的一个或者多个Task 和当前产生数据的Task在同一个Worker 进程里面，那么就走内部的线程间通信，将Tuple 直接发给在当前Worker进程的目的Task。否则，同shuffleGrouping。 Storm可靠性剖析Storm可能出现的问题 worker进程死掉 supervisor进程死掉 nimbus进程死掉 节点宕机 解决方案 (acker机制)ack/fail消息确认机制(确保一个tuple被完全处理) 在spout中发射tuple的时候需要同时发送messageid，这样才相当于开启了消息确认机制 如果你的topology里面的tuple比较多的话，那么把acker的数量设置多一点,效率会高一点。 通过config.setNumAckers(num)来设置一个topology里面的acker的数量，默认值是1。 注意：acker用了特殊的算法，使得对于追踪每个spout tuple的状态所需要的内存量是恒定的（20 bytes) 注意：如果一个tuple在指定的timeout(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS默认值为30秒)时间内没有被成功处理，那么这个tuple会被认为处理失败了。 Storm定时器分析 可以指定每隔一段时间将数据整合一次存入数据库 在main中设置conf.put(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 60);// 设置本Bolt定时发射数据 在bolt中使用下面代码判断是否是触发用的bolt tuple.getSourceComponent().equals(Constants.SYSTEM_COMPONENT_ID) StormUI的详解 deactive：未激活(暂停) emitted:emitted tuple数 与emitted的区别：如果一个task，emitted一个tuple到2个task中，则transferred tuple数是emitted tuple数的两倍 completelatency: spout emitting 一个tuple到spout ack这个tuple的平均时间(可以认为是tuple以及该tuple树的整个处理时间) processlatency: bolt收到一个tuple到bolt ack这个tuple的平均时间，如果没有启动acker机制，那么值为0 execute latency：bolt处理一个tuple的平均时间，不包含acker操作，单位是毫秒(也就是bolt执行 execute 方法的平均时间) capacity：这个值越接近1，说明bolt或者spout基本一直在调用execute方法，说明并行度不够，需要扩展这个组件的executor数量。(调整组件并行度的依据) 总结：execute latency和proces latnecy是处理消息的时效性，而capacity则表示处理能力是否已经饱和，从这3个参数可以知道topology的瓶颈所在。 Storm的优化并行度的优化 worker为storm提供工作进程，程序的并行度可以设置（包括spout和bolt的并行度，如果有acker的话还包括acker的并行度），并行度即为executor的数目。 一般情况下worker与executor的比例是一比十到十五，也可以根据实际需要修改。 worker的优化 CPU 16核，建议配置20个worker。CPU 24或32核，30个worker 默认情况下，Storm启动worker进程时，JVM的最大内存是768M，可以通过在Strom的配置文件storm.yaml中设置worker的启动参数worker.childopts: “-Xmx2048m” 一个topology使用的worker数量，12个是比较合理的，这个时候吞吐量和整体性能最优。如果多增加worker进程的话，会将一些原本线程间的内存通信变为进程间的网络通信。 acker优化 如果可靠性对你来说不是那么重要，那么你可以通过不跟踪这些tuple树来获取更好的性能。不去跟踪消息的话会使得系统里面的消息数量减少一半，因为对于每一个tuple都要发送一个ack消息。 三种去掉可靠性的方法 第一是把config.setNumAckers(0)设置为0，在这种情况下，storm会在spout发射一个tuple之后马上调用spout的ack方法。也就是说这个tuple树不会被跟踪。 第二个方法是在tuple层面去掉可靠性。你可以在发射tuple的时候不指定messageid来达到不跟踪spout中tuple的目的。 最后一个方法是如果你对于一个tuple树里面的某一部分到底成不成功不是很关心，那么可以在发射这些tuple的时候unanchor它们(anchor是锚定的意思，unanchor表示不把当前这个tuple包含到tuple树中，也就是说不跟踪这个消息了)。这样这些tuple就不在tuple树里面， 也就不会被跟踪了。 雪崩问题的出现原因以及解决方法 原因：spout发送的速度大于bolt接收的速度，导致数据堆积，不断消耗内存，最终系统崩溃，并引起数据链上多节点down掉。 解决方案 增加bolt的并行度 增加它接收的速度 可以通过topology.max.spout.pending来控制spout发送消息的速度，通过代码这样设置config.setMaxSpoutPending(num); 注意：这个参数表示，当下游的bolt还有topology.max.spout.pending个 tuple 没有消费完时，spout会停止调用nexttuple方法发射数据。等待下游bolt去消费，当tuple的个数少于topology.max.spout.pending个数时，spout 会继续发射数据(这个属性只对可靠消息处理有用，也就是说需要启用acker消息确认机制，在spout中emit数据的时候需要带有messageid)","categories":[],"tags":[{"name":"storm storm优化","slug":"storm-storm优化","permalink":"http://yoursite.com/tags/storm-storm优化/"}]},{"title":"Strome 基础","slug":"Storm的详细分析","date":"2019-03-21T05:46:56.000Z","updated":"2019-08-21T11:45:52.807Z","comments":true,"path":"2019/03/21/Storm的详细分析/","link":"","permalink":"http://yoursite.com/2019/03/21/Storm的详细分析/","excerpt":"Storm的详细分析Storm人的概述 Storm是Twitter开源的一个实时处理框架 Storm能够实现高频数据和大规模数据的实时处理","text":"Storm的详细分析Storm人的概述 Storm是Twitter开源的一个实时处理框架 Storm能够实现高频数据和大规模数据的实时处理 Storm与MapReduce的区别Storm type MapReduce Storm 数据来源 hdfs上TB级别历史数据 实时新增的某一条数据 处理过程 map阶段和reduce阶段 可以有很多阶段包含spout以及bolt 是否会结束 执行完结束 不会结束 处理速度 主要以执行TB级别数据速度较慢 只处理新增数据速度很快 适用场景 处理批数据不讲时效性 处理新增数据将时效性 Spark Streaming与Storm的区别 type Spark Streaming Storm 计算模型 是近实时处理框架 全实时处理框架 延迟度 最高支持秒级别的延迟 可以支持毫秒级别的延迟 吞吐量 因为是批处理所以吞吐量高 吞吐量相对来说较低 动态调整并行度 不支持 支持 事务机制 支持但是不够完善 支持且完善 Storm各个组件解释 Topology：用于封装一个实时计算应用程序的逻辑 Stream：消息流，是一个没有边界的tuple序列，这些tuple会以分布式的方式进行创建以及处理 Spout：消息源，消息的生产者，会从外部源获取消息然后向Topology发出：tuple Bolt：消息处理者，消息的处理逻辑被封装到bolt之中，处理输入的数据然后产生新的输出数据流 Storm的设计思想 是对stream流的一个抽象即一个不间断的连续tuple 将流中的元素抽象为一个tuple，一个tuple就是一个值列表value list，list中的每个value都有一个name，并且这个value可以是很多数据类型例如基本类型、字符类型等 每一个stream流都有一个数据源，称为Spout stream从spout中获取不间断数据tuple需要经过处理。处理的过程就是stream流转换的过程称为bolt，bolt可以消费任意数量的流，它是将stream汇总的tuple挨个实时进行处理转换成一个新的stream流经过多个bolt处理就可以得到目标数据 spout+tuple+bolt这个过程可以称为是Topology拓扑。Topology是Storm中最高的一个抽象概念他可以被提交到集群中执行 Topology的每个节点都要指定他所发射数据的name，其他节点只需要订阅该name就可以接收数据进行处理 Topology的整个流程 如果将stream比作是一列火车的话 spout就是这列火车的始发站每一节车厢就是一个tuple乘客就是tuple中的values 中间的站点就相当于是bolt进行处理上下乘客终点站就相当于stream的目标数据 Storm的整体架构图 Storm的简单实例开发 需求：一个源源不断的数据1，2，3，4……求每出现一个数字就要计算出现的所有数字的和 开发过程 在IDE中创建maven工程 在pom中添加、Storm依赖 123456&lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-core&lt;/artifactId&gt; &lt;version&gt;1.0.6&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package Storme;import java.util.Map;import org.apache.storm.Config;import org.apache.storm.LocalCluster;import org.apache.storm.generated.StormTopology;import org.apache.storm.spout.SpoutOutputCollector;import org.apache.storm.task.OutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.topology.TopologyBuilder;import org.apache.storm.topology.base.BaseRichBolt;import org.apache.storm.topology.base.BaseRichSpout;import org.apache.storm.tuple.Fields;import org.apache.storm.tuple.Tuple;import org.apache.storm.tuple.Values;import org.apache.storm.utils.Utils;/** * 需求：实现数字累加求和 * 分析： * 需要有一个spout负责源源不断的产生从1开始的递增数字 * 还需要有一个bolt负责对spout产生的数据进行累加求和，并且把结果打印到控制台 * 最后把这个spout和bolt组装成一个topology * */public class WordCount &#123; /** * 实现自己的数据源spout， * 该spout负责源源不断产生从1开始的递增数字 * */ public static class MySpout extends BaseRichSpout&#123; private Map conf;//这里面存储配置信息 private TopologyContext context;//代表上下文 private SpoutOutputCollector collector;//收集器，主要负责向外面发射数据 /** * 是一个初始化的方法，这个方法在本实例运行的之后，首先被调用，仅且仅被调用一次 * 所以这个方法内一般放一些初始化的代码 * 例子：针对操作mysql数据的案例，使用jdbc获取数据库连接的代码需要放到这里面实现 */ public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) &#123; this.conf = conf; this.context = context; this.collector = collector; //System.err.println(&quot;spout------&quot;+conf.get(&quot;name&quot;)); &#125; /** * 这个方法会被循环调用 */ int i = 1; public void nextTuple() &#123; // 注意：针对需要发射的数据，需要封装成tuple，可以使用storm中的values对象快速封装tuple System.out.println(&quot;spout:&quot;+i); this.collector.emit(new Values(i++)); // 让线程每发射一条数据，休息1秒 Utils.sleep(1000); &#125; /** * 声明输出字段 * 定义两个组件之间数据传输的一个规则 * 注意：只要这个组件(spout/spout)向外发射了数据，那么这个declareOutputFields就需要实现 */ public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; // 注意：Fields中的字段列表和Values中的数据列表是一一对应的 declarer.declare(new Fields(&quot;num&quot;)); &#125; &#125; /** * 聚合的Bolt，负责把Spout发射出来的数据进行累加求和，并且打印到控制台 * */ public static class SumBolt extends BaseRichBolt&#123; private Map stormConf; private TopologyContext context; private OutputCollector collector; /** * prepare是一个初始化方法，只会执行一次，这里面也是可以放一些初始化的代码 */ public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123; this.stormConf = stormConf; this.context = context; this.collector = collector; //System.err.println(&quot;bolt------&quot;+stormConf.get(&quot;name&quot;)); &#125; int sum = 0; /** * 这个方法也是会被循环调用 * 主要上一个组件向外发射了数据，那么这个方法就会被调用一次 */ public void execute(Tuple input) &#123; //input.getInteger(0);// 通过角标获取数据 Integer num = input.getIntegerByField(&quot;num&quot;); sum += num; System.out.println(&quot;和为：&quot;+sum); &#125; /** * 注意：这个方法在这里就不需要实现了，因为这个bolt没有向下一个组件发射数据 */ public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; &#125; &#125; public static void main(String[] args) &#123; TopologyBuilder builder = new TopologyBuilder(); // 组装spout builder.setSpout(&quot;spoutid&quot;, new MySpout()); // 组装bolt,并且告诉bolt接收哪个组件的数据 builder.setBolt(&quot;bolt-1&quot;, new SumBolt()).shuffleGrouping(&quot;spoutid&quot;); StormTopology createTopology = builder.createTopology(); // 通过代码创建一个本地集群 LocalCluster localCluster = new LocalCluster(); String topologyName = WordCount.class.getSimpleName(); Config config = new Config(); config.put(&quot;name&quot;, &quot;zs&quot;); // 把代码提交到本地集群中运行 localCluster.submitTopology(topologyName, config, createTopology); &#125;&#125; Storm核心之并行度组件解释 worker：worker是一个进程，每一个worker进程里面都执行的是一个Topology的任务（不会出现一个worker执行多个Topology的任务）。一个worker中会启动一个或多个executor线程来执行Topology的spout或者bolt组件。一个Topology会使用一个或者多个worker来执行任务 executor：是worker进程内部启动的独立线程，每一个executor会产生一个或者多个task（storm默认是一个task即一个spout或者bolt有一个task，如果有多个task，executor会循环调用所有task中的实例） task：是最终运行spout或者bolt中具体代码的执行单元。Topology启动（spout或者bolt）的task的数目是不变的，但是executor线程的数量可以动态进行调整（例如：1个executor线程可以执行该(spout或bolt)的1个或多个task实例）。这意味着，对于1个(spout或bolt)存在这样的条件：#threads&lt;=#tasks（即：线程数小于等于task数目）。默认情况下task的数目等于executor线程数目，即1个executor线程只运行1个task。 默认情况下，一个supervisor节点最多可以启动4个worker进程，每一个topology默认占用一个worker进程，每个spout或者bolt会占用1个executor，每个executor启动1个task。 提高Storm组件的并行度 worker（slot）【间接】 默认一个节点最多可以启动四个worker进程，可以修改进程数量strom-core.jar/defaults.yaml/supervisor.slots.ports 默认一个Topology只有一个worker进程，可以通过代码指定一个Topology使用多个worker进程config.setNumWorkers(workersnum) 注意：如果worker使用完在提交Topology就不会执行，会处于等待状态。worker之是通过Netty通信的 executor【直接】 默认情况下一个executor只会运行一个task，可以直接通过代码修改增加task数量，会直接提高Storm组件的并行度 builder.setSpout(id, spout,parallelism_hint); builder.setBolt(id, bolt,parallelism_hint); task【间接】 通过boltDeclarer.setNumTasks(num);来设置实例的个数 executor的数量会小于等于task的数量(为了rebalance) 弹性计算rebalance 前提是Topology中的task数量要大于executor线程数 通过shell调整 storm rebalance mytopology -w 10 -n 5 -e blue-spout=3 -e yellow-bolt=10 注意：acker的树木运行时是不会变化的，所以多指定几个worker进程，acker的数量也不会增加 -w：表示超时时间，Rebalance会在一个超时时间内注销掉Topology，然后在集群中重新分配worker -n：表示的是worker的数量 -e：调整组件的并行度 注：-n 以及 -e 都可以单独使用或者组合起来使用 通过UI界面进行调整，不建议使用所以就不具体解释使用方法了 并行度设置多少合适 单spout每秒大概可以发送500个tuple 单bolt每秒大概可以接收2000个tuple 单acker每秒大概可以接收6000个tuple 根据需要进行调整","categories":[],"tags":[{"name":"storm","slug":"storm","permalink":"http://yoursite.com/tags/storm/"}]},{"title":"Maven 简介","slug":"maven的简介","date":"2019-01-20T16:00:00.000Z","updated":"2019-08-21T11:43:29.612Z","comments":true,"path":"2019/01/21/maven的简介/","link":"","permalink":"http://yoursite.com/2019/01/21/maven的简介/","excerpt":"Maven 简介为什么需要maven 同样的代码要在不同的机器上运行他所需要的依赖可以放在maven仓库 项目组加入新成员可以快速的配置好环境 在开发其他项目的时候需要用到跟之前项目开发一样的jar包","text":"Maven 简介为什么需要maven 同样的代码要在不同的机器上运行他所需要的依赖可以放在maven仓库 项目组加入新成员可以快速的配置好环境 在开发其他项目的时候需要用到跟之前项目开发一样的jar包 maven是什么 maven是基于项目对象模型POM的软件项目管理工具 是可以跨平台的，主要服务基于Java平台的仙姑构建、依赖管理、项目信息管理等 构建的过程 清理 编译 测试 报告 打包 部署 maven的工程结构 src mian java – 存放Java的文件 源代码等 resource –存放资源文件 比如 spring，hibernate等的配置文件 test Java – 存放所有的.Java的测试文件，比如JUnit 测试类 resource –测试的资源文件夹 target —目标文件的输出位置比如jar包、war包等 pom.xml —maven的项目核心配置文件 maven常用命令 mvn compile 执行编译 会将生成文件存放在target目录中 mvn clean 删除target中的目录文件 mvn test 执行测试命令 执行后会在target目录中生成三个目录文件surefire、surefire-reports（测试报告）、test-classes（测试的字节码文件） mvn package 进行打包操作 操作后的文件存放在target目录之中 例如jar包war包 mvn install 将制定的jar包安装到本地仓库以便于其他工程的引用 mvn clean compile 清除测试类再执行compile执行编译操作 mvn clean test 先清除在进行test测试操作 mvn clean package 先执行clean清除在执行package打包 mvn clean install 先进行clean在执行install","categories":[{"name":"基础","slug":"基础","permalink":"http://yoursite.com/categories/基础/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"}]}]}