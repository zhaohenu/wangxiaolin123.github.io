<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Flink入门简介</title>
      <link href="/2019/09/11/Flink%E5%85%A5%E9%97%A8%E7%AE%80%E4%BB%8B/"/>
      <url>/2019/09/11/Flink%E5%85%A5%E9%97%A8%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567231332652.png" alt="1111222"></p><h2 id="Flink入门简介"><a href="#Flink入门简介" class="headerlink" title="Flink入门简介"></a>Flink入门简介</h2><h3 id="Flink的基本原理以及应用场景"><a href="#Flink的基本原理以及应用场景" class="headerlink" title="Flink的基本原理以及应用场景"></a>Flink的基本原理以及应用场景</h3><a id="more"></a><h4 id="Flink的简介"><a href="#Flink的简介" class="headerlink" title="Flink的简介"></a>Flink的简介</h4><ul><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567231578843.png" alt="111"></p></li><li><p>Flink是一个开源的分布式、高性能、高可用、准确的流处理框架。</p></li><li><p>支持实时流处理以及实时批处理，批处理其实就是流处理的一个特例</p></li><li><p>原生支持迭代计算、内存管理、程序优化等</p></li><li><p>Flink的架构图：</p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567231630042.png" alt="1567231630042"></p></li><li><p>Flink的基本组件：</p><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567231706001.png" alt="1567231706001"></li></ul></li></ul><h4 id="Flink的流处理与批处理"><a href="#Flink的流处理与批处理" class="headerlink" title="Flink的流处理与批处理"></a>Flink的流处理与批处理</h4><ul><li>在大数据领域中，批处理任务以及流处理任务一般被认为是两种不同的任务，一个大数据的框架只能处理其中的一种任务<ul><li>例如：Storm只支持流处理，spark、MapReduce只支持批处理，spark Streaming也是采用了一种micro-batch的架构，即把输入的数据流切分成细粒度的batch，并且为每一个batch提交一个批处理的spark任务，所以spark Streaming的流处理与storm的完全不同。</li></ul></li><li>Flink通过灵活的执行引擎，能够同时支持批处理任务以及流处理任务。<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567249802096.png" alt="1567249802096"></li><li>在执行引擎这一层，批处理与流处理的最大的区别在于节点之间数据的传输方式。</li><li>流处理系统，其节点间数据传输的标准模型是：当一条数据被处理完成后，序列化到缓存中，然后立刻通过网络传输到下一个节点，由下一个节点继续处理</li><li>批处理系统，其节点间数据传输的标准模型是：当一条数据被处理完成后，序列化到缓存中，并不会立刻通过网络传输到下一个节点，当缓存写满，就持久化到本地硬盘上，当所有数据都被处理完成后，才开始将处理后的数据通过网络传输到下一个节点</li><li>这两种数据传输模式是两个极端，对应的是流处理系统对低延迟的要求和批处理系统对高吞吐量的要求</li><li>Flink以固定的缓存块为单位进行网络数据传输，用户可以通过设置缓存块超时值指定缓存块的传输时机。如果缓存块的超时值为0，则Flink的数据传输方式类似上文所提到流处理系统的标准模型，此时系统可以获得最低的处理延迟</li><li>如果缓存块的超时值为无限大，则Flink的数据传输方式类似上文所提到批处理系统的标准模型，此时系统可以获得最高的吞吐量</li><li>同时缓存块的超时值也可以设置为0到无限大之间的任意值。缓存块的超时阈值越小，则Flink流处理执行引擎的数据处理延迟越低，但吞吐量也会降低，反之亦然。通过调整缓存块的超时阈值，用户可根据需求灵活地权衡系统延迟和吞吐量</li></ul></li></ul><h4 id="Flink的应用场景"><a href="#Flink的应用场景" class="headerlink" title="Flink的应用场景"></a>Flink的应用场景</h4><ul><li>优化电商网站的实时搜索结果<ul><li>阿里巴巴的所有基础设施团队使用flink实时更新产品细节和库存信息(Blink)</li></ul></li><li>针对数据分析团队提供实时流数据处理服务<ul><li>通过flink数据分析平台提供实时数据分析服务，及时发现问题</li></ul></li><li>网络/传感器检测和错误检测<ul><li>Bouygues电信公司，是法国最大的电信供应商之一，使用flink监控其有线和无线网络，实现快速故障响应</li></ul></li><li>商业智能分析ETL<ul><li>Zalando使用flink转换数据以便于加载到数据仓库，将复杂的转换操作转化为相对简单的并确保分析终端用户可以更快的访问数据(实时ETL)</li></ul></li></ul><h3 id="Flink与其他框架的对比"><a href="#Flink与其他框架的对比" class="headerlink" title="Flink与其他框架的对比"></a>Flink与其他框架的对比</h3><ul><li>Flink与Storm以及Spark Streaming的对比：</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567250139695.png" alt="1567250139695"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567250383255.png" alt="1567250383255"></li><li>实时处理框架的选择<ul><li>需要关注流数据是否需要进行状态管理</li><li>At-least-once或者Exectly-once消息投递模式是否有特殊要求</li><li>对于小型独立的项目，并且需要低延迟的场景，建议使用storm</li><li>如果你的项目已经使用了spark，并且秒级别的实时处理可以满足需求的话，建议使用sparkStreaming</li><li>要求消息投递语义为<br>Exactly Once 的场景；数据量较大，要求高吞吐低延迟的场景；需要进行状态管理或窗口统计的场景，建议使用flink</li></ul></li></ul><h3 id="Flink的入门案例"><a href="#Flink的入门案例" class="headerlink" title="Flink的入门案例"></a>Flink的入门案例</h3><ul><li><p>需求：手工通过socket实时产生一些单词，使用flink实时接收数据，对指定时间窗口内(例如：2秒)的数据进行聚合统计，并且把时间窗口内计算的结果打印出来</p></li><li><p>代码实现：可以使用Java或者Scala 这里推荐使用Scala并使用Scala演示</p><ul><li><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">添加<span class="type">Scala</span>连<span class="type">Flink</span>的核心依赖包</span><br><span class="line">&lt;dependency&gt;  </span><br><span class="line">  &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;  </span><br><span class="line">  &lt;artifactId&gt;flink-scala_2<span class="number">.11</span>&lt;/artifactId&gt;  </span><br><span class="line">  &lt;version&gt;<span class="number">1.6</span><span class="number">.1</span>&lt;/version&gt;  </span><br><span class="line">&lt;/dependency&gt;  </span><br><span class="line">&lt;dependency&gt;  </span><br><span class="line">  &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;  </span><br><span class="line">  &lt;artifactId&gt;flink-streaming-scala_2<span class="number">.11</span>&lt;/artifactId&gt;  </span><br><span class="line">  &lt;version&gt;<span class="number">1.6</span><span class="number">.1</span>&lt;/version&gt;  </span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li><li><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> <span class="type">FlinkTest</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 实时计算</span></span><br><span class="line"><span class="comment">  * 手工通过socket实时产生一些单词，使用flink实时接收数据，</span></span><br><span class="line"><span class="comment">  * 对指定时间窗口内(例如：2秒)的数据进行聚合统计，并且把时间窗口内计算的结果打印出来</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//获取执行环境</span></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    <span class="comment">//指定source 获取数据源</span></span><br><span class="line">    <span class="keyword">val</span> text = env.socketTextStream(<span class="string">"hadoop110"</span>,<span class="number">9999</span>,'\n')</span><br><span class="line">    <span class="comment">//使用flatmap的时候需要使用隐式转换 添加隐式转换</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line">    <span class="comment">//对数据切分</span></span><br><span class="line">    <span class="keyword">val</span> words = text.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">    <span class="comment">//转换单词格式</span></span><br><span class="line">    <span class="keyword">val</span> wordsCount = words.map((_,<span class="number">1</span>))</span><br><span class="line">    <span class="comment">//吧相同的key放在一起</span></span><br><span class="line">    <span class="keyword">val</span> keys = wordsCount.keyBy(<span class="number">0</span>)</span><br><span class="line">    <span class="comment">//指定一个基于时间的滑动窗口  每隔一秒计算前两秒的数据</span></span><br><span class="line">    <span class="keyword">val</span> windowData = keys.timeWindow(<span class="type">Time</span>.seconds(<span class="number">2</span>),<span class="type">Time</span>.seconds(<span class="number">1</span>))</span><br><span class="line">    <span class="comment">//根据tuple中的数据求和</span></span><br><span class="line">    <span class="keyword">val</span> res = windowData.sum(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">//打印结果  设置并行度为1</span></span><br><span class="line">    res.print().setParallelism(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">//执行代码</span></span><br><span class="line">    env.execute(<span class="string">"WordCount"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> <span class="type">FlinkTest</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala.<span class="type">ExecutionEnvironment</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">BatchWordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> data = env.readTextFile(<span class="string">"D:\\data\\words.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> res = data.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">      .map((_,<span class="number">1</span>))</span><br><span class="line">      .groupBy(<span class="number">0</span>)</span><br><span class="line">      .sum(<span class="number">1</span>)</span><br><span class="line">    res.print()</span><br><span class="line">    res.writeAsCsv(<span class="string">"D:\\data\\words.csv"</span>,<span class="string">"\n"</span>,<span class="string">" "</span>)</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"BatchWordCount"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="Flink的集群介绍"><a href="#Flink的集群介绍" class="headerlink" title="Flink的集群介绍"></a>Flink的集群介绍</h3><h4 id="简单本地集群安装部署"><a href="#简单本地集群安装部署" class="headerlink" title="简单本地集群安装部署"></a>简单本地集群安装部署</h4><ul><li>依赖环境：Linux，jdk1.8以上</li><li>下载地址：<a href="https://archive.apache.org/dist/flink" target="_blank" rel="noopener">https://archive.apache.org/dist/flink</a>  选择合适的版本</li><li>local模式快速安装启动<ul><li>解压</li><li>进入</li><li>启动 ./bin/start-cluster.sh  </li><li>进入web界面查看 8081</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567254037326.png" alt="1567254037326"></li><li>可以将任务提交到进群之中尝试运行</li></ul></li></ul><h4 id="集群搭建中的重点"><a href="#集群搭建中的重点" class="headerlink" title="集群搭建中的重点"></a>集群搭建中的重点</h4><ul><li>Flink-Standalone集群<ul><li>各个参数详解<ul><li>jobmanager.heap.mb：jobmanager节点可用的内存大小</li><li>taskmanager.heap.mb：taskmanager节点可用的内存大小</li><li>taskmanager.numberOfTaskSlots：每台机器可用的cpu数量</li><li>parallelism.default：默认情况下任务的并行度</li><li>taskmanager.tmp.dirs：taskmanager的临时数据存储目录</li><li>slot和parallelism总结<ul><li>slot是静态的概念，是指taskmanager具有的并发执行能力</li><li>parallelism是动态的概念，是指程序运行时实际使用的并发能力</li><li>设置合适的parallelism能提高运算效率，太多了和太少了都不行</li></ul></li></ul></li><li>容错<ul><li>jobmanager挂掉<ul><li>正在执行的任务会失败</li><li>存在单点故障 但是Flink支持HA</li></ul></li><li>taskmanager挂掉<ul><li>如果有多余的taskmanager节点，flink会自动把任务调度到其它节点执行</li></ul></li></ul></li></ul></li><li>Flink on Yarn<ul><li>使用on yarn 的好处<ul><li>提高集群的利用率</li><li>一套集群，可以执行mr任务，spark任务，Flink任务</li></ul></li><li>内部实现结构<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567257268454.png" alt="1567257268454"></li></ul></li><li>Flink on Yarn有两种方式</li><li>第一种运行方式<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567257321529.png" alt="1567257321529"></li><li>yarn-session.sh(开辟资源)+flink run(提交任务)</li><li>启动一个一直运行的flink集群</li><li>bin/yarn-session.sh -n 2 -jm 1024 -tm 1024 </li><li>附着到一个已存在的flink yarn session</li><li>bin/yarn-session.sh -id application_1463870264508_0029</li><li>执行任务</li><li>bin/flink run ./examples/batch/WordCount.jar </li></ul></li><li>第二种运行方式<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567257496396.png" alt="1567257496396"></li><li>flink run -m yarn-cluster(开辟资源+提交任务)</li><li>启动集群，执行任务</li><li>bin/flink run -m yarn-cluster -yn 2 -yjm 1024 -ytm 1024 ./examples/batch/WordCount.jar</li><li>注意：client端必须要设置YARN_CONF_DIR或者HADOOP_CONF_DIR或者HADOOP_HOME环境变量，通过这个环境变量来读取YARN和HDFS的配置信息，否则启动会失败</li></ul></li><li>参数解释<ul><li>-n,–container<arg>   分配多少个yarn容器(=taskmanager的数量)    必选</arg></li><li>-D<arg>                        动态属性  </arg></li><li>-d,–detached                   独立运行  </li><li>-jm,–jobManagerMemory <arg>      JobManager的内存 [in MB]  </arg></li><li>-nm,–name                     在YARN上为一个自定义的应用设置一个名字  </li><li>-q,–query                      显示yarn中可用的资源 (内存,cpu核数)  </li><li>-qu,–queue<arg>               指定YARN队列</arg></li><li>-s,–slots <arg>               每个TaskManager使用的slots数量  </arg></li><li>-tm,–taskManagerMemory<arg>   每个TaskManager的内存 [in MB]  </arg></li><li>-z,–zookeeperNamespace<arg>   针对HA模式在zookeeper上创建NameSpace </arg></li><li>id,–applicationId<yarnappid>        YARN集群上的任务id，附着到一个后台运行的yarn session中</yarnappid></li></ul></li><li>bin/flink run 命令分析<ul><li>run [OPTIONS] <jar-file>  <arguments>  <ul><li>“run”操作参数:  <ul><li>-c,–class<classname> 如果没有在jar包中指定入口类，则需要在这里通过这个参数指定  需要放在jar包前面</classname></li><li>-m,–jobmanager  <a href="host:port" target="_blank" rel="noopener">host:port</a>  指定需要连接的jobmanager(主节点)地址，使用这个参数可以指定一个不同于配置文件中的jobmanager  </li><li>-p,–parallelism<parallelism>  指定程序的并行度。可以覆盖配置文件中的默认值</parallelism></li></ul></li></ul></arguments></jar-file></li><li>默认查找当前yarn集群中已有的yarn-session信息中的jobmanager<ul><li>bin/flink run ./examples/batch/WordCount.jar</li></ul></li><li>连接指定host和port的jobmanager<ul><li>bin/flink run -m hadoop100:1234 ./examples/batch/WordCount.jar </li></ul></li><li>启动一个新的yarn-session<ul><li>bin/flink run -m yarn-cluster -yn 2 ./examples/batch/WordCount.jar</li><li>yarn session命令行的选项也可以使用./bin/flink 工具获得。它们都有一个y或者yarn的前缀</li></ul></li></ul></li></ul></li></ul><h3 id="Flink的HA高可用"><a href="#Flink的HA高可用" class="headerlink" title="Flink的HA高可用"></a>Flink的HA高可用</h3><ul><li>jobManage协调每一个Flink任务的部署，他负责调度和资源管理。</li><li>默认情况下，一个Flink集群中只有一个jobmanege,这样就很容易出现单点故障而导致不能提交新的任务并且现在执行的任务也会失败</li><li>使用jobManage HA 集群可以快速从jobManage故障中恢复，避免单点故障spof,可以再standalone或者yarn集群模式下配置集群的高可用机制</li><li>Standolone高可用详解<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567259000316.png" alt="1567259000316"></li><li>Standalone模式（独立模式）下JobManager的高可用性的基本思想是，任何时候都有一个<br>Master JobManager ，并且多个Standby JobManagers 。 Standby JobManagers可以在Master JobManager 挂掉的情况下接管集群成为Master JobManager。 这样保证了没有单点故障，一旦某一个Standby JobManager接管集群，程序就可以继续运行。 Standby JobManager和Master JobManager实例之间没有明确区别。每个JobManager都可以成为Master或Standby节点</li></ul></li><li>Yarn高可用详解<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567259103814.png" alt="1567259103814"></li><li>主要是利用yarn自己的job恢复机制</li></ul></li></ul><h3 id="Flink-的-Scala-shell代码调试"><a href="#Flink-的-Scala-shell代码调试" class="headerlink" title="Flink 的 Scala shell代码调试"></a>Flink 的 Scala shell代码调试</h3><ul><li>因为每次打jar包进行测试有些麻烦，并且不好定位问题，所以可以再Scala shell中进行调试</li><li>scala shell方式支持流处理和批处理。当启动shell命令行之后，两个不同的ExecutionEnvironments会被自动创建。使用senv(Stream)和benv(Batch)分别去处理流处理和批处理程序。(类似于spark-shell中sc变量)</li><li>启动指令bin/start-scala-shell.sh</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567259304840.png" alt="1567259304840"></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink详细介绍</title>
      <link href="/2019/09/02/Flink%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019/09/02/Flink%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567329814966.png" alt="1567329814966"></p><h2 id="Flink详细介绍"><a href="#Flink详细介绍" class="headerlink" title="Flink详细介绍"></a>Flink详细介绍</h2><h3 id="Flink-API的抽象级别"><a href="#Flink-API的抽象级别" class="headerlink" title="Flink API的抽象级别"></a>Flink API的抽象级别</h3><a id="more"></a><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567329798038.png" alt="1567329798038"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567329931681.png" alt="1567329931681"></li></ul><h3 id="Flink-DataStreamAPI"><a href="#Flink-DataStreamAPI" class="headerlink" title="Flink DataStreamAPI"></a>Flink DataStreamAPI</h3><h4 id="DataSource"><a href="#DataSource" class="headerlink" title="DataSource"></a>DataSource</h4><ul><li><p>source是程序的数据源输入，可以通过StreamExecutionEnvironment.addSource(sourceFunction来给程序添加一个source</p></li><li><p>Flink提供了大量已经实现好的source方法，我们也可以自定义source</p><ul><li>通过实现sourceFunction接口来自定义无并行度的source</li><li>或者你也可以通过实现ParallelSourceFunction 接口<br>or 继承RichParallelSourceFunction 来自定义有并行度的source。</li></ul></li><li><p>source的类型</p><ul><li>基于socket<ul><li>socketTextStream<br>从socket中读取数据，元素可以通过一个分隔符切开。</li></ul></li><li>基于集合<ul><li>fromCollection(Collection)</li><li>通过java的collection集合创建一个数据流，集合中的所有元素必须是相同类型的。</li></ul></li><li>自定义输入<ul><li>addSource 可以实现读取第三方数据源的数据</li><li>系统内置提供了一批connectors，连接器会提供对应的source支持</li></ul></li></ul></li><li><p>内置connectors 连接器</p><ul><li>Apache Kafka (source/sink)</li><li>RabbitMQ (source/sink)</li><li>Apache ActiveMQ (source/sink)</li></ul></li><li><p>source的容错性保证</p><ul><li><table><thead><tr><th><strong>Source</strong></th><th><strong>语义保证</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>kafka</td><td>exactly once(仅一次)</td><td>建议使用0.10及以上</td></tr><tr><td>Collections</td><td>exactly once</td><td></td></tr><tr><td>Files</td><td>exactly once</td><td></td></tr><tr><td>Sockets</td><td>at most once</td><td></td></tr></tbody></table></li></ul></li></ul><h4 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h4><ul><li>map：输入一个元素，然后返回一个元素，中间可以做一些清洗转换等操作</li><li>flatmap：输入一个元素，可以返回零个，一个或者多个元素</li><li>filter：过滤函数，对传入的数据进行判断，符合条件的数据会被留下</li><li>keyby：根据指定的key进行分组，相同key的数据会进入同一个分区</li><li>reduce：对数据进行聚合操作，结合当前元素和上一次reduce返回的值进行聚合操作，然后返回一个新的值</li><li>aggregations：sum(),min(),max()等</li><li>window：后面会详细描述</li><li>union：合并多个流，新的流会包含所有流中的数据  注意：所有合并的流类型必须是一致的</li><li>connect：和union类似，但是只能连接两个流，两个流的数据类型可以不同，会对两个流中的数据应用不同的处理方法。<ul><li>CoMap,  CoFlatMap：在ConnectedStreams中需要使用这种函数，类似于map和flatmap</li></ul></li></ul><h4 id="sink"><a href="#sink" class="headerlink" title="sink"></a>sink</h4><ul><li><p>输出的类型</p><ul><li>writeAsText（）：将元素以字符串形式逐行写入，这些字符串通过调用每个元素的toString()方法来获取</li><li>print（）/printToErr（）：打印每个元素的toString()方法的值到标准输出或者标准错误输出流中</li><li>自定义输出addSink  例如：kafka Redis等</li></ul></li><li><p>内置connectors连接器</p><ul><li>Apache Kafka (source/sink)</li><li>Apache Cassandra (sink)</li><li>Elasticsearch (sink)</li><li>Hadoop FileSystem (sink)</li><li>RabbitMQ (source/sink)</li><li>Apache ActiveMQ (source/sink)</li><li>Redis (sink)</li></ul></li><li><p>sink的容错性保证</p><ul><li><table><thead><tr><th><strong>Sink</strong></th><th><strong>语义保证</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>hdfs</td><td>exactly once</td><td></td></tr><tr><td>elasticsearch</td><td>at least once</td><td></td></tr><tr><td>kafka produce</td><td>at least once/exactly once</td><td>Kafka 0.9 and 0.10提供at   least once   Kafka 0.11提供exactly once</td></tr><tr><td>file</td><td>at least once</td><td></td></tr><tr><td>redis</td><td>at least once</td><td></td></tr></tbody></table></li></ul></li><li><p>自定义sink</p><ul><li>实现自定义sink<ul><li>实现SinkFunction接口</li><li>继承RichSinkFunction</li></ul></li></ul></li></ul><h3 id="Flink-DataSetAPI"><a href="#Flink-DataSetAPI" class="headerlink" title="Flink DataSetAPI"></a>Flink DataSetAPI</h3><h4 id="DataSource-1"><a href="#DataSource-1" class="headerlink" title="DataSource"></a>DataSource</h4><ul><li>基于文件<ul><li>readTextFile(path)</li></ul></li><li>基于集合<ul><li>fromCollection(Collection)</li></ul></li></ul><h4 id="Transformations"><a href="#Transformations" class="headerlink" title="Transformations"></a>Transformations</h4><ul><li>map：输入一个元素，然后返回一个元素，中间可以做一些清洗转换等操作</li><li>flatmap：输入一个元素，可以返回零个，一个或者多个元素</li><li>mappartition：类似map，一次处理一个分区的数据【如果在进行map处理的时候需要获取第三方资源链接，建议使用MapPartition】</li><li>filter：过滤函数，对传入的数据进行判断，符合条件的数据会被留下</li><li>reduce：对数据进行聚合操作，结合当前元素和上一次reduce返回的值进行聚合操作，然后返回一个新的值</li><li>Aggregate：sum、max、min等</li><li>distinct：返回一个数据集中去重之后的元素，data.distinct()</li><li>cross：获取两个数据集的笛卡尔积</li><li>union：返回两个数据集的总和，数据类型需要一致</li><li>first-n: 获取集合中的前N个元素</li><li>Sort Partition：在本地对数据集的所有分区进行排序，通过sortPartition()的链接调用来完成对多个字段的排序</li></ul><h4 id="sink-1"><a href="#sink-1" class="headerlink" title="sink"></a>sink</h4><ul><li>writeAsText():将元素以字符串形式逐行写入，这些字符串通过调用每个元素的toString()方法来获取</li><li>writeAsCsv():将元组以逗号分隔写入文件中，行及字段之间的分隔是可配置的。每个字段的值来自对象的toString()方法</li><li>print():打印每个元素的toString()方法的值到标准输出或者标准错误输出流中</li></ul><h3 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h3><ul><li>Flink针对流处理和批处理提供了相关的API-Table API和SQL。</li><li>注意：目前Table API和SQL功能尚未全部完成，官方正在积极开发中。</li><li>暂时不推荐使用 故暂时不解释其用法</li></ul><h3 id="Flink-Broadcast-amp-Accumulators-amp-Counters"><a href="#Flink-Broadcast-amp-Accumulators-amp-Counters" class="headerlink" title="Flink Broadcast &amp; Accumulators &amp; Counters"></a>Flink Broadcast &amp; Accumulators &amp; Counters</h3><h4 id="Broadcast广播变量"><a href="#Broadcast广播变量" class="headerlink" title="Broadcast广播变量"></a>Broadcast广播变量</h4><ul><li>广播变量允许编程人员在每台机器上保持1个只读的缓存变量，而不是传送变量的副本给tasks</li><li>广播变量创建后，它可以运行在集群中的任何function上，而不需要多次传递给集群节点。另外需要记住，不应该修改广播变量，这样才能确保每个节点获取到的值都是一致的</li><li>一句话解释，可以理解为是一个公共的共享变量，我们可以把一个dataset数据集广播出去，然后不同的task在节点上都能够获取到，这个数据在每个节点上只会存在一份。如果不使用broadcast，则在每个节点中的每个task中都需要拷贝一份dataset数据集，比较浪费内存(也就是一个节点中可能会存在多份dataset数据)。</li><li>用法：<ul><li>初始化数据<ul><li>DataSet<integer> toBroadcast = env.fromElements(1, 2, 3);</integer></li></ul></li><li>广播数据<ul><li>.withBroadcastSet(toBroadcast,”broadcastSetName”);</li></ul></li><li>获取广播数据<ul><li>Collection<integer> broadcastSet =<br>getRuntimeContext().getBroadcastVariable(“broadcastSetName”);</integer></li></ul></li></ul></li><li>注意：<ul><li>广播出去的变量存在于每个节点的内存中，所以这个数据集不能太大。因为广播出去的数据，会常驻内存，除非程序执行结束</li><li>广播变量在初始化广播出去以后不支持修改，这样才能保证每个节点的数据都是一致的。</li></ul></li></ul><h4 id="Accumulators-累加器"><a href="#Accumulators-累加器" class="headerlink" title="Accumulators 累加器"></a>Accumulators 累加器</h4><ul><li>Accumulator即累加器，与Mapreduce counter的应用场景差不多，都能很好地观察task在运行期间的数据变化</li><li>可以在Flink job任务中的算子函数中操作累加器，但是只能在任务执行结束之后才能获得累加器的最终结果。</li></ul><h4 id="Counters-计数器"><a href="#Counters-计数器" class="headerlink" title="Counters 计数器"></a>Counters 计数器</h4><ul><li>Counter是一个具体的累加器(Accumulator)实现<ul><li>IntCounter, LongCounter 和 DoubleCounter</li></ul></li><li>用法：<ul><li>创建累加器<ul><li>private IntCounter numLines = new IntCounter();</li></ul></li><li>注册累加器<ul><li>getRuntimeContext().addAccumulator(“num-lines”,this.numLines);</li></ul></li><li>使用累加器<ul><li>this.numLines.add(1); </li></ul></li><li>获取累加器的结果<ul><li>myJobExecutionResult.getAccumulatorResult(“num-lines”)</li></ul></li></ul></li></ul><h4 id="广播变量-Broadcast-与-累加变量-Accumlators的区别"><a href="#广播变量-Broadcast-与-累加变量-Accumlators的区别" class="headerlink" title="广播变量 Broadcast 与 累加变量 Accumlators的区别"></a>广播变量 Broadcast 与 累加变量 Accumlators的区别</h4><ul><li>Broadcast(广播变量)允许程序员将一个只读的变量缓存在每台机器上，而不用在任务之间传递变量。广播变量可以进行共享，但是不可以进行修改</li><li>Accumulators(累加器)是可以在不同任务中对同一个变量进行累加操作。</li></ul><h3 id="Flink-Window和Time详解"><a href="#Flink-Window和Time详解" class="headerlink" title="Flink Window和Time详解"></a>Flink Window和Time详解</h3><h4 id="Window窗口"><a href="#Window窗口" class="headerlink" title="Window窗口"></a>Window窗口</h4><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567337912453.png" alt="1567337912453"></li><li>聚合事件例如计数、求和，在流上的工作方式与批处理不同<ul><li>比如，对流中的所有元素进行计数是不可能的，因为通常流是无限的（无界的）。所以，流上的聚合需要由window 来划定范围，比如 “计算过去的5分钟” ，或者“最后100个元素的和” </li><li>window是一种可以把无限数据切割为有限数据块的手段</li></ul></li><li>窗口可以是 时间驱动的 【Time Window】（比如：每30秒）或者数据驱动的【Count  Window】（比如：每100个元素）</li><li>widow窗口的类型<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338078663.png" alt="1567338078663"></li><li>tumbling windows：滚动窗口 【没有重叠】<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338109467.png" alt="1567338109467"></li></ul></li><li>sliding windows：滑动窗口 【有重叠】 <ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338132782.png" alt="1567338132782"></li></ul></li></ul></li><li>widow窗口的应用<ul><li>TimeWindow的应用<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338320496.png" alt="1567338320496"></li></ul></li><li>Count window<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338375799.png" alt="1567338375799"></li></ul></li><li>自定义window<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338475470.png" alt="1567338475470"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338483107.png" alt="1567338483107"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338514024.png" alt="1567338514024"></li></ul></li></ul></li><li>window聚合分类<ul><li>增量聚合<ul><li>在窗口中每进一条数据就进行一次聚合计算</li><li>reduce(reduceFunction)</li><li>aggregate(aggregateFunction)</li><li>sum(),min(),max()</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338666708.png" alt="1567338666708"></li><li>实现过程<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338695987.png" alt="1567338695987"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338704045.png" alt="1567338704045"></li></ul></li></ul></li><li>全量聚合<ul><li>等窗口中的所有数据到齐以后才进行聚合计算，可以实现对窗口内所有数据的排序等需求</li><li>apply(windowFunction)</li><li>process(processWindowFunction)   提供了更多上下文的信息</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338848386.png" alt="1567338848386"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338884621.png" alt="1567338884621"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338900562.png" alt="1567338900562"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567338909177.png" alt="1567338909177"></li></ul></li></ul></li></ul><h4 id="Time介绍"><a href="#Time介绍" class="headerlink" title="Time介绍"></a>Time介绍</h4><ul><li><p>针对stream中的时间，可以分为以下三种</p><ul><li>Event Time：事件产生的时间，通常由事件中的时间戳来描述</li><li>Ingestion Time:  事件进入Flink的时间</li><li>Processing time ： 时间倍处理时当前系统时间</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567339213593.png" alt="1567339213593"></li></ul></li><li><p>Time实例分析</p><ul><li><p>原始日志</p><ul><li>2018-10-10 10:00:01,134 INFO executor.Executor: Finished task in state 0.0</li></ul></li><li><p>数据进入Flink的时间是：2018-10-10 20:00:00,102</p></li><li><p>数据到达window进行处理的时间是：2018-10-10 20:00:01,100 </p></li><li><p>如果我们想要统计每分钟内接口调用失败的错误日志个数，使用哪个时间才有意义？</p><ul><li>Flink中，默认Time是ProcessingTime</li><li>可以在代码中设置<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567339399845.png" alt="1567339399845"></li></ul></li><li>但是Processing time 并不是我们特别想要的，因为日志文件在传输过程中顺序可能已经发生了变化，而我们想要的是错误日志产生时的信息，就是Event Time，所以我们需要考虑一下Event Time的乱序问题</li></ul></li><li><p>EventTime和Watermarks</p></li><li><p>在使用eventTime的时候如何处理乱序数据？</p><ul><li>我们知道，流处理从事件产生，到流经source，再到operator，中间是有一个过程和时间的。虽然大部分情况下，流到operator的数据都是按照事件产生的时间顺序来的，但是也不排除由于网络延迟等原因，导致乱序的产生，特别是使用kafka的话，多个分区的数据无法保证有序。所以在进行window计算的时候，我们又不能无限期的等下去，必须要有个机制来保证一个特定的时间后，必须触发window去进行计算了。这个特别的机制，就是watermark，watermark是用于处理乱序事件的。</li><li>watermark可以翻译为水位线</li></ul></li><li><p>有序流与无序流图解</p><ul><li>有序流</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567340864838.png" alt="1567340864838"></li><li>指定在那个时间点断开进行计算就可以直接断开进行计算</li><li>无序流</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567340912113.png" alt="1567340912113"></li><li>因为顺序被打乱 指定在某时间断开 其中的数据是错乱的无法进行立即聚合处理</li></ul></li><li><p>watermarks的使用</p></li><li><p>watermarks的生成方式有两种</p><ul><li>With Periodic Watermarks：周期性的触发watermark 的生成和发送</li><li>With Punctuated Watermarks：基于某些事件触发watermark 的生成和发送</li><li>第一种是我们常用的方法，所以就第一种来进行详细的分析</li></ul></li><li><p>参考官方文档中With Periodic Watermarks的使用方法</p><ul><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567341414170.png" alt="1567341414170"></p></li><li><p>代码中的extractTimestamp方法是从数据本身提取数据的Event time，getCurrentWatermar方法是获取当前水位线，利用currentMaxTimestamp - maxOutOfOrderness ，maxOutOfOrderness表示的是允许数据最大乱序时间</p><p>所以在这里我们需要使用的话就需要实现接口AssignerWithPeriodicWatermarks</p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567341604475.png" alt="1567341604475"></p></li></ul></li><li><p>实现watermark的相关代码</p></li><li><p>从socket模拟接收数据，然后使用map进行处理，后面在调用assignTimestampsAndWatermarks方法抽取timestamp并生成watermark。在调用window 打印信息来验证window被触发的时机</p></li><li><p>具体代码如下：</p></li><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> Flink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.TimeCharacteristic;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.windowing.WindowFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.watermark.Watermark;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.TimeWindow;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> javax.annotation.Nullable;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Watermark 案例</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StreamingWindowWatermark</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//定义 socket 的端口号</span></span><br><span class="line">        <span class="keyword">int</span> port = <span class="number">9001</span>;</span><br><span class="line">        <span class="comment">// 获取运行环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">//设置使用 eventtime，默认是使用 processtime</span></span><br><span class="line">        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line">        <span class="comment">//设置并行度为 1,默认并行度是当前机器的 cpu 数量</span></span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//连接 socket 获取输入的数据</span></span><br><span class="line">        DataStream&lt;String&gt; text = env.socketTextStream(<span class="string">"hadoop100"</span>, port, <span class="string">"\n"</span>);</span><br><span class="line">        <span class="comment">//解析输入的数据</span></span><br><span class="line">        DataStream&lt;Tuple2&lt;String, Long&gt;&gt; inputMap = text.map(<span class="keyword">new</span> MapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Long&gt; <span class="title">map</span><span class="params">(String value)</span></span></span><br><span class="line"><span class="function">                    <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                String[] arr = value.split(<span class="string">","</span>);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(arr[<span class="number">0</span>], Long.parseLong(arr[<span class="number">1</span>]));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//抽取 timestamp 和生成 watermark</span></span><br><span class="line">        DataStream&lt;Tuple2&lt;String, Long&gt;&gt; waterMarkStream = inputMap.assignTimestampsAndWatermarks(<span class="keyword">new</span> AssignerWithPeriodicWatermarks&lt;Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">            Long currentMaxTimestamp = <span class="number">0L</span>;</span><br><span class="line">            <span class="comment">// 最大允许的乱序时间是 10s</span></span><br><span class="line">            <span class="keyword">final</span> Long maxOutOfOrderness = <span class="number">10000L</span>;</span><br><span class="line">            SimpleDateFormat sdf = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss.SSS"</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">/***</span></span><br><span class="line"><span class="comment">             * 定义生成 watermark 的逻辑 * 默认 100ms 被调用一次</span></span><br><span class="line"><span class="comment">             * */</span></span><br><span class="line">            <span class="meta">@Nullable</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Watermark <span class="title">getCurrentWatermark</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Watermark(currentMaxTimestamp - maxOutOfOrderness);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//定义如何提取 timestamp</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Tuple2&lt;String, Long&gt; element, <span class="keyword">long</span> previousElementTimestamp)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">long</span> timestamp = element.f1;</span><br><span class="line">                currentMaxTimestamp = Math.max(timestamp, currentMaxTimestamp);</span><br><span class="line">                System.out.println(<span class="string">"key:"</span> + element.f0 + <span class="string">",eventtime:["</span> + element.f1 + <span class="string">"|"</span> + sdf.format(element.f1) + <span class="string">"], currentMaxTimestamp:["</span> + currentMaxTimestamp + <span class="string">"|"</span> + sdf.format(currentMaxTimestamp) + <span class="string">"],watermark:["</span> + getCurrentWatermark().getTimestamp() + <span class="string">"|"</span> + sdf.format(getCurrentWatermark().getTimestamp()) + <span class="string">"]"</span>);</span><br><span class="line">                <span class="keyword">return</span> timestamp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//分组，聚合</span></span><br><span class="line">        DataStream&lt;String&gt; window = waterMarkStream.keyBy(<span class="number">0</span>)</span><br><span class="line">                .window(TumblingEventTimeWindows.of(Time.seconds(<span class="number">3</span>)))<span class="comment">// 按 照 消 息 的 EventTime 分配窗口，和调用 TimeWindow 效果一样</span></span><br><span class="line">                .apply(<span class="keyword">new</span> WindowFunction&lt;Tuple2&lt;String, Long&gt;, String, Tuple, TimeWindow&gt;() &#123;</span><br><span class="line">                    <span class="comment">/*** 对 window 内的数据进行排序，保证数据的顺序</span></span><br><span class="line"><span class="comment">                     * * <span class="doctag">@param</span> tuple * <span class="doctag">@param</span> window * <span class="doctag">@param</span> input * <span class="doctag">@param</span> out * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">                     * */</span></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(Tuple tuple, TimeWindow window, Iterable&lt;Tuple2&lt;String, Long&gt;&gt; input, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                        String key = tuple.toString();</span><br><span class="line">                        List&lt;Long&gt; arrarList = <span class="keyword">new</span> ArrayList&lt;Long&gt;();</span><br><span class="line">                        Iterator&lt;Tuple2&lt;String, Long&gt;&gt; it = input.iterator();</span><br><span class="line">                        <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">                            Tuple2&lt;String, Long&gt; next = it.next();</span><br><span class="line">                            arrarList.add(next.f1);</span><br><span class="line">                        &#125;</span><br><span class="line">                        Collections.sort(arrarList);</span><br><span class="line">                        SimpleDateFormat sdf = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss.SSS"</span>);</span><br><span class="line">                        String result = key + <span class="string">","</span> + arrarList.size() + <span class="string">","</span> + sdf.format(arrarList.get(<span class="number">0</span>)) + <span class="string">","</span> + sdf.format(arrarList.get(arrarList.size() - <span class="number">1</span>)) + <span class="string">","</span> + sdf.format(window.getStart()) + <span class="string">","</span> + sdf.format(window.getEnd());</span><br><span class="line">                        out.collect(result);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">        <span class="comment">//测试-把结果打印到控制台即可</span></span><br><span class="line">        window.print();</span><br><span class="line">        <span class="comment">//注意：因为 flink 是懒加载的，所以必须调用 execute 方法，上面的代码才会执行</span></span><br><span class="line">        env.execute(<span class="string">"eventtime-watermark"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>程序简单解释</p><ul><li>接收socket传来的数据</li><li>将每行数据按照逗号分隔，每行数据调用map 转换成tuple&lt;String,Long&gt;类型。其中tuple 中的第一个元素代表具体的数据，第二个元素代表数据的eventtime</li><li>抽取timestamp ， 生成watermar ， 允许的最大乱序时间是10s ， 并打印<br>（key,eventtime,currentMaxTimestamp,watermark）等信息</li><li>分组聚合，window 窗口大小为3 秒，输出（key，窗口内元素个数，窗口内最早元素的<br>时间，窗口内最晚元素的时间，窗口自身开始时间，窗口自身结束时间）</li></ul></li><li><p>测试数据</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">测试数据-1如下：watermark+window处理乱序数据</span><br><span class="line">0001,15383598820002018-10-01 10:11:22</span><br><span class="line">0001,15383598860002018-10-01 10:11:26</span><br><span class="line">0001,15383598920002018-10-01 10:11:32</span><br><span class="line">0001,15383598930002018-10-01 10:11:33</span><br><span class="line">0001,15383598940002018-10-01 10:11:34</span><br><span class="line">0001,15383598960002018-10-01 10:11:36</span><br><span class="line">0001,15383598970002018-10-01 10:11:37</span><br><span class="line"></span><br><span class="line">0001,15383598990002018-10-01 10:11:39</span><br><span class="line">0001,15383598910002018-10-01 10:11:31</span><br><span class="line">0001,15383599030002018-10-01 10:11:43</span><br><span class="line"></span><br><span class="line">0001,15383598920002018-10-01 10:11:32</span><br><span class="line">0001,15383598910002018-10-01 10:11:31</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">测试数据-2如下：延迟数据被丢弃</span><br><span class="line">0001,15383598900002018-10-01 10:11:30</span><br><span class="line">0001,15383599030002018-10-01 10:11:43</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">0001,15383598900002018-10-01 10:11:30</span><br><span class="line">0001,15383598910002018-10-01 10:11:31</span><br><span class="line">0001,15383598920002018-10-01 10:11:32</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">测试数据-3如下：allowedLateness </span><br><span class="line">0001,15383598900002018-10-01 10:11:30</span><br><span class="line">0001,15383599030002018-10-01 10:11:43</span><br><span class="line">0001,15383598900002018-10-01 10:11:30</span><br><span class="line">0001,15383598910002018-10-01 10:11:31</span><br><span class="line">0001,15383598920002018-10-01 10:11:32</span><br><span class="line">0001,15383599040002018-10-01 10:11:44</span><br><span class="line">0001,15383598900002018-10-01 10:11:30</span><br><span class="line">0001,15383598910002018-10-01 10:11:31</span><br><span class="line">0001,15383598920002018-10-01 10:11:32</span><br><span class="line">0001,15383599050002018-10-01 10:11:45</span><br><span class="line">0001,15383598900002018-10-01 10:11:30</span><br><span class="line">0001,15383598910002018-10-01 10:11:31</span><br><span class="line">0001,15383598920002018-10-01 10:11:32</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">测试数据-4如下：sideOutputLateData </span><br><span class="line">0001,15383598900002018-10-01 10:11:30</span><br><span class="line">0001,15383599030002018-10-01 10:11:43</span><br><span class="line">0001,15383598900002018-10-01 10:11:30</span><br><span class="line">0001,15383598910002018-10-01 10:11:31</span><br><span class="line">0001,15383598920002018-10-01 10:11:32</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">测试数据-5如下：多并行度下的watermark-8</span><br><span class="line">0001,15383598820002018-10-01 10:11:22</span><br><span class="line">0001,15383598860002018-10-01 10:11:26</span><br><span class="line">0001,15383598920002018-10-01 10:11:32</span><br><span class="line">0001,15383598930002018-10-01 10:11:33</span><br><span class="line">0001,15383598940002018-10-01 10:11:34</span><br><span class="line">0001,15383598960002018-10-01 10:11:36</span><br><span class="line">0001,15383598970002018-10-01 10:11:37</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">测试数据-6如下：</span><br><span class="line">0001,15383598900002018-10-01 10:11:30</span><br><span class="line">0001,15383599030002018-10-01 10:11:43</span><br><span class="line">0001,15383599080002018-10-01 10:11:48</span><br></pre></td></tr></table></figure></li></ul></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567345375589.png" alt="1567345375589"></p></li><li><p>注意：多并行度的情况下，watermark对齐会取所有channel最小的watermark</p></li><li><p>watermarks的生成方式</p><ul><li><p>With Periodic Watermarks</p><p>周期性的触发watermark的生成和发送，默认是100ms</p><p>每隔N秒自动向流里注入一个WATERMARK 时间间隔由ExecutionConfig.setAutoWatermarkInterval 决定. 每次调用getCurrentWatermark 方法, 如果得到的WATERMARK 不为空并且比之前的大就注入流中 </p><p>可以定义一个最大允许乱序的时间，这种比较常用</p><p>实现AssignerWithPeriodicWatermarks接口</p></li><li><p>With Punctuated Watermarks</p><p>基于某些事件触发watermark的生成和发送</p><p>基于事件向流里注入一个WATERMARK，每一个元素都有机会判断是否生成一个WATERMARK. 如果得到的WATERMARK 不为空并且比之前的大就注入流中</p><p>实现AssignerWithPunctuatedWatermarks接口</p></li></ul></li><li><p>watermark  与 event time结合使用</p><ul><li>触发widow进行合并的条件是  watermark &gt;= window_end_time  并且当前窗口内有数据</li><li>这样就可以在允许最大乱序时间内将同一个窗口的数据进行处理，如果数据超过了这个最大允许乱序时间，要怎么解决呢</li></ul></li><li><p>late element 延迟数据的处理方案</p><ul><li>丢弃 系统默认的方法<ul><li>直接将超过允许最大乱序时间的数据丢弃，不做任何处理</li></ul></li><li>allowedLateness  指定允许数据延迟时间<ul><li>再给迟到的数据一个提供一个宽容时间</li><li>加上这个时间以后 在超过最大允许乱序时间以后 在宽容时间内 如果数据出现了 依然可以出发widow执行。</li></ul></li><li>sideOutputLateDate  收集迟到的数据<ul><li>通过sideOutputLateDate将迟到的数据进行统一收集进行存储，方便 以后的问题排查处理</li></ul></li></ul></li><li><p>Flink应该如何设置最大乱序时间</p><ul><li>这个要结合自己的业务以及数据情况去设置。如果maxOutOfOrderness设置的太小，而自身数据发送时由于网络等原因导致乱序或者late太多，那么最终的结果就是会有很多单条的数据在window中被触发，数据的正确性影响太大</li><li>对于严重乱序的数据，需要严格统计数据最大延迟时间，才能保证计算的数据准确，延时设置太小会影响数据准确性，延时设置太大不仅影响数据的实时性，更加会加重Flink作业的负担，不是对eventTime要求特别严格的数据，尽量不要采用eventTime方式来处理，会有丢数据的风险。</li></ul></li></ul></li></ul><h3 id="Flink-并行度详解-Parallel"><a href="#Flink-并行度详解-Parallel" class="headerlink" title="Flink 并行度详解(Parallel )"></a>Flink 并行度详解(Parallel )</h3><h4 id="TaskManager-与-Slot"><a href="#TaskManager-与-Slot" class="headerlink" title="TaskManager 与 Slot"></a>TaskManager 与 Slot</h4><ul><li>Flink的每个TaskManager为集群提供solt。 solt的数量通常与每个TaskManager节点的可用CPU内核数成比例。一般情况下你的slot数是你每个节点的cpu的核数。<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567433392285.png" alt="1567433392285"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567433422808.png" alt="1567433422808"></li></ul></li></ul><h4 id="并行度（Parallel）"><a href="#并行度（Parallel）" class="headerlink" title="并行度（Parallel）"></a>并行度（Parallel）</h4><ul><li>一个Flink程序由多个任务组成(source、transformation和 sink)。 一个任务由多个并行的实例(线程)来执行， 一个任务的并行实例(线程)数目就被称为该任务的并行度。</li><li>一个任务的并行度设置可以从多个层次指定<ul><li>Operator Level（算子层次）</li><li>Execution Environment Level（执行环境层次）</li><li>Client Level（客户端层次）</li><li>System Level（系统层次）</li></ul></li><li>并行度设置之Operator Level<ul><li>一个算子、数据源和sink的并行度可以通过调用 setParallelism()方法来指定</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567433659150.png" alt="1567433659150"></li></ul></li><li>并行度设置之Execution Environment Level<ul><li>执行环境(任务)的默认并行度可以通过调用setParallelism()方法指定。为了以并行度3来执行所有的算子、数据源和data sink， 可以通过如下的方式设置执行环境的并行度</li><li>执行环境的并行度可以被算子的并行度覆盖重写</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567433733701.png" alt="1567433733701"></li></ul></li><li>并行度设置之Client Level<ul><li>并行度可以在客户端将job提交到Flink时设定。</li><li>对于CLI客户端，可以通过-p参数指定并行度</li><li>./bin/flink run <strong>-p</strong> 10 WordCount-java.jar</li></ul></li><li>并行度设置之System Level<ul><li>在系统级可以通过设置flink-conf.yaml文件中的parallelism.default属性来指定所有执行环境的默认并行度</li></ul></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567433861193.png" alt="1567433861193"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567433868135.png" alt="1567433868135"></li></ul><h3 id="Flink的checkpoint机制"><a href="#Flink的checkpoint机制" class="headerlink" title="Flink的checkpoint机制"></a>Flink的checkpoint机制</h3><h4 id="checkpoint简介"><a href="#checkpoint简介" class="headerlink" title="checkpoint简介"></a>checkpoint简介</h4><ul><li>为了保证state的容错性，Flink需要对state进行checkpoint</li><li>Checkpoint是Flink实现容错机制最核心的功能，它能够根据配置周期性地基于Stream中各个Operator/task的状态来生成快照，从而将这些状态数据定期持久化存储下来，当Flink程序一旦意外崩溃时，重新运行程序时可以有选择地从这些快照进行恢复，从而修正因为故障带来的程序数据异常</li><li>Flink的checkpoint机制可以与(stream和state)的持久化存储交互的前提：<ul><li>持久化的source，它需要支持在一定时间内重放事件。这种sources的典型例子是持久化的消息队列（比如Apache  Kafka，RabbitMQ等）或文件系统（比如HDFS，S3，GFS等）</li><li>用于state的持久化存储，例如分布式文件系统（比如HDFS，S3，GFS等）</li></ul></li></ul><h4 id="checkpoint的配置"><a href="#checkpoint的配置" class="headerlink" title="checkpoint的配置"></a>checkpoint的配置</h4><ul><li><p>默认的情况下 checkpoint是disabled不可用状态，想要使用的时候先开启</p></li><li><p>checkpoint的checkPointMode有两种，Exactly-once(默认)和At-least-once</p></li><li><p>Exactly-once对于大多数应用来说是最合适的。At-least-once可能用在某些延迟超低的应用程序（始终延迟为几毫秒）</p></li><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// 每隔1000 ms进行启动一个检查点【设置checkpoint的周期】</span></span><br><span class="line">env.enableCheckpointing(<span class="number">1000</span>);</span><br><span class="line"><span class="comment">// 高级选项：</span></span><br><span class="line"><span class="comment">// 设置模式为exactly-once （这是默认值）</span></span><br><span class="line">env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line"><span class="comment">// 确保检查点之间有至少500 ms的间隔【checkpoint最小间隔】</span></span><br><span class="line">env.getCheckpointConfig().setMinPauseBetweenCheckpoints(<span class="number">500</span>);</span><br><span class="line"><span class="comment">// 检查点必须在一分钟内完成，或者被丢弃【checkpoint的超时时间】</span></span><br><span class="line">env.getCheckpointConfig().setCheckpointTimeout(<span class="number">60000</span>);</span><br><span class="line"><span class="comment">// 同一时间只允许进行一个检查点</span></span><br><span class="line">env.getCheckpointConfig().setMaxConcurrentCheckpoints(<span class="number">1</span>);</span><br><span class="line"><span class="comment">// 表示一旦Flink处理程序被cancel后，会保留Checkpoint数据，以便根据实际需要恢复到指定的Checkpoint</span></span><br><span class="line">env.getCheckpointConfig().enableExternalizedCheckpoints(ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);</span><br></pre></td></tr></table></figure></li></ul><h4 id="state-Backend-状态的后端存储"><a href="#state-Backend-状态的后端存储" class="headerlink" title="state Backend 状态的后端存储"></a>state Backend 状态的后端存储</h4><ul><li><p>默认情况下，state会保存在taskmanager的内存中，checkpoint会存储在JobManager的内存中。</p></li><li><p>state 和checkpoint的存储位置取决于State Backend的配置  可以在程序中修改</p><ul><li>env.setStateBackend(…)</li></ul></li><li><p>三种state Backend</p></li><li><p>MemoryStateBackend</p><ul><li>state数据保存在java堆内存中，执行checkpoint的时候，会把state的快照数据保存到jobmanager的内存中</li><li>基于内存的state backend在生产环境下不建议使用</li></ul></li><li><p>FsStateBackend</p><ul><li>state数据保存在taskmanager的内存中，执行checkpoint的时候，会把state的快照数据保存到配置的文件系统中</li><li>可以使用hdfs等分布式文件系统</li></ul></li><li><p><strong>RocksDBStateBackend</strong></p><ul><li>RocksDB跟上面的都略有不同，它会在本地文件系统中维护状态，state会直接写入本地rocksdb中。同时它需要配置一个远端的filesystem uri（一般是HDFS），在做checkpoint的时候，会把本地的数据直接复制到filesystem中。fail over的时候从filesystem中恢复到本地</li><li>RocksDB克服了state受内存限制的缺点，同时又能够持久化到远端文件系统中，比较适合在生产中使用</li></ul></li><li><p>修改state Backend </p><ul><li><p><strong>单任务调整</strong></p></li><li><p>修改当前任务代码</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">env.setStateBackend(new FsStateBackend(&quot;hdfs://namenode:9000/flink/checkpoints&quot;));</span><br><span class="line">or new MemoryStateBackend()</span><br><span class="line">or new RocksDBStateBackend(filebackend, true);【需要添加第三方依赖】</span><br></pre></td></tr></table></figure></li><li><p>全局调整</p></li><li><p>修改flink-conf.yaml</p></li><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">state.backend: filesystem</span><br><span class="line">state.checkpoints.dir: hdfs:<span class="comment">//namenode:9000/flink/checkpoints</span></span><br><span class="line">注意：state.backend的值可以是下面几种：jobmanager(MemoryStateBackend), filesystem(FsStateBackend), rocksdb(RocksDBStateBackend)</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="Flink-Kafka-Connector详解"><a href="#Flink-Kafka-Connector详解" class="headerlink" title="Flink Kafka-Connector详解"></a>Flink Kafka-Connector详解</h3><h4 id="kafka-connector简介"><a href="#kafka-connector简介" class="headerlink" title="kafka-connector简介"></a>kafka-connector简介</h4><ul><li>Kafka中的partition机制和Flink的并行度机制深度结合</li><li>Kafka可以作为Flink的source和sink</li><li>任务失败，通过设置kafka的offset来恢复应用</li></ul><h4 id="kafka-consumer消费者策略"><a href="#kafka-consumer消费者策略" class="headerlink" title="kafka-consumer消费者策略"></a>kafka-consumer消费者策略</h4><ul><li><strong>setStartFromGroupOffsets()</strong>【默认消费策略】<ul><li>默认读取上次保存的offset信息</li><li>如果是应用第一次启动，读取不到上次的offset信息，则会根据这个参数auto.offset.reset的值来进行消费数据</li></ul></li><li>setStartFromEarliest()<ul><li>从最早的数据开始进行消费，忽略存储的offset信息</li></ul></li><li><strong>setStartFromLatest()</strong><ul><li>从最新的数据进行消费，忽略存储的offset信息</li></ul></li><li>setStartFromSpecificOffsets(Map&lt;KafkaTopicPartition,Long&gt;)<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567435618888.png" alt="1567435618888"></li></ul></li></ul><h4 id="kafka的容错"><a href="#kafka的容错" class="headerlink" title="kafka的容错"></a>kafka的容错</h4><ul><li>当checkpoint机制开启的时候，Kafka Consumer会定期把kafka的offset信息还有其他operator的状态信息一块保存起来。当job失败重启的时候，Flink会从最近一次的checkpoint中进行恢复数据，重新消费kafka中的数据。</li><li>为了能够使用支持容错的kafka Consumer，需要开启checkpoint<ul><li>env.enableCheckpointing(5000); // 每5s checkpoint一次</li></ul></li></ul><h4 id="动态加载topic"><a href="#动态加载topic" class="headerlink" title="动态加载topic"></a>动态加载topic</h4><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567435791533.png" alt="1567435791533"></li></ul><h4 id="kafka-consumer-offset-自动提交"><a href="#kafka-consumer-offset-自动提交" class="headerlink" title="kafka consumer offset 自动提交"></a>kafka consumer offset 自动提交</h4><ul><li>针对job是否开启checkpoint来区分<ul><li>Checkpoint关闭时： 可以通过下面两个参数配置<ul><li>enable.auto.commit</li><li>auto.commit.interval.ms</li></ul></li><li>Checkpoint开启时：当执行checkpoint的时候才会保存offset，这样保证了kafka的offset和checkpoint的状态偏移量保持一致。<ul><li>可以通过这个参数设置setCommitOffsetsOnCheckpoints(boolean)这个参数默认就是true。表示在checkpoint的时候提交offset 此时，kafka中的自动提交机制就会被忽略</li></ul></li></ul></li></ul><h4 id="Kafka-Producer"><a href="#Kafka-Producer" class="headerlink" title="Kafka Producer"></a>Kafka Producer</h4><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1567436059578.png" alt="1567436059578"></li></ul><h4 id="kafka-producer-的容错-kafka0-9-与-0-10"><a href="#kafka-producer-的容错-kafka0-9-与-0-10" class="headerlink" title="kafka producer 的容错  kafka0.9 与 0.10"></a>kafka producer 的容错  kafka0.9 与 0.10</h4><ul><li>如果Flink开启了checkpoint，针对FlinkKafkaProducer09和FlinkKafkaProducer010 可以提供 at-least-once的语义，还需要配置下面两个参数<ul><li>setLogFailuresOnly(false)</li><li>setFlushOnCheckpoint(true)</li></ul></li><li>注意：建议修改kafka 生产者的重试次数<ul><li>retries【这个参数的值默认是0】</li></ul></li></ul><h4 id="Kafka-Producer的容错-Kafka-0-11"><a href="#Kafka-Producer的容错-Kafka-0-11" class="headerlink" title="Kafka Producer的容错-Kafka 0.11"></a>Kafka Producer的容错-Kafka 0.11</h4><ul><li>如果Flink开启了checkpoint，针对FlinkKafkaProducer011 就可以提供<br>exactly-once的语义</li><li>但是需要选择具体的语义<ul><li>Semantic.NONE</li><li>Semantic.AT_LEAST_ONCE【默认】</li><li>Semantic.EXACTLY_ONCE</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python快速入门</title>
      <link href="/2019/08/21/Python%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
      <url>/2019/08/21/Python%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="Python快速入门"><a href="#Python快速入门" class="headerlink" title="Python快速入门"></a>Python快速入门</h2><h3 id="Python简介"><a href="#Python简介" class="headerlink" title="Python简介"></a>Python简介</h3><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566883029034.png" alt="1566883029034"></p><a id="more"></a><ul><li>Python是著名的“龟叔”Guido van Rossum（吉多·范罗苏姆）在1989年圣诞节期间，为了打发无聊的圣诞节而编写的一个编程语言；1991年初，Python发布了第一个公开发行版。Python是用C编写的高级的、面向对象的、开放源代码的编程语言。</li><li>龟叔给Python的定位是“优雅”、“明确”、“简单”，所以Python程序看上去总是简单易懂，初学者学Python，不但入门容易，而且将来深入下去，可以编写那些非常非常复杂的程序。</li><li>现在Python是由一个核心开发团队在维护，Guido van Rossum 仍然占据着至关重要的作用，指导其进展。</li><li>Python的学习成本低，上手快，而且学习后的用处很多，也可以利用Python写出非常复杂的程序，以及复杂的算法等</li><li>Python是一门解释性编程语言，在实际开发中，如果是开发小型工具等可以优先使用Python，开发效率会明显优于Java等编译性语言</li><li>Python也可以开发web网站、http接口等</li></ul><h3 id="Python安装"><a href="#Python安装" class="headerlink" title="Python安装"></a>Python安装</h3><ul><li><p>现在Python常用的版本是2.x以及3.x。Linux中会自带Python大部分默认安装的是2.x的版本。</p></li><li><p>在官方网站下载需要的版本 <a href="https://www.python.org" target="_blank" rel="noopener">https://www.python.org</a></p></li><li><p>在Linux系统中Python的默认安装目录是:/user/bin/python</p></li><li><p>下载安装完成以后需要进行环境变量配置就如同配置JDK一样</p></li><li><p>安装完毕以后再命令行下执行Python命令查看</p></li><li><p>我使用的是windows操作系统</p><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566883609834.png" alt="1566883609834"></li></ul></li><li><p>可以直接在命令行里面输入代码进行操作</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Hello，World"</span>)</span><br><span class="line">结果是：</span><br><span class="line">Hello，World</span><br></pre></td></tr></table></figure></li><li><p>想退出Python命令行可以输入指令exit（）或者quit（）</p></li></ul></li><li><p>我们使用idea作为Python的IDE，需要自行下载Python插件就可以，直接在idea里面搜索下载就可以，在这里就不演示了。</p></li></ul><h3 id="Python常用操作"><a href="#Python常用操作" class="headerlink" title="Python常用操作"></a>Python常用操作</h3><ul><li><p>Python的一些基础语法</p><ul><li>没有大括号，直接使用缩进来代表逻辑的层次</li><li>单行注释 以#开头</li><li>多行注释使用三个单引号或者双引号都可以  ‘’‘ 注释 ’‘’  “”“ 注释 ”“”</li><li>注意：如果注释里面要写中文的话需要指定coding=utf8  否在在别人的IDE中会出现注释乱码的现象</li><li>Python是大小写敏感的</li></ul></li><li><p>基本数据类型</p><ul><li>与其他语言基本相似</li><li>整数、浮点数、字符串、布尔值</li><li>空值：none</li><li>转义符<ul><li>\n  换行符</li><li>\t   制表符</li><li>r     表示禁止字符转义，即转义字符会被当作为普通字符解析</li></ul></li><li>type(arg)  获取arg的数据类型</li><li>isinstance（arg,type） 判断arg是否是type这个类型的  例如 isinstance(1.22,int)</li><li>注意：bool类型的数据底层存储的是0，1如果是布尔值判断是否为int类型的返回值为true</li></ul></li><li><p>字符串常用操作</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">string字符串测试</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">str1 = <span class="string">" Hello World "</span></span><br><span class="line"><span class="comment"># 所有字母转换为小写</span></span><br><span class="line"><span class="keyword">print</span> (str.lower(str1))</span><br><span class="line"><span class="comment"># 所有字母转换为大写</span></span><br><span class="line"><span class="keyword">print</span> (str.upper(str1))</span><br><span class="line">str1 = <span class="string">" \tHello World "</span></span><br><span class="line"><span class="comment"># 删除字符串开头结尾的空格 默认会删除空白符（'\n','\t','\r')</span></span><br><span class="line"><span class="keyword">print</span> (str1.strip())</span><br><span class="line"><span class="comment"># 只删除开头结尾的空格</span></span><br><span class="line"><span class="keyword">print</span> (str1.strip(<span class="string">" "</span>))</span><br><span class="line">str1 = <span class="string">" Hello World "</span></span><br><span class="line"><span class="comment"># 分割字符串 查看分割结果的数据类型</span></span><br><span class="line">split = str1.split(<span class="string">" "</span>)</span><br><span class="line"><span class="keyword">print</span> (split)</span><br><span class="line"><span class="keyword">print</span> (type(split))</span><br><span class="line"><span class="comment"># 使用指定字符对数据进行拼接</span></span><br><span class="line">arr = [<span class="string">"1"</span>,<span class="string">"2"</span>,<span class="string">"3"</span>,<span class="string">"4"</span>,<span class="string">"5"</span>]</span><br><span class="line">joinstr = <span class="string">"_"</span>.join(arr)</span><br><span class="line"><span class="keyword">print</span> (joinstr)</span><br><span class="line"><span class="comment"># 使用+可以直接拼接两个字符串</span></span><br><span class="line">str2 = str1 + <span class="string">"hhhhh"</span></span><br><span class="line"><span class="keyword">print</span> (str2)</span><br><span class="line"><span class="comment"># str3 = str2 + 1 是错误的  不支持字符串直接+上int类型值拼接</span></span><br><span class="line">str3 = <span class="string">"hello %d"</span>%(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> (str3)</span><br><span class="line"></span><br><span class="line">E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/StrTest.py</span><br><span class="line"> hello world </span><br><span class="line"> HELLO WORLD </span><br><span class="line">Hello World</span><br><span class="line">Hello World</span><br><span class="line">[<span class="string">''</span>, <span class="string">'Hello'</span>, <span class="string">'World'</span>, <span class="string">''</span>]</span><br><span class="line">&lt;type <span class="string">'list'</span>&gt;</span><br><span class="line"><span class="number">1</span>_2_3_4_5</span><br><span class="line"> Hello World hhhhh</span><br><span class="line">hello <span class="number">3</span></span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>List常用操作</p><ul><li><p>list是一种有序集合，可以添加和删除其中的元素</p></li><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">List测试</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># 创建一个list</span></span><br><span class="line">list1 = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line"><span class="comment"># 向末尾插入一个数据</span></span><br><span class="line">list1.append(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">print</span> (list1)</span><br><span class="line"><span class="comment"># 向指定索引位置添加数据</span></span><br><span class="line">list1.insert(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"><span class="keyword">print</span> (list1)</span><br><span class="line"><span class="comment"># 删除元素 不加索引位置参数默认删除list列表最后一个</span></span><br><span class="line">list1.pop()</span><br><span class="line"><span class="keyword">print</span> (list1)</span><br><span class="line">list1.pop(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">print</span> (list1)</span><br><span class="line"><span class="comment"># 删除第一次出现的 2 只会删除一个</span></span><br><span class="line">list1.remove(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">print</span> (list1)</span><br><span class="line"><span class="comment"># 替换某个位置的元素</span></span><br><span class="line">list1[<span class="number">0</span>] = <span class="number">100</span></span><br><span class="line"><span class="keyword">print</span> (list1)</span><br><span class="line"><span class="comment"># 计算某个元素出现的次数</span></span><br><span class="line">count = list1.count(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> (count)</span><br><span class="line"><span class="comment"># 将list列表中的数据倒置</span></span><br><span class="line"><span class="keyword">print</span> (list1)</span><br><span class="line">list1.reverse()</span><br><span class="line"><span class="keyword">print</span> (list1)</span><br><span class="line"><span class="comment"># tuple和list类似 但是tuple初始化以后将不能够在进行修改</span></span><br><span class="line">tuple1 = tuple(list1)</span><br><span class="line"><span class="keyword">print</span> (tuple1)</span><br><span class="line"><span class="comment"># 计算tuple内某个元素出现的次数</span></span><br><span class="line">tcount = tuple1.count(<span class="number">100</span>)</span><br><span class="line"><span class="keyword">print</span> (tcount)</span><br><span class="line"></span><br><span class="line">E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/ListTest.py</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">10</span>]</span><br><span class="line">[<span class="number">10</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">10</span>]</span><br><span class="line">[<span class="number">10</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">[<span class="number">100</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line">[<span class="number">100</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">[<span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">100</span>]</span><br><span class="line">(<span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">100</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>Dict常用操作</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Dict测试</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># 创建一个Dict并赋值  Dict相当于是Java中的map</span></span><br><span class="line">dict1 = &#123;<span class="string">'Michael'</span>: <span class="number">95</span>, <span class="string">'Bob'</span>: <span class="number">75</span>, <span class="string">'Tracy'</span>: <span class="number">100</span>&#125;</span><br><span class="line"><span class="keyword">print</span> (dict1)</span><br><span class="line"><span class="comment"># 修改指定key的value</span></span><br><span class="line">dict1[<span class="string">'Bob'</span>] = <span class="number">60</span></span><br><span class="line"><span class="keyword">print</span> (dict1)</span><br><span class="line"><span class="comment"># 取出指定key的value 使用此方法如果可以不存在程序就会报错</span></span><br><span class="line">data = dict1[<span class="string">'Bob'</span>]</span><br><span class="line"><span class="keyword">print</span> (data)</span><br><span class="line"><span class="comment"># 使用 dice.get()如果key不存在将会返回none值</span></span><br><span class="line">data2 = dict1.get(<span class="string">'bob'</span>)</span><br><span class="line"><span class="keyword">print</span> (data2)</span><br><span class="line"><span class="comment"># 删除指定key的键值对 如果指定key不存在就会报错</span></span><br><span class="line">dict1.pop(<span class="string">'Bob'</span>)</span><br><span class="line"><span class="keyword">print</span> (dict1)</span><br><span class="line"><span class="comment"># 删除第一个键值对并返回删除的元素</span></span><br><span class="line">data3 = dict1.popitem()</span><br><span class="line"><span class="keyword">print</span> (data3)</span><br><span class="line"><span class="keyword">print</span> (dict1)</span><br><span class="line"><span class="comment"># 清理所有元素</span></span><br><span class="line">dict1.clear()</span><br><span class="line"><span class="keyword">print</span> (dict1)</span><br><span class="line"></span><br><span class="line">d = &#123;<span class="string">'Michael'</span>: <span class="number">95</span>, <span class="string">'Bob'</span>: <span class="number">75</span>, <span class="string">'Tracy'</span>: <span class="string">'hello'</span>&#125;</span><br><span class="line"><span class="keyword">print</span> (d)</span><br><span class="line"><span class="comment"># 判断对列中是否存在指定的key</span></span><br><span class="line">res = d.has_key(<span class="string">'bob'</span>)</span><br><span class="line"><span class="keyword">print</span> (res)</span><br><span class="line"><span class="comment"># 返回一个list，list中的元素是tuple类型的</span></span><br><span class="line">res2 = d.items()</span><br><span class="line"><span class="keyword">print</span> (res2)</span><br><span class="line"><span class="comment"># 返回一个包含所有key的list</span></span><br><span class="line">res3 = d.keys()</span><br><span class="line"><span class="keyword">print</span> (res3)</span><br><span class="line"><span class="comment"># 返回一个包含所有value的list</span></span><br><span class="line">res4 = d.values()</span><br><span class="line"><span class="keyword">print</span> (res4)</span><br><span class="line"></span><br><span class="line">E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/DictTest.py</span><br><span class="line">&#123;<span class="string">'Bob'</span>: <span class="number">75</span>, <span class="string">'Michael'</span>: <span class="number">95</span>, <span class="string">'Tracy'</span>: <span class="number">100</span>&#125;</span><br><span class="line">&#123;<span class="string">'Bob'</span>: <span class="number">60</span>, <span class="string">'Michael'</span>: <span class="number">95</span>, <span class="string">'Tracy'</span>: <span class="number">100</span>&#125;</span><br><span class="line"><span class="number">60</span></span><br><span class="line"><span class="literal">None</span></span><br><span class="line">&#123;<span class="string">'Michael'</span>: <span class="number">95</span>, <span class="string">'Tracy'</span>: <span class="number">100</span>&#125;</span><br><span class="line">(<span class="string">'Michael'</span>, <span class="number">95</span>)</span><br><span class="line">&#123;<span class="string">'Tracy'</span>: <span class="number">100</span>&#125;</span><br><span class="line">&#123;&#125;</span><br><span class="line">&#123;<span class="string">'Bob'</span>: <span class="number">75</span>, <span class="string">'Michael'</span>: <span class="number">95</span>, <span class="string">'Tracy'</span>: <span class="string">'hello'</span>&#125;</span><br><span class="line"><span class="literal">False</span></span><br><span class="line">[(<span class="string">'Bob'</span>, <span class="number">75</span>), (<span class="string">'Michael'</span>, <span class="number">95</span>), (<span class="string">'Tracy'</span>, <span class="string">'hello'</span>)]</span><br><span class="line">[<span class="string">'Bob'</span>, <span class="string">'Michael'</span>, <span class="string">'Tracy'</span>]</span><br><span class="line">[<span class="number">75</span>, <span class="number">95</span>, <span class="string">'hello'</span>]</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>Set常用操作</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Set测试</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># 新建一个set  set会自动删除重复的元素</span></span><br><span class="line">set1 = set([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>])</span><br><span class="line"><span class="keyword">print</span> (set1)</span><br><span class="line"><span class="comment"># 向set中添加元素</span></span><br><span class="line">set1.add(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">print</span> (set1)</span><br><span class="line"><span class="comment"># set不能直接删除元素 需要将set转换为list修改以后再转为set</span></span><br><span class="line">l = list(set1)</span><br><span class="line">l[<span class="number">1</span>] = <span class="number">100</span></span><br><span class="line">set2 = set(l)</span><br><span class="line"><span class="keyword">print</span> (set2)</span><br><span class="line"><span class="comment"># 删除元素</span></span><br><span class="line">set1.remove(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">print</span> (set1)</span><br><span class="line"><span class="comment"># 清空元素</span></span><br><span class="line">set1.clear()</span><br><span class="line"><span class="keyword">print</span> (set1)</span><br><span class="line"></span><br><span class="line">E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/SetTest.py</span><br><span class="line">set([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">set([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">set([<span class="number">1</span>, <span class="number">3</span>, <span class="number">100</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line">set([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">set([])</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>循环语句</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">循环的测试</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># for循环</span></span><br><span class="line">l = [<span class="string">'ok'</span>, <span class="string">'yes'</span>, <span class="string">'no'</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> l:</span><br><span class="line">    print(i)</span><br><span class="line">d = &#123;<span class="string">'Michael'</span>: <span class="number">95</span>, <span class="string">'Bob'</span>: <span class="number">75</span>, <span class="string">'Tracy'</span>: <span class="string">'hello'</span>&#125;</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> d.items():</span><br><span class="line">    <span class="keyword">print</span> (k,v)</span><br><span class="line"></span><br><span class="line"><span class="comment"># while 循环</span></span><br><span class="line">sum = <span class="number">0</span></span><br><span class="line">n = <span class="number">10</span></span><br><span class="line"><span class="keyword">while</span> n&gt;<span class="number">0</span> :</span><br><span class="line">    sum+=n</span><br><span class="line">    n-=<span class="number">1</span></span><br><span class="line"><span class="keyword">print</span> (sum)</span><br><span class="line"></span><br><span class="line">E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/XunHuanTest.py</span><br><span class="line">ok</span><br><span class="line">yes</span><br><span class="line">no</span><br><span class="line">(<span class="string">'Bob'</span>, <span class="number">75</span>)</span><br><span class="line">(<span class="string">'Michael'</span>, <span class="number">95</span>)</span><br><span class="line">(<span class="string">'Tracy'</span>, <span class="string">'hello'</span>)</span><br><span class="line"><span class="number">55</span></span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>判断语句</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">判断测试</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">age = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> age &gt; <span class="number">18</span> :</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"已经成年了"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> age &gt;= <span class="number">18</span> :</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"已经成年了"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"还未成年"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> age &lt; <span class="number">18</span> :</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"还未成年"</span>)</span><br><span class="line"><span class="keyword">elif</span> age &lt; <span class="number">40</span> :</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"还年轻"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"老了"</span>)</span><br><span class="line">    </span><br><span class="line">E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/IfElseTest.py</span><br><span class="line">已经成年了</span><br><span class="line">已经成年了</span><br><span class="line">还年轻</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>函数</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数的使用</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">1：使用def定义函数</span></span><br><span class="line"><span class="string">2：指定函数名称</span></span><br><span class="line"><span class="string">3：指定函数参数(如果有的情况下)</span></span><br><span class="line"><span class="string">4：指定函数体的执行逻辑</span></span><br><span class="line"><span class="string">5：return返回值(如果需要返回的情况)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># 一般函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(x)</span>:</span></span><br><span class="line">    x += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">res = fun(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">print</span> (res)</span><br><span class="line"><span class="comment"># 空函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun2</span> <span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 多返回值函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">funs</span><span class="params">(y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> y, y+<span class="number">1</span></span><br><span class="line"><span class="comment"># 含有默认参数值的参数，如果不传入参数的话就会按默认值</span></span><br><span class="line"><span class="comment"># 后面不可以跟不带默认参数值的参数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">defalut</span><span class="params">(x=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"><span class="comment"># 在参数前面加*表示该参数为可变参数，他需要放在最后一个</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun5</span><span class="params">(y,*x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span>  x,y</span><br><span class="line">res2  = fun5(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line"><span class="keyword">print</span> (res2)</span><br><span class="line"></span><br><span class="line">E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/DefTest.py</span><br><span class="line"><span class="number">2</span></span><br><span class="line">((<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>异常处理</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">异常处理</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"打开链接"</span>)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"业务代码1"</span>)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"业务代码2"</span>)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"提交任务"</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"exception %s"</span>%e)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"关闭链接"</span>)</span><br><span class="line"><span class="comment"># Python脚本执行的入口 相当于Java中的main函数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    fun()</span><br><span class="line"> </span><br><span class="line">E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/ExceptionTest.py</span><br><span class="line">打开链接</span><br><span class="line">业务代码<span class="number">1</span></span><br><span class="line">业务代码<span class="number">2</span></span><br><span class="line">提交任务</span><br><span class="line">关闭链接</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>切片【List、tuple】</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">切片功能</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">()</span>:</span></span><br><span class="line">    li = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">    <span class="comment"># 指定索引左闭右开</span></span><br><span class="line">    print(li[<span class="number">2</span>:<span class="number">5</span>])</span><br><span class="line">    <span class="comment"># 不指定索引 切开所有数据</span></span><br><span class="line">    print(li[::])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    func()</span><br><span class="line"></span><br><span class="line">E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/QiePian.py</span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>迭代【List、tuple、dict、set】</p><ul><li>即for循环迭代取值代码参考循环中的for循环</li></ul></li><li><p>面向对象</p><ul><li><p>创建类 </p></li><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">创建一个Person的实体类</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>:</span></span><br><span class="line">    <span class="comment"># 定义一个name属性</span></span><br><span class="line">    name = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,_name)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        构造函数</span></span><br><span class="line"><span class="string">        :param _name:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.name = _name</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"hello %s"</span>%self.name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 实例化 不需要new</span></span><br><span class="line">    p = Person(<span class="string">"zs"</span>)</span><br><span class="line">    p.hello()</span><br><span class="line">    </span><br><span class="line"> E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/Person.py</span><br><span class="line">hello zs</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>Python模块</p><ul><li>Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。模块让你能够有逻辑地组织你的 Python 代码段，把相关的代码分配到一个模块里能让你的代码更好用，更易懂，模块能定义函数，类和变量，模块里也能包含可执行的代码。</li><li>Python本身就内置了很多很好用的模块，只要正常安装，这些模块就可以正常使用</li><li>在Python中有很多第三方的模块，通过管理工具pip使用</li><li>一般来说，第三方库都会在Python官方的pypi.python.org网站注册，要安装一个第三方库需要知道库的名称，就可以在官网搜索。类似于Java中的maven</li><li>本地模块的引用<ul><li>引用其他包里的类</li><li>首先被引用的包里必须有<strong>init</strong>.py文件</li><li>然后使用指令 import 包地址 as 别名</li><li>也可以使用 from 包地址 import 需要使用的方法</li><li>注意：当一个文件被引用的时候会进行一次编译，生成一个.pyc的文件，主要是为了加快程序的运行速度</li></ul></li></ul></li><li><p>编译以及反编译</p><ul><li>Python程序，是把原始程序代码放在.py文件里，而Python会在执行.py文件的时候将.py形式的程序编译成中间式文件（byte-compiled）的.pyc文件，这么做的目的就是为了加快下次执行文件的速度。</li><li>所以，在我们运行python文件的时候，就会自动首先查看是否具有.pyc文件，如果有的话，而且.py文件的修改时间和.pyc的修改时间一样，就会读取.pyc文件，否则，Python就会读原来的.py文件。</li><li>其实并不是所有的.py文件在与运行的时候都会产生.pyc文件，只有在import xxx.py文件的时候，才会生成相应的xxx.pyc文件</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python Python简介 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch问题以及调优</title>
      <link href="/2019/07/03/Elasticsearch%E9%97%AE%E9%A2%98%E4%BB%A5%E5%8F%8A%E8%B0%83%E4%BC%98/"/>
      <url>/2019/07/03/Elasticsearch%E9%97%AE%E9%A2%98%E4%BB%A5%E5%8F%8A%E8%B0%83%E4%BC%98/</url>
      
        <content type="html"><![CDATA[<h2 id="Elasticsearch问题以及调优"><a href="#Elasticsearch问题以及调优" class="headerlink" title="Elasticsearch问题以及调优"></a>Elasticsearch问题以及调优</h2><h3 id="Elasticsearch脑裂问题分析"><a href="#Elasticsearch脑裂问题分析" class="headerlink" title="Elasticsearch脑裂问题分析"></a>Elasticsearch脑裂问题分析</h3><ul><li><p>脑裂问题的图解</p><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566822492817.png" alt="1566822492817"></li></ul><a id="more"></a><ul><li>脑裂问题就是在集群环境之中，由于节点之间的通信问题导致节点对集群的状态理解不同，导致es有些查询非常缓慢甚至查询失败</li><li>最好的解决办法就是重启集群，详细的问题分析可以查看我的博客《Elasticsearch脑裂问题详细分析及解决方案》</li></ul></li></ul><h3 id="Elasticsearch索引模板以及索引名"><a href="#Elasticsearch索引模板以及索引名" class="headerlink" title="Elasticsearch索引模板以及索引名"></a>Elasticsearch索引模板以及索引名</h3><h4 id="索引模板index-template"><a href="#索引模板index-template" class="headerlink" title="索引模板index template"></a>索引模板index template</h4><ul><li><p>在我们的工作中，针对一个大批量的数据存储时需要使用多个索引库，如果我们手工去为每个索引库配置信息就很麻烦，所以就有了索引模板，创建一个模板，制定好配置信息，如果我们闯进的索引库匹配到了模板就会使用模板中的配置信息</p></li><li><p>创建模板</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; -XPUT localhost:9200/_template/template_1 -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;template&quot; : &quot;*&quot;,</span><br><span class="line">    &quot;order&quot; : 0,</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">        &quot;type1&quot; : &#123;</span><br><span class="line">            &quot;_source&quot; : &#123; &quot;enabled&quot; : false &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">其中的order值是用来进行模板之间的优先级排序的，如果一个索引匹配到多个模板则比较模板的order值，选取最大order值的模板进行配置信息匹配</span><br></pre></td></tr></table></figure></li></ul></li><li><p>查看模板信息  curl -XGET localhost:9200/_template/temp*?pretty</p></li><li><p>删除模板  curl -XDELETE localhost:9200/_template/temp_1</p></li></ul><h4 id="索引别名index-alias"><a href="#索引别名index-alias" class="headerlink" title="索引别名index alias"></a>索引别名index alias</h4><ul><li><p>索引别名就是为索引起一个或者多个别名方便引用</p></li><li><p>公司使用es收集应用的日志，每个星期创建一个索引库，这样时间长了就会创建很多个索引库，操作和管理非常不方便</p></li><li><p>由于新增的索引只会操作最新的这一周的索引库，所以我们就可以创建两个别名</p></li><li><p>curr_week :此别名执行这个星期的索引库，新增的数据操作这个索引库</p></li><li><p>last_3_month:这个别名指向的是近三个月的索引库，因为我们需要查询近三个月的数据</p></li><li><p>后期只需要修改两个别名与索引库的指向关系即可，应用层的代码不许要更新、</p></li><li><p>还需要将三个月之前的索引库close掉，将一年前的索引库删除</p></li><li><p>es默认对查询分片的数量是有限制的，默认是1000个，使用通配符查询多个索引库的时候会出问题，正好可以使用别名解决</p></li><li><p>增加索引别名  可同时增减多个</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; -XPOST &apos;http://localhost:9200/_aliases&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;test1&quot;, &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;,</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;test2&quot;, &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;</span><br><span class="line"></span><br><span class="line">    ]</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>删除索引别名</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; -XPOST &apos;http://localhost:9200/_aliases&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;remove&quot; : &#123; &quot;index&quot; : &quot;test1&quot;, &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="Elasticsearch参数调优"><a href="#Elasticsearch参数调优" class="headerlink" title="Elasticsearch参数调优"></a>Elasticsearch参数调优</h3><ul><li><p>解决es启动警告信息</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/security/limits.conf</span><br><span class="line">增加以下内容</span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* hard nproc 4096</span><br><span class="line">vi /etc/security/limits.d/90-nproc.conf </span><br><span class="line">把1024修改为4096</span><br><span class="line">*          soft    nproc     4096</span><br></pre></td></tr></table></figure></li></ul></li><li><p>修改配置文件调整es的jvm内存大小</p><ul><li>修改bin/elasticsearch.in.sh中ES_MIN_MEM和ES_MAX_MEM的大小，建议设置一样大，避免频繁的分配内存，根据服务器内存大小，一般分配60%左右(默认256M)</li><li>注意内存最大不要超过32G 一旦你越过这个神奇的32GB边界，指针会切换回普通对象指针.。每个指针的大小增加，使用更多的CPU内存带宽。事实上，你使用40~50G的内存和使用32G的内存效果是一样的。</li></ul></li><li><p>设置memory_lock来锁定进程的物理内存地址</p><ul><li><p>避免交换（swapped）来提高性能</p><p>修改文件conf/elasticsearch.yml</p><p>bootstrap.memory_lock: true</p><p>需要根据es启动日志修改/etc/security/limits.conf文件(重启系统)</p></li></ul></li><li><p>改变分片的数量</p><ul><li>分片多的话，可以提升建立索引的能力，5-20个比较合适。</li><li>如果分片的数量过多或者过少都会导致检索比较慢</li><li>分片过多会导致查询的额时候打开较多的文件，而分片数过少会导至单个分片索引过大，所以检索速度也会慢。</li><li>建议单个分片存储20G左右的索引数据【最高也不要超过50G，否则性能会很差】，所以，分片数量=数据总量/20G</li><li>副本多的话，可以提升搜索的能力，但是如果设置很多副本的话也会对服务器造成额外的压力，因为主分片需要给所有副本同步数据。所以建议最多设置1-2个即可。</li></ul></li><li><p>针对不使用的index，建议close，减少内存占用。因为只要索引处于open状态，索引库中的segement就会占用内存，close之后就只会占用磁盘空间了。</p><ul><li>curl -XPOST ‘localhost:9200/test/_close’</li></ul></li><li><p>要定时对索引进行合并优化，不然segment越多，占用的segment memory越多，查询的性能也越差</p><ul><li><p>索引量不是很大的话可以将segment设为1</p></li><li><p>在es2.1.0以前调用_optimize接口，后期改为_forcemerge接口</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;http://localhost:9200/test/_forcemerge?max_num_segments=1&apos;</span><br><span class="line">client.admin().indices().prepareForceMerge(&quot;test&quot;).setMaxNumSegments(1).get();</span><br><span class="line">注意：索引合并是针对分片的。segment设置为1，则每个分片都有一个索引片段。</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p>删除文档：在es中删除文档，数据不会马上在硬盘上除去，而是在es索引中产生一个.del的文件，而在检索过程中这部分数据也会参与检索，es在检索过程会判断是否删除了，如果删除了在过滤掉。这样也会降低检索效率。所以可以执行清除删除文档</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">shell:</span><br><span class="line">curl -XPOST &apos;http://localhost:9200/test/_forcemerge?only_expunge_deletes=true&apos;</span><br><span class="line">java:</span><br><span class="line">client.admin().indices().prepareForceMerge(&quot;test&quot;).setOnlyExpungeDeletes(true).get();</span><br></pre></td></tr></table></figure></li></ul></li><li><p>如果在项目开始的时候需要批量入库大量数据的话，建议将副本数设置为0</p><ul><li>因为es在索引数据的时候，如果有副本存在，数据也会马上同步到副本中，这样会对es增加压力。可以等索引完成后将副本按需要改回来。这样可以提高索引效率</li></ul></li><li><p>Elasticsearch在建立索引时，根据id或(id,类型)进行hash，得到hash值之后再与该索引的分片数量取模，取模的值即为存入的分片编号</p><ul><li><p>可以指定把数据存储到某一个分片中，通过routing参数  可以显著提高性能</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/yehua/emp?routing=rout_param&apos; -d &apos;&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:20&#125;&apos;</span><br><span class="line">routing(路由参数)</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 调优 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch调优 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch脑裂问题详细分析以及解决方案</title>
      <link href="/2019/07/02/Elasticsearch%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/2019/07/02/Elasticsearch%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<h2 id="Elasticsearch脑裂问题详细分析以及解决方案"><a href="#Elasticsearch脑裂问题详细分析以及解决方案" class="headerlink" title="Elasticsearch脑裂问题详细分析以及解决方案"></a>Elasticsearch脑裂问题详细分析以及解决方案</h2><h3 id="什么是脑裂问题"><a href="#什么是脑裂问题" class="headerlink" title="什么是脑裂问题"></a>什么是脑裂问题</h3><ul><li>脑裂问题其实就是同一个集群的不同节点对于整个几位群的状态有不同的理解，导致操作错乱，类似于精神分裂</li></ul><h3 id="怎么发现集群产生脑裂问题"><a href="#怎么发现集群产生脑裂问题" class="headerlink" title="怎么发现集群产生脑裂问题"></a>怎么发现集群产生脑裂问题</h3><a id="more"></a><ul><li>Elasticsearch出现查询非常缓慢的情况</li><li>通过命令查看集群的状态<ul><li>curl -XGET ‘<a href="http://localhost:9200/_cluster/health&#39;" target="_blank" rel="noopener">http://localhost:9200/_cluster/health&#39;</a></li></ul></li><li>发现集群状态为red，且集群数量明显错误，再向不同的节点查询集群状态的时候，总体状态都是red，但是返回的集群数量却不太一样</li><li>正常情况下，访问每一个节点，对集群中的状态返回应该是一致的。不一致的信息表示集群中不同节点对master节点的选择出现了问题。导致集群不能正常工作</li></ul><h3 id="产生脑裂问题的原因"><a href="#产生脑裂问题的原因" class="headerlink" title="产生脑裂问题的原因"></a>产生脑裂问题的原因</h3><ul><li>网络<ul><li>由于某些节点之间的网络通信出现问题，导致一些节点认为master节点已经挂了，所以有重新选举了新的master节点，从而导致集群信息混乱，可以检查Ganglia集群监控，来查看是否是网络原因</li></ul></li><li>节点负载过大：由于master节点与data节点都是混在一起的，有可能master节点的负载过大，导致对应的es实例停止响应，这时一部分节点会一位master节点已经挂掉从而重新选举，导致多master节点运行。同时由于data节点上ES进程占用的内存较大，较大规模的内存回收操作也能造成ES进程失去响应。所以，这个原因的可能性应该是最大的。</li></ul><h3 id="如何解决脑裂问题"><a href="#如何解决脑裂问题" class="headerlink" title="如何解决脑裂问题"></a>如何解决脑裂问题</h3><ul><li><p>对于网络问题，只能进行网络修复，在重启集群</p></li><li><p>对于负载的问题</p><ul><li><p>一个直观的解决方案就是将master节点与data节点分离，准备几台机器加入集群中，这几台机器只能充当master节点，不可担任存储和搜索的角色</p><ul><li><p>配置信息</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">node.master: true</span><br><span class="line">node.data: false</span><br><span class="line">其他节点  只能充当data不能充当master</span><br><span class="line">node.master: false</span><br><span class="line">node.data: true</span><br></pre></td></tr></table></figure></li></ul></li><li><p>还有两个参数的修改可以减少脑裂问题的出现</p><ul><li>discovery.zen.ping_timeout（默认值是3秒）：默认情况下，一个节点会认为，如果master节点在3秒之内没有应答，那么这个节点就是死掉了，而增加这个值，会增加节点等待响应的时间，从一定程度上会减少误判。</li><li>discovery.zen.minimum_master_nodes（默认是1）：这个参数控制的是，一个节点需要看到的具有master节点资格的最小数量，然后才能在集群中做操作。官方的推荐值是(N/2)+1，其中N是具有master资格的节点的数量</li></ul></li><li><p>如果脑裂问题已经发生该如何解决</p><ul><li>当脑裂发生后，唯一的修复办法是解决这个问题并重启集群。 当elasticsearch集群启动时，会选出一个主节点（一般是启动的第一个节点被选为主）。由于索引的两份拷贝已经不一样了，elasticsearch会认为选出来的主保留的分片是“主拷贝”并将这份拷贝推送给集群中的其他节点。这很严重。让我们设想下你是用的是node客户端并且一个节点保留了索引中的正确数据。但如果是另外的一个节点先启动并被选为主，它会将一份过期的索引数据推送给另一个节点，覆盖它，导致丢失了有效数据。</li><li>所以怎么从脑裂中恢复？第一个建议是给所有数据重新索引。第二，如果脑裂发生了，要十分小心的重启你的集群。停掉所有节点并决定哪一个节点第一个启动。 如果需要，单独启动每个节点并分析它保存的数据。如果不是有效的，关掉它，并删除它数据目录的内容（删前先做个备份）。如果你找到了你想要保存数据的节点，启动它并且检查日志确保它被选为主节点。这之后你可以安全的启动你集群里的其他节点了。</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 问题分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch脑裂问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch高级</title>
      <link href="/2019/07/01/Elasticsearch%E9%AB%98%E7%BA%A7%E4%BA%8C/"/>
      <url>/2019/07/01/Elasticsearch%E9%AB%98%E7%BA%A7%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="Elasticsearch高级二"><a href="#Elasticsearch高级二" class="headerlink" title="Elasticsearch高级二"></a>Elasticsearch高级二</h2><h3 id="Elasticsearch查询详解"><a href="#Elasticsearch查询详解" class="headerlink" title="Elasticsearch查询详解"></a>Elasticsearch查询详解</h3><h4 id="查询Query"><a href="#查询Query" class="headerlink" title="查询Query"></a>查询Query</h4><a id="more"></a><ul><li><p>代码</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public class EsDemo2 &#123;</span><br><span class="line">    static String index = &quot;test&quot;;</span><br><span class="line">    static String type = &quot;emp&quot;;</span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        Settings settings = Settings.builder()</span><br><span class="line">                .put(&quot;cluster.name&quot;, &quot;elasticsearch&quot;)</span><br><span class="line">                .put(&quot;client.transport.sniff&quot;, true)</span><br><span class="line">                .build();</span><br><span class="line">        TransportClient client = new PreBuiltTransportClient(Settings.EMPTY)</span><br><span class="line">                .addTransportAddress(new TransportAddress(InetAddress.getByName(&quot;hadoop110&quot;), 9300));</span><br><span class="line">        testSearch(client);</span><br><span class="line">    &#125;</span><br><span class="line">     public static void testSearch(TransportClient client)&#123;</span><br><span class="line">        SearchResponse searchResponse = client.prepareSearch(index)</span><br><span class="line">                .setQuery(QueryBuilders.&lt; !-- matchAllQuery() 具体的查询方法 -- &gt;)</span><br><span class="line">                .get();</span><br><span class="line">        SearchHits hits = searchResponse.getHits();</span><br><span class="line">        //获取总条数</span><br><span class="line">        long totalHits = hits.getTotalHits();</span><br><span class="line">        System.out.println(&quot;数据的总条数&quot;+totalHits);</span><br><span class="line">        //打印所有数据内容</span><br><span class="line">        SearchHit[] hits1 = hits.getHits();</span><br><span class="line">        for (SearchHit hit:hits1) &#123;</span><br><span class="line">            System.out.println(hit.getSourceAsString());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>matchAllQuery()  查询所有数据</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">结果：</span><br><span class="line">数据的总条数6</span><br><span class="line">&#123;&quot;name&quot;:&quot;jessic&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:15&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:19&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>matchQuery((“name”,”zs”))  根据指定列进行模糊查询 不支持通配符</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">数据的总条数2</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:15&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>multiMatchQuery(“zs”,”name”,”city”)  在多个列中进行模糊查询 查询的列不存在不会报错</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">数据的总条数2</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:15&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>queryStringQuery(“name:z*”) Lucene提供的方法支持对某一列查询的时候使用通配符</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">数据的总条数2</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:15&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>boolQuery()</p><p>.should(QueryBuilders.matchQuery(“name”,”zs”).boost(10.0f))        .should(QueryBuilders.matchQuery(“age”,19).boost(1.0f))</p><p>根据不同的条件进行多次查询  可以根据boost值来设置两条语句的结果先后顺序</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">数据的总条数4</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:15&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:19&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>termQuery(“name”,”abc xyz”)  查询的时候不会进行分词的精确查询</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">数据的总条数0</span><br></pre></td></tr></table></figure></li><li><p>在默认情况之下es会将所有词进行分词索引，这是你试试用及精确查询时查不到的</p></li><li><p>解决方案</p><ul><li><p>在创建索引的时候将不需要进行分词的特殊索引指定不分词</p></li><li><p>根据Lucene提供的方法直接查询可以对已经分词的索引进行精确查询</p></li><li><p>queryStringQuery(“name:&quot;abc xyz&quot;“)</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">数据的总条数1</span><br><span class="line">&#123;&quot;name&quot;:&quot;abc xyz&quot;,&quot;age&quot;:15&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p>matchQuery(“name”,”abc xyz”).operator(Operator.AND)  也可以对已经分词的索引进行精确查询</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">数据的总条数1</span><br><span class="line">&#123;&quot;name&quot;:&quot;abc xyz&quot;,&quot;age&quot;:15&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="其他查询"><a href="#其他查询" class="headerlink" title="其他查询"></a>其他查询</h4><ul><li><p>from、size  分页</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.setFrom(2)</span><br><span class="line">.setSize(3)</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;abc xyz&quot;,&quot;age&quot;:15&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>sort 排序</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.setQuery(QueryBuilders.matchAllQuery()) //取出所有数据</span><br><span class="line">.addSort(&quot;age&quot;, SortOrder.DESC)  //按照年龄降序排序</span><br><span class="line"></span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jessic&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;abc xyz&quot;,&quot;age&quot;:15&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>filter 过滤</p><ul><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.setPostFilter(QueryBuilders.rangeQuery(<span class="string">"age"</span>).from(<span class="string">"16"</span>).to(<span class="number">20</span>))</span><br><span class="line">    过滤出来年龄在<span class="number">16</span>到<span class="number">20</span>之间的</span><br><span class="line">&#123;<span class="string">"name"</span>:<span class="string">"jessic"</span>,<span class="string">"age"</span>:<span class="number">18</span>&#125;</span><br><span class="line">&#123;<span class="string">"name"</span>:<span class="string">"zs"</span>,<span class="string">"age"</span>:<span class="number">16</span>&#125;</span><br><span class="line">&#123;<span class="string">"name"</span>:<span class="string">"jack"</span>,<span class="string">"age"</span>:<span class="number">19</span>&#125;</span><br><span class="line">&#123;<span class="string">"name"</span>:<span class="string">"lili"</span>,<span class="string">"age"</span>:<span class="number">16</span>&#125;</span><br><span class="line">&#123;<span class="string">"name"</span>:<span class="string">"tom"</span>,<span class="string">"age"</span>:<span class="number">19</span>&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>highlight  高亮  将搜索出的结果加上高亮的效果</p></li><li><p>按查询匹配度排序</p><ul><li>.setExplain(true)</li></ul></li></ul><h4 id="两个简单练习"><a href="#两个简单练习" class="headerlink" title="两个简单练习"></a>两个简单练习</h4><ul><li><p>聚合分组求count</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">    * 统计测试</span><br><span class="line">    * 聚合分组求count</span><br><span class="line">    */</span><br><span class="line">   public static void testAggregation(TransportClient client)&#123;</span><br><span class="line">       SearchResponse searchResponse = client.prepareSearch(index)</span><br><span class="line">               //.setTypes(type)</span><br><span class="line">               .setQuery(QueryBuilders.matchAllQuery())</span><br><span class="line">               .addAggregation(AggregationBuilders.terms(&quot;term_age&quot;).field(&quot;age&quot;))</span><br><span class="line">               .get();</span><br><span class="line">       Terms term_age = searchResponse.getAggregations().get(&quot;term_age&quot;);</span><br><span class="line">       List&lt;? extends Terms.Bucket&gt; buckets = term_age.getBuckets();</span><br><span class="line">       for (Terms.Bucket bk:buckets) &#123;</span><br><span class="line">           System.out.println(bk.getKey()+&quot;----------&quot;+bk.getDocCount());</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>聚合分组求sum</p><ul><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 统计测试</span></span><br><span class="line"><span class="comment"> * 聚合分组求sum</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testAggregation2</span><span class="params">(TransportClient client)</span></span>&#123;</span><br><span class="line">    SearchResponse searchResponse = client.prepareSearch(index)</span><br><span class="line">            .setQuery(QueryBuilders.matchAllQuery())</span><br><span class="line">            .addAggregation(AggregationBuilders.terms(<span class="string">"term_name"</span>).field(<span class="string">"name.keyword"</span>)  <span class="comment">//name是text类型不支持分组，所以取他的keyword</span></span><br><span class="line">            .subAggregation(AggregationBuilders.sum(<span class="string">"sum_score"</span>).field(<span class="string">"score"</span>)))</span><br><span class="line">            .get();</span><br><span class="line">    Terms term_name = searchResponse.getAggregations().get(<span class="string">"term_name"</span>);</span><br><span class="line">    List&lt;? extends Terms.Bucket&gt; buckets = term_name.getBuckets();</span><br><span class="line">    <span class="keyword">for</span> (Terms.Bucket bk:buckets) &#123;</span><br><span class="line">        Sum sumScore = bk.getAggregations().get(<span class="string">"sum_score"</span>);</span><br><span class="line">        System.out.println(bk.getKey()+<span class="string">"----------"</span>+sumScore.getValue());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="Elasticsearch中的setting以及mapping详解"><a href="#Elasticsearch中的setting以及mapping详解" class="headerlink" title="Elasticsearch中的setting以及mapping详解"></a>Elasticsearch中的setting以及mapping详解</h3><ul><li><p>setting是修改索引库默认的配置</p><ul><li><p>查看页面的setting信息</p><ul><li>curl -XGET <a href="http://localhost:9200/test/_settings?pretty" target="_blank" rel="noopener">http://localhost:9200/test/_settings?pretty</a></li></ul></li><li><p>修改已经存在的索引库信息</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; -XPUT &apos;localhost:9200/test/_settings&apos; -d&apos;&#123;&quot;index&quot;:&#123;&quot;number_of_replicas&quot;:1&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ul><ul><li><p>修改不存在的索引库的信息</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; -XPUT &apos;localhost:9200/test1/&apos; -d&apos;&#123;&quot;settings&quot;:&#123;&quot;number_of_shards&quot;:3,&quot;number_of_replicas&quot;:0&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>mapping 是对索引库中的索引的名称以及数据类型进行定义，类似于MySQL的表名以及表的结构信息。但是es的mapping比较灵活，可以动态识别各字段的信息，一般不需要自定义mapping</p><ul><li><p>查看索引库mapping信息</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET http://localhost:9200/test/emp/_mapping?pretty</span><br></pre></td></tr></table></figure></li></ul></li><li><p>操作已经存在的索引  指定分词器</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; -XPOST http://localhost:9200/test/emp/_mapping -d&apos;&#123;&quot;properties&quot;:&#123;&quot;name&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ul><ul><li><p>操作不存在的索引</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; -XPUT &apos;localhost:9200/test2&apos; -d&apos;&#123;&quot;mappings&quot;:&#123;&quot;emp&quot;:&#123;&quot;properties&quot;:&#123;&quot;name&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;&#125;&#125;&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="Elasticsearch的分片查询方式"><a href="#Elasticsearch的分片查询方式" class="headerlink" title="Elasticsearch的分片查询方式"></a>Elasticsearch的分片查询方式</h3><ul><li>默认的是randomize across shards   表示随机选取，即随机从分片中取数据</li><li>_local :表示执行查询操作的时候回优先在本地节点中的分片中进行查询，没有的话在去其他节点</li><li>_only_local:表示只在本地分片中查询</li><li>_primary:表示只在主分片中查询</li><li>_primary_first:表示优先在主分片中查询，如果主分片出现问题数据丢失或者其他就会去副分片中查询</li><li>_replica_first:表示优先在副分片上查询，有问题了再去主分片查询</li><li>_only_node:在指定ID的节点上查询，只有该节点上有相关分片就回进行查询，可能导致查询结果不够完整</li><li>_only_nodes:指定ID的节点是多个</li><li>_prefer_node:优先在指定ID的节点查询 查不到再去其他节点</li><li>_shards:查询指定分片的信息 可以实现急速查询  但需要指定索引所在分片的信息</li></ul>]]></content>
      
      
      <categories>
          
          <category> 提高 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ELK的简单部署以及使用</title>
      <link href="/2019/06/06/ELK%E7%AE%80%E5%8D%95%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
      <url>/2019/06/06/ELK%E7%AE%80%E5%8D%95%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="ELK简单部署以及使用"><a href="#ELK简单部署以及使用" class="headerlink" title="ELK简单部署以及使用"></a>ELK简单部署以及使用</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><ul><li>此项目是使用filebeat轻量化日志采集工具，将日志采集到kafka，在使用logstash工具将日志采集到Elasticsearch中，使用kibana工具在web界面上进行各种搜索查看建立图标等操作。默认kafka以及Elasticsearch已经装好了。</li></ul><a id="more"></a><h3 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h3><ul><li>进入到官网<a href="https://www.elastic.co/" target="_blank" rel="noopener">https://www.elastic.co</a><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566796617980.png" alt="1566796617980"></li></ul></li><li>找到产品<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566796654407.png" alt="1566796654407"></li></ul></li><li>点击下载<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566796697107.png" alt="1566796697107"></li></ul></li><li>选择需要下载的工具点击下载<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566796751070.png" alt="1566796751070"></li><li>在past releases中可以选择其他版本点击下载就可以</li></ul></li><li>下载好安装包以后进行解压、配置环境变量</li></ul><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><ul><li><p>filebeat变量配置</p><ul><li><p>首先进入到filebeat解压后的文件中</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd filebeat-6.4.3-linux-x86_64</span><br></pre></td></tr></table></figure></li></ul></li><li><p>修改filebeat.yml中的配置</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi filebeat.yml</span><br></pre></td></tr></table></figure></li></ul></li><li><p>修改成以下值</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">filebeat.inputs:</span><br><span class="line">- type: log</span><br><span class="line">enabled: true</span><br><span class="line"> paths:</span><br><span class="line">    - /data/filebeattest/logs/*.log  //需要采集的日志地址</span><br><span class="line">output.kafka:</span><br><span class="line">  hosts: [&quot;hadoop110:9092&quot;]   //kafka的地址 如果使用hadoop这种类型的名字需要在本节点上配置 hosts文件</span><br><span class="line">  topic: &apos;filelog&apos;   //kafka中的topic</span><br><span class="line">  partition.round_robin:</span><br><span class="line">    reachable_only: false</span><br><span class="line"></span><br><span class="line">  required_acks: 1</span><br><span class="line">  compression: gzip</span><br><span class="line">  max_message_bytes: 1000000</span><br></pre></td></tr></table></figure></li></ul></li><li><p>启动filebeat的指令</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filebeat -c filebeat.yml</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p>logstash变量配置</p><ul><li><p>进入到logstash的解压文件中</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd logstash-6.4.3</span><br></pre></td></tr></table></figure></li></ul></li><li><p>创建一个配置文件的文件夹conf 并在文件夹里创建一个配置文件kafka-elasticsearch.conf</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir conf</span><br><span class="line">cd conf</span><br><span class="line">touch kafka-elasticsearch.conf</span><br></pre></td></tr></table></figure></li></ul></li><li><p>给配置文件加上配置信息</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vi kafka-elasticsearch.conf</span><br><span class="line">input &#123;</span><br><span class="line">  kafka &#123;</span><br><span class="line">     topics =&gt; [&quot;filelog&quot;]</span><br><span class="line">     bootstrap_servers =&gt; &quot;hadoop110:9092&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line"></span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">       hosts =&gt; [&quot;hadoop110:9200&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>启动logstash</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logstash  -f  conf/kafka-elasticsearch.conf</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p>配置kibana</p><ul><li><p>进入到kibana的解压文件中</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd kibana-6.4.3-linux-x86_64</span><br></pre></td></tr></table></figure></li></ul></li><li><p>修改一些需要的变量配置</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd confog</span><br><span class="line">vi kibana.yml</span><br><span class="line">server.port: 5601</span><br><span class="line">elasticsearch.url: &quot;http://hadoop110:9200&quot;</span><br><span class="line">根据实际需要修改</span><br></pre></td></tr></table></figure></li></ul></li><li><p>启动kibana</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kibana</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ul><h3 id="启动检查效果"><a href="#启动检查效果" class="headerlink" title="启动检查效果"></a>启动检查效果</h3><ul><li>进入到kibana的web界面查看效果<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566799108735.png" alt="1566799108735"></li><li>看到我们创建的索引已经存在了就说明我们的真个过程已经成功了</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch高级</title>
      <link href="/2019/05/11/Elasticsearch%E5%9F%BA%E7%A1%80/"/>
      <url>/2019/05/11/Elasticsearch%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="Elasticsearch高级"><a href="#Elasticsearch高级" class="headerlink" title="Elasticsearch高级"></a>Elasticsearch高级</h2><h3 id="Elasticsearch批量操作的查询类型"><a href="#Elasticsearch批量操作的查询类型" class="headerlink" title="Elasticsearch批量操作的查询类型"></a>Elasticsearch批量操作的查询类型</h3><h5 id="Bulk批量查询的Java实现"><a href="#Bulk批量查询的Java实现" class="headerlink" title="Bulk批量查询的Java实现"></a>Bulk批量查询的Java实现</h5><a id="more"></a><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">package EsTest;</span><br><span class="line"></span><br><span class="line">import org.elasticsearch.action.bulk.BulkItemResponse;</span><br><span class="line">import org.elasticsearch.action.bulk.BulkRequestBuilder;</span><br><span class="line">import org.elasticsearch.action.bulk.BulkResponse;</span><br><span class="line">import org.elasticsearch.action.delete.DeleteRequest;</span><br><span class="line">import org.elasticsearch.action.index.IndexRequest;</span><br><span class="line">import org.elasticsearch.client.transport.TransportClient;</span><br><span class="line">import org.elasticsearch.common.settings.Settings;</span><br><span class="line">import org.elasticsearch.common.transport.TransportAddress;</span><br><span class="line">import org.elasticsearch.transport.client.PreBuiltTransportClient;</span><br><span class="line"></span><br><span class="line">import java.net.InetAddress;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Es简单操作测试</span><br><span class="line"> */</span><br><span class="line">public class EsDemo2 &#123;</span><br><span class="line">    static String index = &quot;test&quot;;</span><br><span class="line">    static String type = &quot;emp&quot;;</span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        Settings settings = Settings.builder()</span><br><span class="line">                .put(&quot;cluster.name&quot;, &quot;elasticsearch&quot;)</span><br><span class="line">                .put(&quot;client.transport.sniff&quot;, true)</span><br><span class="line">                .build();</span><br><span class="line">        TransportClient client = new PreBuiltTransportClient(Settings.EMPTY)</span><br><span class="line">                .addTransportAddress(new TransportAddress(InetAddress.getByName(&quot;hadoop110&quot;), 9300));</span><br><span class="line">        testBulk(client);</span><br><span class="line">    &#125;</span><br><span class="line">    /**</span><br><span class="line">     * bulk批量查询测试</span><br><span class="line">     */</span><br><span class="line">    public static  void testBulk(TransportClient client)&#123;</span><br><span class="line">        BulkRequestBuilder bulkRequestBuilder = client.prepareBulk();</span><br><span class="line">        //创建请求</span><br><span class="line">        IndexRequest indexRequest = new IndexRequest(index, type)</span><br><span class="line">                                    .source(&quot;&#123;\&quot;name\&quot;:\&quot;zs1\&quot;,\&quot;age\&quot;:25&#125;&quot;);</span><br><span class="line">        //删除请求</span><br><span class="line">        DeleteRequest deleteRequest = new DeleteRequest(index, type, &quot;21&quot;,,XContentType.JSON);</span><br><span class="line">        //将操作整合到buider中</span><br><span class="line">        bulkRequestBuilder.add(indexRequest);</span><br><span class="line">        bulkRequestBuilder.add(deleteRequest);</span><br><span class="line">        //执行批量操作</span><br><span class="line">        BulkResponse bulkItemResponses = bulkRequestBuilder.get();</span><br><span class="line">        //查看执行过程中失败的信息</span><br><span class="line">        if(bulkItemResponses.hasFailures())&#123;</span><br><span class="line">            BulkItemResponse[] items = bulkItemResponses.getItems();</span><br><span class="line">            for (BulkItemResponse item: items) &#123;</span><br><span class="line">                System.out.println(item.getFailureMessage());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;else &#123;</span><br><span class="line">            System.out.println(&quot;所有bulk指令都执行成功了&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="SearchType的详解"><a href="#SearchType的详解" class="headerlink" title="SearchType的详解"></a>SearchType的详解</h4><ul><li><p>query and fetch :当客户机向es集群中的某一个节点发送请求时，这个节点会将请求复制到每一个节点上，然后每一个节点会将所请求的数据返回到查询节点上，然后由查询节点返回到客户机上，这样的优点就是速度快，缺点是不准确，客户想要10条数据，集群返回的是10*n条数据，n是集群的节点数</p></li><li><p>query then fetch:当客户机向集群发送请求时，集群中接收请求的节点也会将查询请求发送到每一个节点之上，但是每个节点只返回查询结果的ID等值给主节点，主节点将受到的数据在进行排序取出所需要的条数，然后根据其ID等到相应节点上取的数据，在将数据返回至客户机。优点是可以准确返回需要条数的请求，且结果相对来说准确，缺点是查询速度慢，是es的默认查询类型</p></li><li><p>DFS D是Distributed，F是frequency的缩写，S是Scatter的缩写，整个单词可能是分布式词频率和文档频率散发的缩写</p><ul><li>dfs简称是初始化散发</li><li>官方解释是初始化散发其实就是在进行真正的查询之前，先把各个分片的词频率和文档频率收集一下，然后进行词搜索的时候，各分片依据全局的词频率和文档频率进行搜索和排名。</li><li>通俗一点来说就是统计所有节点的搜索排名的算法，总结到一起可以对整个文档进行精确的算法排名</li></ul></li><li><p>dfs query and fetch：就是加了dfs的query and fetch依然是速度快，但是结果条数多</p></li><li><p>dfs query then fetch:执行过程：首先，从各个节点的搜索排序算法即词频率文档频率等，然后根据整合好的算法在每个节点上取出相应数据的ID等信息，在主节点上再次通过该算法获取准确的数据信息，在通过他们的ID等信息去各个节点获取具体数据返回至客户机上。优点是查询准确率高，但是查询速度慢</p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566654050267.png" alt="1566654050267"></p></li><li><p>代码写法</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Es简单操作测试</span><br><span class="line"> */</span><br><span class="line">public class EsDemo2 &#123;</span><br><span class="line">    static String index = &quot;test&quot;;</span><br><span class="line">    static String type = &quot;emp&quot;;</span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        Settings settings = Settings.builder()</span><br><span class="line">                .put(&quot;cluster.name&quot;, &quot;elasticsearch&quot;)</span><br><span class="line">                .put(&quot;client.transport.sniff&quot;, true)</span><br><span class="line">                .build();</span><br><span class="line">        TransportClient client = new PreBuiltTransportClient(Settings.EMPTY)</span><br><span class="line">                .addTransportAddress(new TransportAddress(InetAddress.getByName(&quot;hadoop110&quot;), 9300));</span><br><span class="line">        //testBulk(client);</span><br><span class="line">        testSeType(client);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 查询类型的测试</span><br><span class="line">     */</span><br><span class="line">    public  static void testSeType(TransportClient client)&#123;</span><br><span class="line">        SearchResponse searchResponse = client.prepareSearch(index)  //索引库信息</span><br><span class="line">                .setQuery(QueryBuilders.matchAllQuery())  //查询规则 所有队列</span><br><span class="line">                .setPreference(&quot;_shards:1&quot;)  //指点分片</span><br><span class="line">                .setSearchType(SearchType.QUERY_THEN_FETCH)  //类型可以自己指定</span><br><span class="line">                .get();</span><br><span class="line">        SearchHits hits = searchResponse.getHits();</span><br><span class="line">        //获取总条数</span><br><span class="line">        long totalHits = hits.getTotalHits();</span><br><span class="line">        System.out.println(&quot;数据的总条数&quot;+totalHits);</span><br><span class="line">        //打印所有数据内容</span><br><span class="line">        SearchHit[] hits1 = hits.getHits();</span><br><span class="line">        for (SearchHit hit:hits1) &#123;</span><br><span class="line">            System.out.println(hit.getSourceAsString());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="Elasticsearch分词详解"><a href="#Elasticsearch分词详解" class="headerlink" title="Elasticsearch分词详解"></a>Elasticsearch分词详解</h3><h4 id="es索引建立和搜索过程图解"><a href="#es索引建立和搜索过程图解" class="headerlink" title="es索引建立和搜索过程图解"></a>es索引建立和搜索过程图解</h4><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566654133368.png" alt="sss"></li></ul><h4 id="倒排索引介绍"><a href="#倒排索引介绍" class="headerlink" title="倒排索引介绍"></a>倒排索引介绍</h4><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566654223385.png" alt="1566654223385"></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566654235494.png" alt="1566654235494"></li><li>表中的各个单词表示文档意思<ul><li>单词ID：记录每个单词的编号</li><li>单词：单词ID对应的单词</li><li>文档频率：单词在几个文档中出现过</li><li>倒排列表：单词出现的文档信息以及单词出现位置信息</li><li>DocID：单词出现的文档的ID</li><li>TF：单词在该文档出现的次数</li><li>POS：单词在文档中出现的位置</li></ul></li></ul><h4 id="分词器Analyzer的介绍"><a href="#分词器Analyzer的介绍" class="headerlink" title="分词器Analyzer的介绍"></a>分词器Analyzer的介绍</h4><ul><li><p>分词器就是将数据按以此为单位分开</p></li><li><p>分词器的作用</p><ul><li>是吧文本中的词按照一定的规则进行切分。</li><li>分词器所对应的的类是Analyzer是一个抽象类，具体的实现方法要靠他的子类，所以对于不同的语言就可以提供不同的分词器</li><li>在创建索引以及搜索的时候都会用到分词器，而且这两个过程所用到的分析器必须是同一种分词器</li></ul></li><li><p>分词器的工作流程</p><ul><li>切分关键词</li><li>取出停用词</li><li>对于英文字母，将所有字母转换为小写</li></ul></li><li><p>停用词的介绍</p><ul><li>有些词在文本中出现的概率很高但是对于文本所携带的信息并没有什么影响</li><li>英文中的<ul><li>a,an,the,of 等   <ul><li><a href="http://www.ranks.nl/stopwords" target="_blank" rel="noopener">http://www.ranks.nl/stopwords</a></li></ul></li></ul></li><li>中文的<ul><li>的，了，是，着，以及各种标点符号等等<ul><li><a href="http://www.ranks.nl/stopwords/chinese-stopwords" target="_blank" rel="noopener">http://www.ranks.nl/stopwords/chinese-stopwords</a></li></ul></li></ul></li><li>文本经过分词的过程以后，这种停用词一般都会被过滤掉，不会被索引</li><li>如果搜索的词含有停用词一本也会被过滤掉</li><li>过滤掉停用词可以加快建立索引，减小索引库的文件的大小</li></ul></li><li><p>几个重要的分词器介绍</p><ul><li><table><thead><tr><th align="center">分词器</th><th align="center">分词方式</th></tr></thead><tbody><tr><td align="center">StandardAnalyzer</td><td align="center">单词分词器</td></tr><tr><td align="center">ChineseAnalyzer</td><td align="center">单字分词器</td></tr><tr><td align="center">CJKAnalyzer</td><td align="center">二分法分词器</td></tr><tr><td align="center">IKAnalyzer</td><td align="center">词库分词器</td></tr></tbody></table></li><li><p>单字分词以及单词分词的意思是一样的</p><ul><li>“我们是中国人”效果：“我”“们”“是”“中”“国”“人”</li></ul></li><li><p>二分法分词器：按两个字的方式分词</p><ul><li>“我们是中国人”，效果：“我们”、“们是”、“是中”、“中国”、“国人”</li></ul></li><li><p>词库分词器</p><ul><li>按某种算法造词，然后将词存入到词库，把搜索内容匹配到词库的词然后进行拆分。</li></ul></li></ul></li></ul><h3 id="Elasticsearch分词插件介绍以及使用es-ik"><a href="#Elasticsearch分词插件介绍以及使用es-ik" class="headerlink" title="Elasticsearch分词插件介绍以及使用es-ik"></a>Elasticsearch分词插件介绍以及使用es-ik</h3><ul><li>官方默认的分词插件对中文的支持不是很好，所以我们需要采用第三方的词库来进行分词，IK就是一个分成不错的分词工具</li><li>下载地址<ul><li><a href="https://github.com/medcl/elasticsearch-analysis-ik/releases" target="_blank" rel="noopener">https://github.com/medcl/elasticsearch-analysis-ik/releases</a></li></ul></li><li>将下载好的文件放在ES_HOME/plugins/ik目录下解压</li><li>解压后就可以使用</li><li>自己添加词库<ul><li>进入到config文件中</li><li>创建一个自己存放自己词库的文件夹</li><li>在文件夹中创建dic文件将自己的词库内容放到所创建的文件中</li><li>修改IKAnalyzer.cfg.xml文件信息</li><li>将自己创建的词库加进去</li><li>重启es就可以使用自己创建的词库了</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566655870803.png" alt="1566655870803"></li></ul></li><li>实现热词的自动更新不需要重启es<ul><li>在一台服务器上部署一个Tomcat</li><li>在Tomcat中的webapp/ROOT 创建hot.doc热词词库</li><li>通过访问网络端口确定这个热词库可以访问</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566656094187.png" alt="1566656094187"></li><li>修改IK的配置<ul><li><entry key="remote_ext_dict"><a href="http://192.168.80.100:8080/hot.dic" target="_blank" rel="noopener">http://192.168.80.100:8080/hot.dic</a></entry></li></ul></li><li>重启es之后就可以在hot.dic文件中动态添加热词，IK会定时从端口中访问该文件然后进行更新热词</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 提高 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch IK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch Head Plugin</title>
      <link href="/2019/04/02/Elasticsearch%20Head%20Plugin%20%E8%AF%A6%E7%BB%86%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
      <url>/2019/04/02/Elasticsearch%20Head%20Plugin%20%E8%AF%A6%E7%BB%86%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="Elasticsearch-Head-Plugin-详细安装教程"><a href="#Elasticsearch-Head-Plugin-详细安装教程" class="headerlink" title="Elasticsearch Head Plugin 详细安装教程"></a>Elasticsearch Head Plugin 详细安装教程</h2><h4 id="Elasticsearch-Head-Plugin站点插件可以以网页形式展现ES"><a href="#Elasticsearch-Head-Plugin站点插件可以以网页形式展现ES" class="headerlink" title="Elasticsearch Head Plugin站点插件可以以网页形式展现ES"></a>Elasticsearch Head Plugin站点插件可以以网页形式展现ES</h4><a id="more"></a><ul><li><p>注意：这个插件依赖于nodejs,phantomjs所以我们在安装插件之前需要安装nodejs以及grunt</p><ul><li><p>nodejs下载地址<a href="https://nodejs.org/dist/v10.15.3/node-v10.15.3-linux-x64.tar.xz" target="_blank" rel="noopener">https://nodejs.org/dist/v10.15.3/node-v10.15.3-linux-x64.tar.xz</a></p><ul><li>复制此链接就可以直接下或者<a href="https://nodejs.org/dist" target="_blank" rel="noopener">https://nodejs.org/dist</a> 使用这个两节找适合自己的版本</li></ul></li><li><p>因为此文件是.tar.xz，所以需要先使用xz解压在使用tar解压  如果解压xz的命令不存在就需要使用yum进行下载 yum -y install xz</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">解压：</span><br><span class="line">xz -d node-v10.15.3-linux-x64.tar.xz</span><br><span class="line">tar -xvf node-v10.15.3-linux-x64.tar</span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s /data/soft/node-v10.15.3-linux-x64/bin/node  /usr/bin/node</span><br><span class="line">ln -s /data/soft/node-v10.15.3-linux-x64/bin/npm /usr/bin/npm</span><br></pre></td></tr></table></figure></li><li><p>设定nodejs安装软件的dialing服务器</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config set registry https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure></li><li><p>安装grunt</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install -g grunt </span><br><span class="line">npm install -g grunt-cli</span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /data/soft/node-v10.15.3-linux-x64/bin/grunt  /usr/bin/grunt</span><br></pre></td></tr></table></figure></li><li><p>安装phantomjs</p><ul><li>下载地址<a href="http://phantomjs.org/download.html" target="_blank" rel="noopener">http://phantomjs.org/download.html</a></li></ul></li><li><p>解压</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bzip2 -d phantomjs-2.1.1-linux-x86_64.tar.bz2</span><br><span class="line">tar -xvf phantomjs-2.1.1-linux-x86_64.tar</span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /data/soft/phantomjs-2.1.1-linux-x86_64/bin/phantomjs  /usr/bin/phantomjs</span><br></pre></td></tr></table></figure></li><li><p>安装依赖软件</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install wget fontconfig</span><br></pre></td></tr></table></figure></li></ul></li><li><p>安装head插件</p><ul><li><p>下载地址：<a href="https://github.com/mobz/elasticsearch-head/archive/master.zip" target="_blank" rel="noopener">https://github.com/mobz/elasticsearch-head/archive/master.zip</a></p></li><li><p>解压 需要使用unzip命令</p></li><li><p>下载unzip</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y unzip</span><br></pre></td></tr></table></figure></li><li><p>解压</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip elasticsearch-head-master.zip</span><br></pre></td></tr></table></figure></li><li><p>然后cd进入到解压的文件中</p></li><li><p>安装两个插件</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm audit fix</span><br><span class="line">npm audit fix --force</span><br></pre></td></tr></table></figure></li><li><p>执行安装命令安装head</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install</span><br></pre></td></tr></table></figure></li><li><p>启动之前修改Gruntfile.js文件，增加hostname参数</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi Gruntfile.js</span><br><span class="line">options: &#123;</span><br><span class="line">hostname: &apos;hadoop100&apos;,</span><br><span class="line">port: 9101,</span><br><span class="line">base: &apos;.&apos;,</span><br><span class="line">keepalive: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>启动服务</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grunt Server</span><br></pre></td></tr></table></figure></li><li><p>启动服务后还需要修改Elasticsearch中的一些配置</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi config/elasticsearch.yml</span><br><span class="line">http.cors.enabled: true </span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br></pre></td></tr></table></figure></li><li><p>修改完成后重启ES</p></li><li><p>进入网址<a href="http://hadoop100:9101/可以看到以下信息就说明插件安装成功了" target="_blank" rel="noopener">http://hadoop100:9101/可以看到以下信息就说明插件安装成功了</a></p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566465169785.png" alt="1566465169785"></p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 安装部署 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch的安装部署</title>
      <link href="/2019/04/02/2019-04-2-Elasticsearch%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
      <url>/2019/04/02/2019-04-2-Elasticsearch%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<h3 id="Elasticsearch安装部署"><a href="#Elasticsearch安装部署" class="headerlink" title="Elasticsearch安装部署"></a>Elasticsearch安装部署</h3><ol><li>安装JDK版本最好在1.8以上（因为这个比较基础就不详细解释了）</li></ol><a id="more"></a><ol><li><p>下载Elasticsearch </p><ul><li>网址：<a href="https://www.elastic.co/downloads/past-releases/elasticsearch-6-4-3" target="_blank" rel="noopener">https://www.elastic.co/downloads/past-releases/elasticsearch-6-4-3</a></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566399839410.png" alt="1566399839410"></li><li>选择合适的版本下载就可以</li></ul></li><li><p>下载完成以后上传到Linux系统中，解压</p></li><li><p>进入到解压后的文件中尝试进行开启</p><ul><li>bin/elasticsearch （-d 后台运行）</li><li>注意：需要关闭机器的防火墙（service iptables stop）关闭开机自启动（chkconfig iptables off)</li><li>会发现执行报错  就是不可以在root用户下打开，选择一个其他用户就可以了</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566398085045.png" alt="1566398085045"></li></ul></li><li><p>修改配置变量</p><ul><li><p>修改Elasticsearch中config变量 （vi config/elasticsearch.yml)</p></li><li><p>增加两行代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.system_call_filter: false  </span><br><span class="line">network.host: 192.168.32.110   //后面的的IP设置你自己的本地IP就可以</span><br></pre></td></tr></table></figure></li></ul></li></ol><ul><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566398675928.png" alt="1566398675928"></p></li><li><p>修改Linux的配置变量</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/security/limits.conf</span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* hard nproc 4096</span><br><span class="line">vi /etc/sysctl.conf</span><br><span class="line">vm.max_map_count=262144</span><br><span class="line">vi /etc/security/limits.d/90-nproc.conf </span><br><span class="line">把1024修改为4096</span><br><span class="line">*          soft    nproc     4096</span><br></pre></td></tr></table></figure></li><li><p>修改完配置以后重启操作系统在启动就可以啦</p></li><li><p>启动之后出现以下情况</p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566456097622.png" alt="1566456097622"></p></li><li><p>没有报错就表示启动成功了 这时候jps查看进程就可以看到Elasticsearch了</p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566456158512.png" alt="1566456158512"></p></li><li><p>然后可以使用web界面查看 在浏览器输入 <a href="http://yourip:9200" target="_blank" rel="noopener">http://yourip:9200</a>  就可以查看了</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 安装部署 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Storm高级以及优化</title>
      <link href="/2019/04/01/Storm%E9%AB%98%E7%BA%A7/"/>
      <url>/2019/04/01/Storm%E9%AB%98%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<h3 id="Storm高级"><a href="#Storm高级" class="headerlink" title="Storm高级"></a>Storm高级</h3><h4 id="Storm核心之流分组"><a href="#Storm核心之流分组" class="headerlink" title="Storm核心之流分组"></a>Storm核心之流分组</h4><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566219022407.png" alt="1566219022407"></p><h5 id="stream-grouping-分类"><a href="#stream-grouping-分类" class="headerlink" title="stream grouping 分类"></a>stream grouping 分类</h5><a id="more"></a><ul><li>Shuffle Grouping：随机分组。将stream中的tuple缓存后随机发放给所有bolt，可以使每个bolt中的数据量大致相等（可以较好的实现负载均衡）</li><li>Fields Grouping：按字段分组，例如按groupID字段进行分组，将同一个分组的tuple分到统一任务中</li><li>All Grouping:广播发送，每一个tuple都会发送到所有任务中，所以每一个bolt都会有所有的tuple</li><li>Global Grouping：全局分组，这个tuple会被分配到storm中的某一个bolt,具体一点就是分配到ID值最小的一个bolt之中 </li><li>Non Grouping：随机分派，效果和shuffle一样</li><li>Direct Grouping：直接分组，将tuple发送给制定好的任务中</li><li>localOrShuffleGrouping：指如果目标Bolt 中的一个或者多个Task 和当前产生数据的Task在同一个Worker 进程里面，那么就走内部的线程间通信，将Tuple 直接发给在当前Worker进程的目的Task。否则，同shuffleGrouping。</li></ul><h4 id="Storm可靠性剖析"><a href="#Storm可靠性剖析" class="headerlink" title="Storm可靠性剖析"></a>Storm可靠性剖析</h4><h6 id="Storm可能出现的问题"><a href="#Storm可能出现的问题" class="headerlink" title="Storm可能出现的问题"></a>Storm可能出现的问题</h6><ul><li>worker进程死掉</li><li>supervisor进程死掉</li><li>nimbus进程死掉</li><li>节点宕机</li></ul><h6 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h6><ul><li>(acker机制)ack/fail消息确认机制(确保一个tuple被完全处理)<ul><li>在spout中发射tuple的时候需要同时发送messageid，这样才相当于开启了消息确认机制</li><li>如果你的topology里面的tuple比较多的话，那么把acker的数量设置多一点,效率会高一点。</li><li>通过config.setNumAckers(num)来设置一个topology里面的acker的数量，默认值是1。</li><li>注意：acker用了特殊的算法，使得对于追踪每个spout tuple的状态所需要的内存量是恒定的（20 bytes) </li><li>注意：如果一个tuple在指定的timeout(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS默认值为30秒)时间内没有被成功处理，那么这个tuple会被认为处理失败了。</li></ul></li></ul><h4 id="Storm定时器分析"><a href="#Storm定时器分析" class="headerlink" title="Storm定时器分析"></a>Storm定时器分析</h4><ul><li>可以指定每隔一段时间将数据整合一次存入数据库<ul><li>在main中设置conf.put(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 60);// 设置本Bolt定时发射数据</li><li>在bolt中使用下面代码判断是否是触发用的bolt tuple.getSourceComponent().equals(Constants.SYSTEM_COMPONENT_ID)</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566305060434.png" alt="1566305060434"></li></ul></li></ul><h4 id="StormUI的详解"><a href="#StormUI的详解" class="headerlink" title="StormUI的详解"></a>StormUI的详解</h4><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566219892284.png" alt="1566219892284"></p><ul><li>deactive：未激活(暂停)</li><li>emitted:emitted tuple数<ul><li>与emitted的区别：如果一个task，emitted一个tuple到2个task中，则transferred tuple数是emitted tuple数的两倍</li></ul></li><li>completelatency: spout emitting 一个tuple到spout ack这个tuple的平均时间(可以认为是tuple以及该tuple树的整个处理时间)</li><li>processlatency:   bolt收到一个tuple到bolt ack这个tuple的平均时间，如果没有启动acker机制，那么值为0</li><li>execute latency：bolt处理一个tuple的平均时间，不包含acker操作，单位是毫秒(也就是bolt<br>执行 execute 方法的平均时间)</li><li>capacity：这个值越接近1，说明bolt或者spout基本一直在调用execute方法，说明并行度不够，需要扩展这个组件的executor数量。(调整组件并行度的依据)</li><li>总结：execute latency和proces latnecy是处理消息的时效性，而capacity则表示处理能力是否已经饱和，从这3个参数可以知道topology的瓶颈所在。</li></ul><h4 id="Storm的优化"><a href="#Storm的优化" class="headerlink" title="Storm的优化"></a>Storm的优化</h4><h5 id="并行度的优化"><a href="#并行度的优化" class="headerlink" title="并行度的优化"></a>并行度的优化</h5><ul><li>worker为storm提供工作进程，程序的并行度可以设置（包括spout和bolt的并行度，如果有acker的话还包括acker的并行度），并行度即为executor的数目。</li><li>一般情况下worker与executor的比例是一比十到十五，也可以根据实际需要修改。</li></ul><h5 id="worker的优化"><a href="#worker的优化" class="headerlink" title="worker的优化"></a>worker的优化</h5><ul><li>CPU 16核，建议配置20个worker。CPU 24或32核，30个worker</li><li>默认情况下，Storm启动worker进程时，JVM的最大内存是768M，可以通过在Strom的配置文件storm.yaml中设置worker的启动参数worker.childopts: “-Xmx2048m”</li><li>一个topology使用的worker数量，12个是比较合理的，这个时候吞吐量和整体性能最优。如果多增加worker进程的话，会将一些原本线程间的内存通信变为进程间的网络通信。</li></ul><h5 id="acker优化"><a href="#acker优化" class="headerlink" title="acker优化"></a>acker优化</h5><ul><li>如果可靠性对你来说不是那么重要，那么你可以通过不跟踪这些tuple树来获取更好的性能。不去跟踪消息的话会使得系统里面的消息数量减少一半，因为对于每一个tuple都要发送一个ack消息。</li><li>三种去掉可靠性的方法<ul><li>第一是把config.setNumAckers(0)设置为0，在这种情况下，storm会在spout发射一个tuple之后马上调用spout的ack方法。也就是说这个tuple树不会被跟踪。</li><li>第二个方法是在tuple层面去掉可靠性。你可以在发射tuple的时候不指定messageid来达到不跟踪spout中tuple的目的。</li><li>最后一个方法是如果你对于一个tuple树里面的某一部分到底成不成功不是很关心，那么可以在发射这些tuple的时候unanchor它们(anchor是锚定的意思，unanchor表示不把当前这个tuple包含到tuple树中，也就是说不跟踪这个消息了)。这样这些tuple就不在tuple树里面， 也就不会被跟踪了。</li></ul></li></ul><h4 id="雪崩问题的出现原因以及解决方法"><a href="#雪崩问题的出现原因以及解决方法" class="headerlink" title="雪崩问题的出现原因以及解决方法"></a>雪崩问题的出现原因以及解决方法</h4><ul><li>原因：spout发送的速度大于bolt接收的速度，导致数据堆积，不断消耗内存，最终系统崩溃，并引起数据链上多节点down掉。</li><li>解决方案<ul><li>增加bolt的并行度 增加它接收的速度</li><li>可以通过topology.max.spout.pending来控制spout发送消息的速度，通过代码这样设置config.setMaxSpoutPending(num);<ul><li>注意：这个参数表示，当下游的bolt还有topology.max.spout.pending个 tuple 没有消费完时，spout会停止调用nexttuple方法发射数据。等待下游bolt去消费，当tuple的个数少于topology.max.spout.pending个数时，spout 会继续发射数据(这个属性只对可靠消息处理有用，也就是说需要启用acker消息确认机制，在spout中emit数据的时候需要带有messageid)</li></ul></li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> storm storm优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch简介</title>
      <link href="/2019/04/01/Elasticsearch%E7%AE%80%E4%BB%8B/"/>
      <url>/2019/04/01/Elasticsearch%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h1><h3 id="Elasticsearch简介"><a href="#Elasticsearch简介" class="headerlink" title="Elasticsearch简介"></a>Elasticsearch简介</h3><p>​    Elasticsearch是一个实时分布式搜索和分析引擎。它对Lucene进行了封装。能够满足实时搜索的稳定、可靠、快速等。基于REST接口。</p><a id="more"></a><h4 id="ES与MySQL的对比"><a href="#ES与MySQL的对比" class="headerlink" title="ES与MySQL的对比"></a>ES与MySQL的对比</h4><table><thead><tr><th>Elasticsearch</th><th>MySQL</th></tr></thead><tbody><tr><td>index 索引库</td><td>database 数据库</td></tr><tr><td>type 类型</td><td>table 类型</td></tr><tr><td>document 文档</td><td>row 行</td></tr><tr><td>field 字段</td><td>column 列</td></tr></tbody></table><h3 id="Elasticsearch安装部署"><a href="#Elasticsearch安装部署" class="headerlink" title="Elasticsearch安装部署"></a>Elasticsearch安装部署</h3><ol><li><p>安装JDK版本最好在1.8以上（因为这个比较基础就不详细解释了）</p></li><li><p>下载Elasticsearch </p><ul><li>网址：<a href="https://www.elastic.co/downloads/past-releases/elasticsearch-6-4-3" target="_blank" rel="noopener">https://www.elastic.co/downloads/past-releases/elasticsearch-6-4-3</a></li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566399839410.png" alt="1566399839410"></li><li>选择合适的版本下载就可以</li></ul></li><li><p>下载完成以后上传到Linux系统中，解压</p></li><li><p>进入到解压后的文件中尝试进行开启</p><ul><li>bin/elasticsearch （-d 后台运行）</li><li>注意：需要关闭机器的防火墙（service iptables stop）关闭开机自启动（chkconfig iptables off)</li><li>会发现执行报错  就是不可以在root用户下打开，选择一个其他用户就可以了</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566398085045.png" alt="1566398085045"></li></ul></li><li><p>修改配置变量</p><ul><li><p>修改Elasticsearch中config变量 （vi config/elasticsearch.yml)</p></li><li><p>增加两行代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.system_call_filter: false  </span><br><span class="line">network.host: 192.168.32.110   //后面的的IP设置你自己的本地IP就可以</span><br></pre></td></tr></table></figure></li></ul></li></ol><ul><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566398675928.png" alt="1566398675928"></p></li><li><p>修改Linux的配置变量</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/security/limits.conf</span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* hard nproc 4096</span><br><span class="line">vi /etc/sysctl.conf</span><br><span class="line">vm.max_map_count=262144</span><br><span class="line">vi /etc/security/limits.d/90-nproc.conf </span><br><span class="line">把1024修改为4096</span><br><span class="line">*          soft    nproc     4096</span><br></pre></td></tr></table></figure></li><li><p>修改完配置以后重启操作系统在启动就可以啦</p></li><li><p>启动之后出现以下情况</p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566456097622.png" alt="1566456097622"></p></li><li><p>没有报错就表示启动成功了 这时候jps查看进程就可以看到Elasticsearch了</p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566456158512.png" alt="1566456158512"></p></li><li><p>然后可以使用web界面查看 在浏览器输入 <a href="http://yourip:9200" target="_blank" rel="noopener">http://yourip:9200</a>  就可以查看了</p></li></ul><h3 id="简单基本操作"><a href="#简单基本操作" class="headerlink" title="简单基本操作"></a>简单基本操作</h3><h4 id="CURL简介"><a href="#CURL简介" class="headerlink" title="CURL简介"></a>CURL简介</h4><ul><li>curl起始就是一个可以在命令行下访问URL的工具</li><li>curl可以利用URL语法在命令行的方式下操作开源的文件</li><li>这样即可以方便我们其他不同部门对我们数据库的操作，也方便我们管理数据库，方便管理其他用户的权限</li></ul><h4 id="CURL的简单操作"><a href="#CURL的简单操作" class="headerlink" title="CURL的简单操作"></a>CURL的简单操作</h4><ul><li><p>-x 是指定http请求的方法</p><ul><li>他的类型有很多种包括 GET POST  PUT DELETE  查询、修改、增加、删除等很多操作</li></ul></li><li><p>-d 是指需要传递的参数</p></li><li><p>首先我们先<strong>创建</strong>一个简单的索引</p><ul><li>curl  -XPUT ‘<a href="http://localhost:9200/test/&#39;" target="_blank" rel="noopener">http://localhost:9200/test/&#39;</a>   localhost一定要换成你之前设置的IP</li><li>这样它就为我们创建了test索引库</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566457384502.png" alt="1566457384502"></li></ul></li><li><p>然后我们可以创建一个索引并为创建的索引添加一些内容然后进行一些列<strong>查询</strong></p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; //—H指定添加内容的类型为json类型</span><br><span class="line">-XPOST http://localhost:9200/test/emp/1 //1是指定索引的IP 不加系统也会自动生成</span><br><span class="line">-d &apos;&#123;</span><br><span class="line">&quot;name&quot; : &quot;tom&quot;,</span><br><span class="line">&quot;age&quot; : 25</span><br><span class="line">&#125;&apos;   //加入索引中的具体内容</span><br></pre></td></tr></table></figure></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566458468549.png" alt="1566458468549"></p></li><li><p>查询我们刚刚创建的索引</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET http://localhost:9200/test/emp/1?pretty</span><br></pre></td></tr></table></figure></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566458541679.png" alt="1566458541679"></p></li><li><p>检索索引中的一部分内容</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET &apos;http://localhost:9200/test/emp/1?_source=name&amp;pretty&apos;</span><br></pre></td></tr></table></figure></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566458667647.png" alt="1566458667647"></p></li><li><p>查询指定索引库指定类型的所有数据</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET http://hadoop110:9200/test/emp/_search?pretty </span><br><span class="line">查看tem类型下的所有数据</span><br></pre></td></tr></table></figure></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566458873757.png" alt="1566458873757"></p></li></ul></li><li><p>对ES进行<strong>更新</strong>操作，ES中可以使用put或者post两种方式进行更新操作</p><ul><li><p>执行更新操作的时候ES的操作细节</p><ul><li>首先将旧的文件标记为删除状态</li><li>添加新的文件</li><li>旧文件不会立即消失但是我们看不见</li><li>ES在后续你添加更多文件的时候在后台清理掉标记为删除状态的文件</li></ul></li><li><p>执行局部更新的操作</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; -XPOST  http://hadoop110:9200/test/emp/1/_update -d &apos;&#123;&quot;doc&quot;:&#123;&quot;age&quot;:20&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></li><li><p>我们接着进行一次查询看数据是否已经更新</p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566459328843.png" alt="1566459328843"></p></li><li><p>可以看到年龄已将改成20了 所以说明更新操作成功了 我们可以根据这个操作做很多事情</p></li></ul></li><li><p>对ES进行<strong>删除</strong>操作</p><ul><li><p>删除我们之前创建的索引</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XDELETE http://hadoop110:9200/test/emp/1</span><br></pre></td></tr></table></figure></li><li><p>删除以后我们在进行get获取操作就会报错说明我们的删除操作已经执行成功了</p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566459547355.png" alt="1566459547355"></p></li><li><p>如果删除文档存在 则会返回：200 ok的状态码，found属性值为true，_version属性的值+1</p></li><li><p>如果想要删除的文件不存在就会返回：404 NotFound的状态码，found属性值为false，但是_version属性的值依然会+1，这个就是内部管理的一部分，它保证了我们在多个节点间的不同操作的顺序都被正确标记了</p></li></ul></li><li><p>对ES进行批量操作 包括很多步的增删改查等</p><ul><li><p>批量操作就是bulk API帮助我们同时执行多个操作</p></li><li><p>语法的格式：</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">action：index/create/update/delete  //需要执行的操作类型</span><br><span class="line">metadata：_index,_type,_id   //指定需要操作的索引的索引库、类型、ID等</span><br><span class="line">request body：_source(删除操作不需要)  </span><br><span class="line">&#123; action: &#123; metadata &#125;&#125;   //具体要执行的操作</span><br><span class="line">&#123; request body        &#125;</span><br><span class="line">.........</span><br></pre></td></tr></table></figure></li><li><p>create与index的区别</p><ul><li>在创建数据时，如果数据已存在 create会返回创建失败，文件已存在，但是index会执行成功</li></ul></li><li><p>使用方法： 我们创建一个文件保存我们需要执行的操作</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi requests</span><br><span class="line">&#123; &quot;index&quot; : &#123;&quot;_index&quot;:&quot;test&quot;,&quot;_type&quot;:&quot;emp&quot;,&quot;_id&quot;:&quot;21&quot;&#125;&#125;</span><br><span class="line">&#123; &quot;name&quot; : &quot;test21&quot;&#125;</span><br><span class="line">执行：</span><br><span class="line">curl -H &quot;Content-Type: application/json&quot;  -XPUT localhost:9200/test/emp/_bulk --data-binary @requests</span><br></pre></td></tr></table></figure></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566461216320.png" alt="1566461216320"></p></li><li><p>出现下面结果表示执行成功了</p></li><li><p>我们可以放多条指令进去 同时执行多条指令但是要保证中间格式不出错</p></li></ul></li></ul><h3 id="插件的介绍"><a href="#插件的介绍" class="headerlink" title="插件的介绍"></a>插件的介绍</h3><h4 id="Elasticsearch-Head-Plugin站点插件可以以网页形式展现ES"><a href="#Elasticsearch-Head-Plugin站点插件可以以网页形式展现ES" class="headerlink" title="Elasticsearch Head Plugin站点插件可以以网页形式展现ES"></a>Elasticsearch Head Plugin站点插件可以以网页形式展现ES</h4><ul><li><p>注意：这个插件依赖于nodejs,phantomjs所以我们在安装插件之前需要安装nodejs以及grunt</p><ul><li><p>nodejs下载地址<a href="https://nodejs.org/dist/v10.15.3/node-v10.15.3-linux-x64.tar.xz" target="_blank" rel="noopener">https://nodejs.org/dist/v10.15.3/node-v10.15.3-linux-x64.tar.xz</a></p><ul><li>复制此链接就可以直接下或者<a href="https://nodejs.org/dist" target="_blank" rel="noopener">https://nodejs.org/dist</a> 使用这个两节找适合自己的版本</li></ul></li><li><p>因为此文件是.tar.xz，所以需要先使用xz解压在使用tar解压  如果解压xz的命令不存在就需要使用yum进行下载 yum -y install xz</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">解压：</span><br><span class="line">xz -d node-v10.15.3-linux-x64.tar.xz</span><br><span class="line">tar -xvf node-v10.15.3-linux-x64.tar</span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s /data/soft/node-v10.15.3-linux-x64/bin/node  /usr/bin/node</span><br><span class="line">ln -s /data/soft/node-v10.15.3-linux-x64/bin/npm /usr/bin/npm</span><br></pre></td></tr></table></figure></li><li><p>设定nodejs安装软件的dialing服务器</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config set registry https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure></li><li><p>安装grunt</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install -g grunt </span><br><span class="line">npm install -g grunt-cli</span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /data/soft/node-v10.15.3-linux-x64/bin/grunt  /usr/bin/grunt</span><br></pre></td></tr></table></figure></li><li><p>安装phantomjs</p><ul><li>下载地址<a href="http://phantomjs.org/download.html" target="_blank" rel="noopener">http://phantomjs.org/download.html</a></li></ul></li><li><p>解压</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bzip2 -d phantomjs-2.1.1-linux-x86_64.tar.bz2</span><br><span class="line">tar -xvf phantomjs-2.1.1-linux-x86_64.tar</span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /data/soft/phantomjs-2.1.1-linux-x86_64/bin/phantomjs  /usr/bin/phantomjs</span><br></pre></td></tr></table></figure></li><li><p>安装依赖软件</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install wget fontconfig</span><br></pre></td></tr></table></figure></li></ul></li><li><p>安装head插件</p><ul><li><p>下载地址：<a href="https://github.com/mobz/elasticsearch-head/archive/master.zip" target="_blank" rel="noopener">https://github.com/mobz/elasticsearch-head/archive/master.zip</a></p></li><li><p>解压 需要使用unzip命令</p></li><li><p>下载unzip</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y unzip</span><br></pre></td></tr></table></figure></li><li><p>解压</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip elasticsearch-head-master.zip</span><br></pre></td></tr></table></figure></li><li><p>然后cd进入到解压的文件中</p></li><li><p>安装两个插件</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm audit fix</span><br><span class="line">npm audit fix --force</span><br></pre></td></tr></table></figure></li><li><p>执行安装命令安装head</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install</span><br></pre></td></tr></table></figure></li><li><p>启动之前修改Gruntfile.js文件，增加hostname参数</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi Gruntfile.js</span><br><span class="line">options: &#123;</span><br><span class="line">hostname: &apos;hadoop100&apos;,</span><br><span class="line">port: 9101,</span><br><span class="line">base: &apos;.&apos;,</span><br><span class="line">keepalive: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>启动服务</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grunt Server</span><br></pre></td></tr></table></figure></li><li><p>启动服务后还需要修改Elasticsearch中的一些配置</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi config/elasticsearch.yml</span><br><span class="line">http.cors.enabled: true </span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br></pre></td></tr></table></figure></li><li><p>修改完成后重启ES</p></li><li><p>进入网址<a href="http://hadoop100:9101/可以看到以下信息就说明插件安装成功了" target="_blank" rel="noopener">http://hadoop100:9101/可以看到以下信息就说明插件安装成功了</a></p></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566465169785.png" alt="1566465169785"></p></li></ul></li></ul><h3 id="配置参数详解"><a href="#配置参数详解" class="headerlink" title="配置参数详解"></a>配置参数详解</h3><ul><li>配置文件elasticsearch.yml</li><li>ES已经为大多数的参数设置了合理的默认值 我们只需要在有特殊需求的时候进行修改</li><li>书写规范<ul><li>属性顶格写，不能有空格</li><li>缩进一定要是用空格而不能使用制表符</li><li>属性与属性值之间必须有一个空格</li></ul></li><li>常见的配置文件以及其含义<ul><li>cluster.name:   集群名称</li><li>node.name  节点名称</li><li>path.data: /path/to/data     es的数据存储目录</li><li>path.logs: /path/to/logs   es的日志存储目录</li><li>bootstrap.memory_lock: true   锁定物理内存地址，防止elasticsearch内存被交换出去,也就是避免es使用swap交换分区中的内存</li><li>network.host: 192.168.0.1   为es设置ip绑定</li><li>http.port: 9200   为es设置自定义端口，默认是9200</li><li>discovery.zen.ping.unicast.hosts: [“host1”, “host2”]    当启动新节点时，通过这个ip列表进行节点发现，组建集群</li><li>discovery.zen.minimum_master_nodes:   通过配置这个参数来防止集群脑裂现象 (集群总节点数量/2)+1</li><li>gateway.recover_after_nodes: 3   一个集群中的N个节点启动后,才允许进行数据恢复处理，默认是1</li><li>action.destructive_requires_name: true   设置是否可以通过正则或者_all删除或者关闭索引库</li></ul></li></ul><h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ul><li><p>cluster</p><ul><li>代表的是一个集群，集群中有很多节点，其中有一个主节点，这个主节点通过选举产生，主从节点时对于集群内部而言的。es有一个概念叫去中心化，就是说没有中心节点，这个是对于外部来说的，在外部来看，集群就是一个整体，我们两节集群中的任何一个节点与集群通信跟直接与集群通信是等价的。</li><li>主节点的主要职责就是负责管理集群的状态，包括管理分片以及副本的状态，以及节点的删除、新节点的发现等</li><li>注意：主节点不负责对进群的增删改查处理，只负责管理集群状态</li></ul></li><li><p>shards</p><ul><li><p>代表的是索引分片，ES将一个完整的索引分成多个分片，这样的好处是可以把一个大的索引分成多个分片后分布到不同的节点上，构成分布式搜索。提高性能和吞吐量</p></li><li><p>分片的的数量只能在创建索引库的时候指定，索引库创建以后不可以更改</p></li><li><p>索引库默认是5个分片 每个分片最多存储2,147,483,519条数据</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type: application/json&quot; -XPUT &apos;localhost:9200/test/&apos; -d&apos;&#123;&quot;settings&quot;:&#123;&quot;number_of_shards&quot;:3&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>replicas</p><ul><li><p>代表的是分片的副本，es给分片设置副本是为了提高系统的容错性，当某个节点的某个分片损坏或者丢失了可以从副本中恢复。</p></li><li><p>提高es的查询效率，es会自动搜索并请求进行负载均衡</p></li><li><p>默认每个分区只有一个副本，主副本不会存在于一个节点之上，副本数量可以在创建索引库的时候进行设置吧</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &apos;localhost:9200/test/&apos; -d&apos;&#123;&quot;settings&quot;:&#123;&quot;number_of_replicas&quot;:2&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>recovery</p><ul><li>代表数据的恢复或者数据的重新分布</li><li>es在所有节点的加入或者退出后会根据机器的负载对索引分片进行重新分配，挂掉的节点重启时也会进行数据恢复</li></ul></li></ul><h3 id="ElasticsearchJavaAPI操作"><a href="#ElasticsearchJavaAPI操作" class="headerlink" title="ElasticsearchJavaAPI操作"></a>ElasticsearchJavaAPI操作</h3><h4 id="使用Java对ES进行操作"><a href="#使用Java对ES进行操作" class="headerlink" title="使用Java对ES进行操作"></a>使用Java对ES进行操作</h4><ul><li><p>添加maven依赖</p><ul><li><p>可以maven仓库中寻找适合你的版本</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;transport&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;6.4.3&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Java中对ES的简单增删改查操作</p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">package EsTest;</span><br><span class="line"></span><br><span class="line">import org.elasticsearch.action.delete.DeleteResponse;</span><br><span class="line">import org.elasticsearch.action.get.GetResponse;</span><br><span class="line">import org.elasticsearch.action.index.IndexResponse;</span><br><span class="line">import org.elasticsearch.action.update.UpdateResponse;</span><br><span class="line">import org.elasticsearch.client.transport.TransportClient;</span><br><span class="line">import org.elasticsearch.common.settings.Settings;</span><br><span class="line">import org.elasticsearch.common.transport.TransportAddress;</span><br><span class="line">import org.elasticsearch.common.xcontent.XContentType;</span><br><span class="line">import org.elasticsearch.transport.client.PreBuiltTransportClient;</span><br><span class="line"></span><br><span class="line">import java.net.InetAddress;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line">/**</span><br><span class="line"> * Es简单操作测试</span><br><span class="line"> */</span><br><span class="line">public class EsDemo1 &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        //给集群添加自动嗅探的功能</span><br><span class="line">        Settings settings = Settings.builder()</span><br><span class="line">                .put(&quot;cluster.name&quot;, &quot;elasticsearch&quot;) //集群名称</span><br><span class="line">                .put(&quot;client.transport.sniff&quot;, true)  //开启自动嗅探功能，可以自动识别集群内的其他节点信息</span><br><span class="line">                .build();</span><br><span class="line">        //创建连接</span><br><span class="line">        TransportClient client = new PreBuiltTransportClient(Settings.EMPTY)</span><br><span class="line">                //可添加多个节点</span><br><span class="line">                //.addTransportAddress(new TransportAddress(InetAddress.getByName(&quot;hadoop100&quot;), 9300))</span><br><span class="line">                .addTransportAddress(new TransportAddress(InetAddress.getByName(&quot;hadoop110&quot;), 9300));</span><br><span class="line"></span><br><span class="line">        //获取节点的信息</span><br><span class="line">        int size = client.connectedNodes().size();</span><br><span class="line">        //System.out.println(size);</span><br><span class="line">        String index = &quot;test&quot;;</span><br><span class="line">        String type = &quot;emp&quot;;</span><br><span class="line">        //添加数据 使用json字符串</span><br><span class="line">        String json = &quot;&#123;\&quot;name\&quot;:\&quot;jack\&quot;,\&quot;age\&quot;:10&#125;&quot;;</span><br><span class="line">        IndexResponse res = client.prepareIndex(index, type, &quot;1&quot;)</span><br><span class="line">                .setSource(json, XContentType.JSON).get();</span><br><span class="line">        //System.out.println(res.toString());</span><br><span class="line">        //添加数据 使用map结构</span><br><span class="line">        HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;();</span><br><span class="line">        map.put(&quot;name&quot;,&quot;zs&quot;);</span><br><span class="line">        map.put(&quot;age&quot;,21);</span><br><span class="line">        IndexResponse res2 = client.prepareIndex(index, type, &quot;101&quot;)</span><br><span class="line">                .setSource(map)</span><br><span class="line">                .execute()</span><br><span class="line">                .actionGet();</span><br><span class="line">        //更新操作 update</span><br><span class="line">        UpdateResponse updateResponse = client.prepareUpdate(index, type, &quot;101&quot;).setDoc(&quot;&#123;\&quot;age\&quot;:18&#125;&quot;, XContentType.JSON).get();</span><br><span class="line">        //根据ID进行数据查询</span><br><span class="line">        GetResponse get1 = client.prepareGet(index, type, &quot;101&quot;).get();</span><br><span class="line">        System.out.println(get1.getSourceAsString());</span><br><span class="line">        //删除操作 delete</span><br><span class="line">        DeleteResponse deleteResponse = client.prepareDelete(index, type, &quot;101&quot;).get();</span><br><span class="line">        System.out.println(deleteResponse.toString());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Storm 基础</title>
      <link href="/2019/03/21/Storm%E7%9A%84%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/"/>
      <url>/2019/03/21/Storm%E7%9A%84%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="Storm的详细分析"><a href="#Storm的详细分析" class="headerlink" title="Storm的详细分析"></a>Storm的详细分析</h3><h4 id="Storm人的概述"><a href="#Storm人的概述" class="headerlink" title="Storm人的概述"></a>Storm人的概述</h4><ul><li>Storm是Twitter开源的一个实时处理框架</li><li>Storm能够实现高频数据和大规模数据的实时处理</li></ul><a id="more"></a><h5 id="Storm与MapReduce的区别Storm"><a href="#Storm与MapReduce的区别Storm" class="headerlink" title="Storm与MapReduce的区别Storm"></a>Storm与MapReduce的区别Storm</h5><table><thead><tr><th>type</th><th>MapReduce</th><th>Storm</th></tr></thead><tbody><tr><td>数据来源</td><td>hdfs上TB级别历史数据</td><td>实时新增的某一条数据</td></tr><tr><td>处理过程</td><td>map阶段和reduce阶段</td><td>可以有很多阶段包含spout以及bolt</td></tr><tr><td>是否会结束</td><td>执行完结束</td><td>不会结束</td></tr><tr><td>处理速度</td><td>主要以执行TB级别数据速度较慢</td><td>只处理新增数据速度很快</td></tr><tr><td>适用场景</td><td>处理批数据不讲时效性</td><td>处理新增数据将时效性</td></tr></tbody></table><h5 id="Spark-Streaming与Storm的区别"><a href="#Spark-Streaming与Storm的区别" class="headerlink" title="Spark Streaming与Storm的区别"></a>Spark Streaming与Storm的区别</h5><table><thead><tr><th>type</th><th>Spark Streaming</th><th>Storm</th></tr></thead><tbody><tr><td>计算模型</td><td>是近实时处理框架</td><td>全实时处理框架</td></tr><tr><td>延迟度</td><td>最高支持秒级别的延迟</td><td>可以支持毫秒级别的延迟</td></tr><tr><td>吞吐量</td><td>因为是批处理所以吞吐量高</td><td>吞吐量相对来说较低</td></tr><tr><td>动态调整并行度</td><td>不支持</td><td>支持</td></tr><tr><td>事务机制</td><td>支持但是不够完善</td><td>支持且完善</td></tr></tbody></table><h5 id="Storm各个组件解释"><a href="#Storm各个组件解释" class="headerlink" title="Storm各个组件解释"></a>Storm各个组件解释</h5><ul><li>Topology：用于封装一个实时计算应用程序的逻辑</li><li>Stream：消息流，是一个没有边界的tuple序列，这些tuple会以分布式的方式进行创建以及处理</li><li>Spout：消息源，消息的生产者，会从外部源获取消息然后向Topology发出：tuple</li><li>Bolt：消息处理者，消息的处理逻辑被封装到bolt之中，处理输入的数据然后产生新的输出数据流</li></ul><h5 id="Storm的设计思想"><a href="#Storm的设计思想" class="headerlink" title="Storm的设计思想"></a>Storm的设计思想</h5><ul><li>是对stream流的一个抽象即一个不间断的连续tuple</li><li>将流中的元素抽象为一个tuple，一个tuple就是一个值列表value list，list中的每个value都有一个name，并且这个value可以是很多数据类型例如基本类型、字符类型等</li><li>每一个stream流都有一个数据源，称为Spout</li><li>stream从spout中获取不间断数据tuple需要经过处理。处理的过程就是stream流转换的过程称为bolt，bolt可以消费任意数量的流，它是将stream汇总的tuple挨个实时进行处理转换成一个新的stream流经过多个bolt处理就可以得到目标数据</li><li>spout+tuple+bolt这个过程可以称为是Topology拓扑。Topology是Storm中最高的一个抽象概念他可以被提交到集群中执行</li><li>Topology的每个节点都要指定他所发射数据的name，其他节点只需要订阅该name就可以接收数据进行处理</li></ul><h5 id="Topology的整个流程"><a href="#Topology的整个流程" class="headerlink" title="Topology的整个流程"></a>Topology的整个流程</h5><ul><li>如果将stream比作是一列火车的话 spout就是这列火车的始发站每一节车厢就是一个tuple乘客就是tuple中的values 中间的站点就相当于是bolt进行处理上下乘客终点站就相当于stream的目标数据</li></ul><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566209818229.png" alt="1566209818229"></p><h5 id="Storm的整体架构图"><a href="#Storm的整体架构图" class="headerlink" title="Storm的整体架构图"></a>Storm的整体架构图</h5><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566215107025.png" alt="1566215107025"></p><h5 id="Storm的简单实例开发"><a href="#Storm的简单实例开发" class="headerlink" title="Storm的简单实例开发"></a>Storm的简单实例开发</h5><ul><li><p>需求：一个源源不断的数据1，2，3，4……求每出现一个数字就要计算出现的所有数字的和</p></li><li><p>开发过程</p><ul><li><p>在IDE中创建maven工程</p></li><li><p>在pom中添加、Storm依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;storm-core&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0.6&lt;/version&gt;</span><br><span class="line">    &lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line">package Storme;</span><br><span class="line"></span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">import org.apache.storm.Config;</span><br><span class="line">import org.apache.storm.LocalCluster;</span><br><span class="line">import org.apache.storm.generated.StormTopology;</span><br><span class="line">import org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line">import org.apache.storm.task.OutputCollector;</span><br><span class="line">import org.apache.storm.task.TopologyContext;</span><br><span class="line">import org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">import org.apache.storm.topology.TopologyBuilder;</span><br><span class="line">import org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line">import org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line">import org.apache.storm.tuple.Fields;</span><br><span class="line">import org.apache.storm.tuple.Tuple;</span><br><span class="line">import org.apache.storm.tuple.Values;</span><br><span class="line">import org.apache.storm.utils.Utils;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 需求：实现数字累加求和</span><br><span class="line"> * 分析：</span><br><span class="line"> * 需要有一个spout负责源源不断的产生从1开始的递增数字</span><br><span class="line"> * 还需要有一个bolt负责对spout产生的数据进行累加求和，并且把结果打印到控制台</span><br><span class="line"> * 最后把这个spout和bolt组装成一个topology</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class WordCount &#123;</span><br><span class="line">/**</span><br><span class="line"> * 实现自己的数据源spout，</span><br><span class="line"> * 该spout负责源源不断产生从1开始的递增数字</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public static class MySpout extends BaseRichSpout&#123;</span><br><span class="line"></span><br><span class="line">private Map conf;//这里面存储配置信息</span><br><span class="line">private TopologyContext context;//代表上下文</span><br><span class="line">private SpoutOutputCollector collector;//收集器，主要负责向外面发射数据</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 是一个初始化的方法，这个方法在本实例运行的之后，首先被调用，仅且仅被调用一次</span><br><span class="line"> * 所以这个方法内一般放一些初始化的代码</span><br><span class="line"> * 例子：针对操作mysql数据的案例，使用jdbc获取数据库连接的代码需要放到这里面实现</span><br><span class="line"> */</span><br><span class="line">public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) &#123;</span><br><span class="line">this.conf = conf;</span><br><span class="line">this.context = context;</span><br><span class="line">this.collector = collector;</span><br><span class="line">//System.err.println(&quot;spout------&quot;+conf.get(&quot;name&quot;));</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * 这个方法会被循环调用</span><br><span class="line"> */</span><br><span class="line">int i = 1;</span><br><span class="line">public void nextTuple() &#123;</span><br><span class="line">//注意：针对需要发射的数据，需要封装成tuple，可以使用storm中的values对象快速封装tuple</span><br><span class="line">System.out.println(&quot;spout:&quot;+i);</span><br><span class="line">this.collector.emit(new Values(i++));</span><br><span class="line">//让线程每发射一条数据，休息1秒</span><br><span class="line">Utils.sleep(1000);</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * 声明输出字段</span><br><span class="line"> * 定义两个组件之间数据传输的一个规则</span><br><span class="line"> * 注意：只要这个组件(spout/spout)向外发射了数据，那么这个declareOutputFields就需要实现</span><br><span class="line"> */</span><br><span class="line">public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">//注意：Fields中的字段列表和Values中的数据列表是一一对应的</span><br><span class="line">declarer.declare(new Fields(&quot;num&quot;));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * 聚合的Bolt，负责把Spout发射出来的数据进行累加求和，并且打印到控制台</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public static class SumBolt extends BaseRichBolt&#123;</span><br><span class="line">private Map stormConf;</span><br><span class="line">private TopologyContext context; </span><br><span class="line">private OutputCollector collector;</span><br><span class="line">/**</span><br><span class="line"> * prepare是一个初始化方法，只会执行一次，这里面也是可以放一些初始化的代码</span><br><span class="line"> */</span><br><span class="line">public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123;</span><br><span class="line">this.stormConf = stormConf;</span><br><span class="line">this.context = context;</span><br><span class="line">this.collector = collector;</span><br><span class="line">//System.err.println(&quot;bolt------&quot;+stormConf.get(&quot;name&quot;));</span><br><span class="line">&#125;</span><br><span class="line">int sum = 0;</span><br><span class="line">/**</span><br><span class="line"> * 这个方法也是会被循环调用</span><br><span class="line"> * 主要上一个组件向外发射了数据，那么这个方法就会被调用一次</span><br><span class="line"> */</span><br><span class="line">public void execute(Tuple input) &#123;</span><br><span class="line">//input.getInteger(0);//通过角标获取数据</span><br><span class="line">Integer num = input.getIntegerByField(&quot;num&quot;);</span><br><span class="line">sum += num;</span><br><span class="line">System.out.println(&quot;和为：&quot;+sum);</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * 注意：这个方法在这里就不需要实现了，因为这个bolt没有向下一个组件发射数据</span><br><span class="line"> */</span><br><span class="line">public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">TopologyBuilder builder = new TopologyBuilder();</span><br><span class="line">//组装spout</span><br><span class="line">builder.setSpout(&quot;spoutid&quot;, new MySpout());</span><br><span class="line">//组装bolt,并且告诉bolt接收哪个组件的数据</span><br><span class="line">builder.setBolt(&quot;bolt-1&quot;, new SumBolt()).shuffleGrouping(&quot;spoutid&quot;);</span><br><span class="line">StormTopology createTopology = builder.createTopology();</span><br><span class="line">//通过代码创建一个本地集群</span><br><span class="line">LocalCluster localCluster = new LocalCluster();</span><br><span class="line">String topologyName = WordCount.class.getSimpleName();</span><br><span class="line">Config config = new Config();</span><br><span class="line">config.put(&quot;name&quot;, &quot;zs&quot;);</span><br><span class="line">//把代码提交到本地集群中运行</span><br><span class="line">localCluster.submitTopology(topologyName, config, createTopology);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="Storm核心之并行度"><a href="#Storm核心之并行度" class="headerlink" title="Storm核心之并行度"></a>Storm核心之并行度</h4><h5 id="组件解释"><a href="#组件解释" class="headerlink" title="组件解释"></a>组件解释</h5><ul><li>worker：worker是一个进程，每一个worker进程里面都执行的是一个Topology的任务（不会出现一个worker执行多个Topology的任务）。一个worker中会启动一个或多个executor线程来执行Topology的spout或者bolt组件。一个Topology会使用一个或者多个worker来执行任务</li><li>executor：是worker进程内部启动的独立线程，每一个executor会产生一个或者多个task（storm默认是一个task即一个spout或者bolt有一个task，如果有多个task，executor会循环调用所有task中的实例）</li><li>task：是最终运行spout或者bolt中具体代码的执行单元。Topology启动（spout或者bolt）的task的数目是不变的，但是executor线程的数量可以动态进行调整（例如：1个executor线程可以执行该(spout或bolt)的1个或多个task实例）。这意味着，对于1个(spout或bolt)存在这样的条件：#threads&lt;=#tasks（即：线程数小于等于task数目）。默认情况下task的数目等于executor线程数目，即1个executor线程只运行1个task。</li><li>默认情况下，一个supervisor节点最多可以启动4个worker进程，每一个topology默认占用一个worker进程，每个spout或者bolt会占用1个executor，每个executor启动1个task。</li></ul><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566213893905.png" alt="1566213893905"></p><h5 id="提高Storm组件的并行度"><a href="#提高Storm组件的并行度" class="headerlink" title="提高Storm组件的并行度"></a>提高Storm组件的并行度</h5><ul><li>worker（slot）【间接】<ul><li>默认一个节点最多可以启动四个worker进程，可以修改进程数量strom-core.jar/defaults.yaml/supervisor.slots.ports</li><li>默认一个Topology只有一个worker进程，可以通过代码指定一个Topology使用多个worker进程config.setNumWorkers(workersnum)</li><li>注意：如果worker使用完在提交Topology就不会执行，会处于等待状态。worker之是通过Netty通信的</li></ul></li><li>executor【直接】<ul><li>默认情况下一个executor只会运行一个task，可以直接通过代码修改增加task数量，会直接提高Storm组件的并行度</li><li>builder.setSpout(id, spout,parallelism_hint);</li><li>builder.setBolt(id, bolt,parallelism_hint);</li></ul></li><li>task【间接】<ul><li>通过boltDeclarer.setNumTasks(num);来设置实例的个数</li><li>executor的数量会小于等于task的数量(为了rebalance)</li></ul></li></ul><h5 id="弹性计算rebalance"><a href="#弹性计算rebalance" class="headerlink" title="弹性计算rebalance"></a>弹性计算rebalance</h5><ul><li>前提是Topology中的task数量要大于executor线程数</li><li>通过shell调整<ul><li>storm rebalance mytopology -w 10 -n 5 -e blue-spout=3 -e yellow-bolt=10</li><li>注意：acker的树木运行时是不会变化的，所以多指定几个worker进程，acker的数量也不会增加</li><li>-w：表示超时时间，Rebalance会在一个超时时间内注销掉Topology，然后在集群中重新分配worker</li><li>-n：表示的是worker的数量</li><li>-e：调整组件的并行度</li><li>注：-n 以及 -e 都可以单独使用或者组合起来使用</li></ul></li><li>通过UI界面进行调整，不建议使用所以就不具体解释使用方法了</li></ul><h5 id="并行度设置多少合适"><a href="#并行度设置多少合适" class="headerlink" title="并行度设置多少合适"></a>并行度设置多少合适</h5><ul><li>单spout每秒大概可以发送500个tuple</li><li>单bolt每秒大概可以接收2000个tuple</li><li>单acker每秒大概可以接收6000个tuple</li><li>根据需要进行调整</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Maven 简介</title>
      <link href="/2019/01/21/maven%E7%9A%84%E7%AE%80%E4%BB%8B/"/>
      <url>/2019/01/21/maven%E7%9A%84%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="Maven-简介"><a href="#Maven-简介" class="headerlink" title="Maven 简介"></a>Maven 简介</h2><h3 id="为什么需要maven"><a href="#为什么需要maven" class="headerlink" title="为什么需要maven"></a>为什么需要maven</h3><ul><li>同样的代码要在不同的机器上运行他所需要的依赖可以放在maven仓库</li><li>项目组加入新成员可以快速的配置好环境</li><li>在开发其他项目的时候需要用到跟之前项目开发一样的jar包</li></ul><a id="more"></a><h3 id="maven是什么"><a href="#maven是什么" class="headerlink" title="maven是什么"></a>maven是什么</h3><ul><li>maven是基于项目对象模型POM的软件项目管理工具</li><li>是可以跨平台的，主要服务基于Java平台的仙姑构建、依赖管理、项目信息管理等</li></ul><h5 id="构建的过程"><a href="#构建的过程" class="headerlink" title="构建的过程"></a>构建的过程</h5><ul><li>清理</li><li>编译</li><li>测试</li><li>报告</li><li>打包</li><li>部署</li></ul><h3 id="maven的工程结构"><a href="#maven的工程结构" class="headerlink" title="maven的工程结构"></a>maven的工程结构</h3><ul><li>src </li><li><ul><li>mian</li><li><ul><li>java   – 存放Java的文件 源代码等</li><li>resource   –存放资源文件 比如 spring，hibernate等的配置文件</li></ul></li><li>test</li><li><ul><li>Java   – 存放所有的.Java的测试文件，比如JUnit 测试类</li><li>resource   –测试的资源文件夹</li></ul></li></ul></li><li>target       —目标文件的输出位置比如jar包、war包等</li><li>pom.xml      —maven的项目核心配置文件</li></ul><h3 id="maven常用命令"><a href="#maven常用命令" class="headerlink" title="maven常用命令"></a>maven常用命令</h3><ul><li>mvn compile  执行编译 会将生成文件存放在target目录中</li><li>mvn clean  删除target中的目录文件</li><li>mvn test    执行测试命令 执行后会在target目录中生成三个目录文件surefire、surefire-reports（测试报告）、test-classes（测试的字节码文件）</li><li>mvn  package 进行打包操作 操作后的文件存放在target目录之中 例如jar包war包</li><li>mvn install  将制定的jar包安装到本地仓库以便于其他工程的引用</li><li>mvn clean compile 清除测试类再执行compile执行编译操作</li><li>mvn clean test  先清除在进行test测试操作</li><li>mvn clean package 先执行clean清除在执行package打包</li><li>mvn clean install  先进行clean在执行install</li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python提高</title>
      <link href="/2018/08/22/Python%E6%8F%90%E9%AB%98/"/>
      <url>/2018/08/22/Python%E6%8F%90%E9%AB%98/</url>
      
        <content type="html"><![CDATA[<h2 id="Python提高"><a href="#Python提高" class="headerlink" title="Python提高"></a>Python提高</h2><h4 id="Python操作文件"><a href="#Python操作文件" class="headerlink" title="Python操作文件"></a>Python操作文件</h4><a id="more"></a><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">读文件操作</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#此方式如果遇到错误就直接导致程序出错建立的连接无法关闭可以使用try也可以使用with</span></span><br><span class="line">    <span class="comment">#打开文件  r 模式只读 文件不存在就会报错</span></span><br><span class="line">    file = open(<span class="string">"D:\\data\\pythontest.txt"</span>,<span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:</span><br><span class="line">        <span class="comment">#不对文件进行去除操作的话会自动识别文件中的\n然后执行换行</span></span><br><span class="line">        <span class="keyword">print</span> (line)</span><br><span class="line">        <span class="keyword">print</span> (line.strip())</span><br><span class="line">    <span class="comment">#关闭连接</span></span><br><span class="line">    file.close()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># python 封装好的方式 不需要我们手动的关闭流会自动关闭</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"D:\\data\\pythontest.txt"</span>,<span class="string">'r'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fp:</span><br><span class="line">            <span class="keyword">print</span> (line.strip())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment">#fun()</span></span><br><span class="line">    fun2()</span><br></pre></td></tr></table></figure></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566916171752.png" alt="1566916171752"></p></li></ul><h4 id="Python执行shell指令"><a href="#Python执行shell指令" class="headerlink" title="Python执行shell指令"></a>Python执行shell指令</h4><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># coding=utf8</span><br><span class="line"></span><br><span class="line">import  os, commands , sys</span><br><span class="line"></span><br><span class="line">def fun():</span><br><span class="line">    # 执行Windows中的命令行指令</span><br><span class="line">    status = os.system(&quot;java -version&quot;)</span><br><span class="line">    print (&quot;status:&quot;,status)</span><br><span class="line"></span><br><span class="line">def fun2():</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    使用commands也可以执行该命令</span><br><span class="line">    并且可以获得命令的执行状态码以及执行的输出结果</span><br><span class="line">    status：状态码</span><br><span class="line">    output：输出内容</span><br><span class="line">    :return:</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    (status , output) = commands.getstatusoutput(&quot;java -version&quot;)</span><br><span class="line">    print (&quot;statsus: &quot;,status)</span><br><span class="line">    print (&quot;output: &quot;, output)</span><br><span class="line"></span><br><span class="line">def fun3():</span><br><span class="line">    # len 可以返回集合中元素的个数</span><br><span class="line">    print(len(sys.argv))</span><br><span class="line">    # 获取集合中第一个元素</span><br><span class="line">    print(sys.argv[0])</span><br><span class="line">    # os._exit(1) 结束程序，返回指定的状态码</span><br><span class="line">    if len(sys.argv) == 3:</span><br><span class="line">        print(sys.argv[1])</span><br><span class="line">        print(sys.argv[2])</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    fun()</span><br><span class="line">    fun2()</span><br><span class="line">    fun3()</span><br></pre></td></tr></table></figure></li></ul><h4 id="Python访问数据库"><a href="#Python访问数据库" class="headerlink" title="Python访问数据库"></a>Python访问数据库</h4><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># coding=utf8</span><br><span class="line"></span><br><span class="line">import MySQLdb</span><br><span class="line"></span><br><span class="line">def qurey():</span><br><span class="line">    db = MySQLdb.connect(&quot;127.0.0.1&quot;,&quot;root&quot;,&quot;root&quot;,&quot;test&quot;)</span><br><span class="line">    qucursor = db.cursor()</span><br><span class="line"></span><br><span class="line">    sql = &quot;select * from student&quot;</span><br><span class="line">    qucursor.execute(sql)</span><br><span class="line">    lines = qucursor.fetchall()</span><br><span class="line">    for line in lines:</span><br><span class="line">        print (line)</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    qurey()</span><br><span class="line">    </span><br><span class="line">E:\python2.7\python.exe E:/ideapython/PythonDemo/DBTest.py</span><br><span class="line">(1L, &apos;zs&apos;, 18L)</span><br><span class="line">(2L, &apos;ls&apos;, 19L)</span><br><span class="line">(3L, &apos;ww&apos;, 20L)</span><br><span class="line">(4L, &apos;qq&apos;, 18L)</span><br><span class="line">(5L, &apos;aa&apos;, 15L)</span><br><span class="line">(6L, &apos;bb&apos;, 17L)</span><br><span class="line">(7L, &apos;cc&apos;, 25L)</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></li><li><p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566917628183.png" alt="1566917628183"></p></li></ul><h4 id="Python接口开发"><a href="#Python接口开发" class="headerlink" title="Python接口开发"></a>Python接口开发</h4><ul><li><p>打开Tomcat 在E:\apache-tomcat-8.5.32\webapps\ROOT 目录下创建一个简单的测试文本文件</p><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566917415335.png" alt="1566917415335"></li></ul></li><li><p>进去到Tomcat的bin目录下找到startup.bat脚本文件执行</p><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566917503194.png" alt="1566917503194"></li></ul></li><li><p>在本地浏览器中进入 localhost：8080/test.txt 查看是否能获取到值</p><ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566917559911.png" alt="1566917559911"></li></ul></li><li><p>使用代码操作获取</p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> httplib,json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">req</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">"http://localhost:8080/test.txt"</span></span><br><span class="line">    <span class="comment"># 获取连接</span></span><br><span class="line">    conn = httplib.HTTPConnection(<span class="string">"localhost"</span>,<span class="string">"8080"</span>)</span><br><span class="line">    <span class="comment"># 执行get请求</span></span><br><span class="line">    conn.request(<span class="string">"GET"</span>,url)</span><br><span class="line">    <span class="comment"># 获取相应内容</span></span><br><span class="line">    res = conn.getresponse()</span><br><span class="line">    <span class="comment"># 读取相应内容</span></span><br><span class="line">    data = res.read()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 把获取到的json字符串转成json对象</span></span><br><span class="line">    loads = json.loads(data)</span><br><span class="line">    get = loads.get(<span class="string">"name"</span>, <span class="string">"defautname"</span>)</span><br><span class="line">    <span class="keyword">print</span> (get)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    req()</span><br><span class="line">    </span><br><span class="line"> E:\python2<span class="number">.7</span>\python.exe E:/ideapython/PythonDemo/HttpTest.py</span><br><span class="line">zs</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 提高 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python Python提高 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Shell</title>
      <link href="/2018/08/22/Shell/"/>
      <url>/2018/08/22/Shell/</url>
      
        <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566977443612.png" alt="1566977443612"></p><h2 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h2><a id="more"></a><h3 id="shell介绍"><a href="#shell介绍" class="headerlink" title="shell介绍"></a>shell介绍</h3><ul><li>Shell是用户与Linux系统进行操作沟通的桥梁</li><li>shell的种类有很多 ，介绍的这种是bash  也就是Bourne Again Shell</li><li>shell文件的后缀通常是 .sh</li><li>shell脚本中的第一行通常是   #！bin/bash  </li><li>脚本执行方式<ul><li>a.sh  已经配置过环境变量 且脚本有足够的权限</li><li>bash a.sh  直接执行</li><li>bash -x a.sh单步执行</li><li>bash -n   a.sh  语法检查  </li></ul></li></ul><h3 id="shell中的变量"><a href="#shell中的变量" class="headerlink" title="shell中的变量"></a>shell中的变量</h3><ul><li>变量不需要声明，初始化也不需要指定数据类型</li><li>变量的命名规范<ul><li>变量名中只能含有数字、字母、下划线，不能以数字开头</li><li>严格区分大小写</li><li>变量的赋值使用=号，变量等号赋值之间不能有空格</li><li>显示变量  echo ${变量名}</li></ul></li><li>本地变量<ul><li>只对当前的shell进程有效  相当于是Java中的private<ul><li>定义 ：aa=value</li><li>引用   : ${aa}</li><li>取消该变量 ： unset aa</li></ul></li></ul></li><li>环境变量<ul><li>自定义的环境变量只对当前的shell进程以及他的子shell进程有效 对其他shell进程无效</li><li>定义 ： export  aa=vlaue</li><li>如果想要对所有的shell进程都有效的话需要修改系统的环境变量<ul><li>vi /etc/profile</li><li>source /etc/profile</li></ul></li><li>和windows中的环境变量类似</li></ul></li><li>位置变量<ul><li>‘位置变量  $1$2$3$4</li><li>在函数执行的时候穿的变量<ul><li>test.sh  aa  bb  cc dd</li></ul></li><li>$0  表示的是脚本自己</li><li>$1  表示第一个参数 …..</li><li>相当于Java中的args参数</li></ul></li><li>特殊变量<ul><li>$ ?  接收上一个命令返回的状态码  在0-255之间</li><li>$# 参数的个数</li><li>$*  $@  表示所有参数</li><li>$$ 获取当前shell脚本的进程号</li></ul></li><li>引号<ul><li>‘’  单引号不解析变量</li><li>“”  双引号解析变量</li><li>单引号包双引号不解析</li><li>双引号包单引号解析</li></ul></li></ul><h3 id="shell中的循环以及判断"><a href="#shell中的循环以及判断" class="headerlink" title="shell中的循环以及判断"></a>shell中的循环以及判断</h3><ul><li><p>for循环</p><ul><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">第一种格式</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)</span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">.....</span><br><span class="line">done</span><br><span class="line">第二种格式</span><br><span class="line"><span class="keyword">for</span> (i in <span class="number">0</span> <span class="number">1</span> ... <span class="number">10</span>)</span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">......</span><br><span class="line">done</span><br><span class="line">第三种格式</span><br><span class="line"><span class="keyword">for</span> (i in &#123;<span class="number">1</span>..<span class="number">10</span>&#125;)</span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">......</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li></ul></li><li><p>条件测试</p><ul><li>整型<ul><li>gt 大于</li><li>lt  小于</li><li>ge  大于等于</li><li>le  小于等于</li><li>eq   等于</li><li>ne   不等于</li></ul></li><li>字符串<ul><li>=  等于</li><li>！=  不等于</li></ul></li></ul></li><li><p>while循环</p><ul><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> [$aa -gt $bb ];</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">.....</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li></ul></li><li><p>if条件判断</p><ul><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">单分支</span><br><span class="line"><span class="keyword">if</span> [$aa -gt $bb ];</span><br><span class="line">then</span><br><span class="line">......</span><br><span class="line">fi</span><br><span class="line">双分支</span><br><span class="line"><span class="keyword">if</span> [$aa -gt $bb ];</span><br><span class="line">then</span><br><span class="line">......</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">......</span><br><span class="line">fi</span><br><span class="line">多分支</span><br><span class="line"><span class="keyword">if</span> [$aa -gt $bb ];</span><br><span class="line">then</span><br><span class="line">......</span><br><span class="line">elif [$aa -gt $bb ];</span><br><span class="line">then</span><br><span class="line">.......</span><br><span class="line">elif [$aa -gt $bb ];</span><br><span class="line">then</span><br><span class="line">.......</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">......</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="shell中的字符串"><a href="#shell中的字符串" class="headerlink" title="shell中的字符串"></a>shell中的字符串</h3><ul><li><p>获取字符串的长度</p><ul><li><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span>&#123;#aa&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>字符串的截取</p><ul><li><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span>&#123;aa:offset:length&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>字符串的替换  /替换一个  //替换所有</p><ul><li><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span>&#123;aa/old/new&#125;</span><br><span class="line"><span class="meta">$</span>&#123;aa//old/new&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>取尾部指定个数的字符  不加负号是取除了前n个的所有</p><ul><li><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span>&#123;aa: -5&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>大小写转换  ^^转大写  ，，转小写</p><ul><li><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span>&#123;aa^^&#125;</span><br><span class="line"><span class="meta">$</span>&#123;aa,,&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="shell扩展"><a href="#shell扩展" class="headerlink" title="shell扩展"></a>shell扩展</h3><ul><li>算术运算<ul><li>let var=算数表达式   let var=10+10</li><li>let  var=$[算数表达式]  let var2=$[var+10]</li><li>let  var=$((算数表达式))  </li></ul></li><li>date<ul><li>输出当前时间</li><li>格式化输出  date +%Y-%m-%d</li><li>date +%s  表示自1970-01-01 00:00:00以来的秒数</li><li>指定时间输出    date –date=’2009-01-01 11:11:11’</li><li>指定时间输出 date –date=’1 days ago’   date -d’1 days ago’</li><li>获取指定日期的前一天  date -d’20181212 1 days ago’ +%Y-%m-%d</li></ul></li><li>read<ul><li>接收键盘的输入或者其他文件的描述的输入</li><li>read var</li><li>read如果后面不指定变量，那么read命令会将接收到的数据放置在环境变量REPLY中</li><li>read -p “Enter your name:”var   加入提示文本</li><li>read -s  -p “Enter your password:” pass   表示键盘输入时字符不显示</li><li>read-t 5 -p “enter your name:” var   指定键盘输入字符数量</li></ul></li><li>后台模式运行脚本<ul><li>在脚本后面加一个 &amp;字符  test.sh &amp;  后台运行</li><li>当用户注销或者网络断开的时候会受到hangup信号关闭所有子进程</li><li>nohup test.sh  忽略挂断信号</li><li>使用nohup  test.sh &amp;  来启动一个需要一直执行的脚本</li></ul></li><li>标准输入输出错误重定向<ul><li>标准输入、输出、错误输出可以使用0、1、2表示</li><li>标准加重定向 &gt; 重定向到某一个文件中  &gt;&gt; 也是重定向但是文件信息是追加的</li><li>标准正确输出加重定向<ul><li>ls 1&gt;a.txt   将ls命令的正确输出内容保存到a.txt当中  1可以省略</li><li>lk  2&gt;&gt;a.txt  lk是一个错误指令 他会输出报错信息 将它的信息追加到a.txt之中</li><li>如果用 ls 2&gt;a.txt  或者  lk 1&gt;a.txt  都是无效的</li></ul></li><li>将正确与错误的标准输出信息都存在同一个文件中<ul><li>ls 1&gt;&gt;a.txt  2&gt;&amp;1    </li></ul></li><li>把信息重定向到一个无底洞里，相当于是直接把输出信息删除<ul><li>ls &gt; /dev/null</li></ul></li></ul></li><li>crontab定时器<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566991118734.png" alt="1566991118734"></li><li>定时执行指定任务<ul><li>vi  /etc/crontab</li><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566990959096.png" alt="1566990959096"></li></ul></li><li>前面是修改执行时间  中间是用户名  后面是具体需要执行的命令</li><li>tail -f /var/log/cron    查看crontab的执行日志</li><li>service crond status</li></ul></li><li>ps 以及 jps<ul><li>ps -ef查看所有进程</li><li>jps查看Java进程</li></ul></li><li>vi常用技巧<ul><li>/String  查找某个字符 n下一个 </li><li>：Num  查找某一行</li><li>yy  复制当前行</li><li>num yy  从当前行开始复制num行</li><li>p 粘贴</li><li>dd  删除当前行</li><li>999 dd 删除当前跟后面的所有</li><li>G  跳转到最后一行</li><li>gg 跳转第一行</li></ul></li><li>假死问题<ul><li>在命令行中 按 Ctrl+S可能会造成假死状态  命令无法输入</li><li>按 Ctrl+q即可退出</li></ul></li></ul><h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><ul><li><p>awk是一个强大的文本分析工具，相对于 grep的查找，sed的编辑，awk在其对数据分析形成报告时尤为强大。</p><ul><li>简单来说awk就是将文本逐行读入，以空格为默认分隔符将每行切片，切开的部分在进行分析处理</li><li>awk有三个版本  awk nawk gawk</li></ul></li><li><p>awk程序的报告生成能力通常用来从大文本文件中提取数据元素并将它们格式化成可读的报告。最完美的例子是格式化日志文件。awk程序允许从日志文件中只过滤出你想要看的数据</p></li><li><p>命令格式</p><ul><li><p>awk [options] program file</p><ul><li><p>options  选项</p></li><li><p>program  程序</p></li><li><p>file 操作的文件</p><table><thead><tr><th>选项</th><th>描述</th></tr></thead><tbody><tr><td>-F fs</td><td>指定行中的程序分割字段的分隔符</td></tr><tr><td>-f file</td><td>指定程序脚本文件</td></tr></tbody></table></li></ul></li></ul></li><li><p>awk的基本特性之一即是处理文本文件的能力，他会自动为每个数据元素分配一个变量</p><ul><li>$0  代表整个文本行</li><li>$1代表文本行中的第一个数据字段</li><li>$2代表文本行中的第二个数据字段</li><li>$n代表文本行中的第n个数据字段</li><li>注意：文本行中的文本是自动划分的  awk默认的分割符是任意的空白字符串例如：空格或者制表符</li><li>如果想要读取其他分隔字段，可以使用-F选项指定<ul><li>实例：awk -F： ‘{print $2}’ test.txt   指定分隔符为：</li></ul></li></ul></li><li><p>如果awk只能进行一行命令的分析就没有那么大的用处了，所以awk给我们提供了有个方法，将多条编程语言放在一个文件中 然后使用-f指定这个文件执行 这个文件称为是awk脚本</p><ul><li>实例：awk -F: -f script /etc/passwd</li></ul></li><li><p>awk中的各种begin，end</p><ul><li>begin：有时候需要在处理数据之前运行脚本，比如给数据添加一个开头</li><li>end：允许你在指定一个程序脚本，在awk处理完数据的时候执行它</li></ul></li><li><p>awk的内置变量吧</p><ul><li>FS：Field Seperator, 输入时的字段分隔符<ul><li>awk ‘BEGIN{FS=”:”}{print $2,$5}’ test.txt</li></ul></li><li>RS：Record Seperator，输入行分隔符</li><li>OFS：Output Field Seperator, 输出时的字段分隔符;</li><li>ORS:Outpput Row Seperator, 输出时的行分隔符；</li><li>NF：Numbers of Field，字段数量<ul><li>awk ‘BEGIN{FS=”:”}{print $1,NF}’ test.txt   整行的字段数量</li></ul></li><li>NR：Numbers of Record, 行号；所有文件的一并计数；</li><li>FNR：行号；各文件分别计数；</li></ul></li><li><p>awk中的匹配操作符</p><ul><li>正则表达式需要放在/expr/中，/expr/必须出现在它要控制的程序脚本的左花括号前。<ul><li>awk ‘/110.52.250.126/  {print $1}’ access_2013_05_30.log </li></ul></li><li>匹配操作符允许将正则表达式限定在数据行中的特定数据字段。<ul><li>awk ‘ ($1 ~ /110.52.250.126/)  {print $1}’ access_2013_05_30.log </li><li>awk ‘ ($1 !~ /110.52.250.126/)  {print $1}’ access_2013_05_30.log</li></ul></li></ul></li><li><p>扩展</p><ul><li>shell中的管道<ul><li>command1 | command 2   他可以将command1输出的数据当做是2的输入数据进行处理</li></ul></li><li>wc -l 统计行数</li><li>uniq  -c在输出行的前面加上输出文件出现的次数</li><li>uniq   -u 仅仅显示不重复的行</li><li>sort   -nr<ul><li>n  依照数值的大小排序</li><li>r   反序</li><li>k   按照某一列进行排序</li></ul></li><li>head -3  取出前三个</li></ul></li><li><p>统计日志练习统计pv、uv 统计访问次数最多的三个IP</p><ul><li><p>日志文件链接：</p></li><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//清洗不符合规定的数据</span></span><br><span class="line">awk <span class="string">'($7 !~ /\.css|\.gif|\.js|\.png|\.jpg/ )&#123;print $0&#125;'</span> access_2013_05_30.log &gt;&gt;clean.log</span><br><span class="line"><span class="comment">//我们粗略的认为清洗过后的条数就可以是pv</span></span><br><span class="line">wc -l clean.log   使用shell的方式统计</span><br><span class="line">awk <span class="string">'BEGIN&#123;PV=0&#125; &#123;PV++&#125; END&#123;print PV&#125;'</span> clean.log   使用awk的方式统计</span><br><span class="line">awk <span class="string">'END&#123;print NR&#125;'</span> clean.log     使用awk的方式统计</span><br><span class="line"><span class="comment">//统计uv</span></span><br><span class="line">awk <span class="string">'&#123;print $1&#125;'</span> clean.log |sort -n |uniq -u | wc -l</span><br><span class="line"><span class="comment">//统计排名前三的ID</span></span><br><span class="line">awk <span class="string">'&#123;print $1&#125;'</span> clean.log | sort -n | uniq -c | sort -nr -k <span class="number">1</span> | head -<span class="number">3</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><ul><li>sed -i ‘s/aaa/bbb/g’ test.conf<ul><li>i 表示对文件直接进行修改</li><li>s  表示操作是替换字符</li><li>aaa 表示的是源字符</li><li>bbb 表示的是替换的字符</li><li>g   表示对文件中所有该字符进行替换操作</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux</title>
      <link href="/2018/08/21/Linux/"/>
      <url>/2018/08/21/Linux/</url>
      
        <content type="html"><![CDATA[<ul><li><img src="https://raw.githubusercontent.com/zhaoxintaoaa/images/master/1566975389273.png" alt="1566975389273"></li></ul><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><a id="more"></a><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><ul><li>是一个免费开源的操作系统</li><li>组成部分<ul><li>内核</li><li>shell</li><li>文件系统</li><li>应用程序</li></ul></li></ul><h4 id="重要指令"><a href="#重要指令" class="headerlink" title="重要指令"></a>重要指令</h4><ul><li><p>常用指令</p><ul><li><p>pwd 列出当前全路径</p></li><li><p>ls ll ll -a 列出目录下所有文件 加a会列出隐藏文件</p></li><li><p>touch  创建一个空文件</p></li><li><p>mkdir -p 创建目录 加p是递归创建目录 且若目录存在不报错</p></li><li><p>mv old new  重命名</p></li><li><p>连接</p><ul><li>硬链接  ln  文件  连接  直接复制</li><li>软连接  ln -s  只是多加了一个快捷方式</li></ul></li><li><p>cd 切换目录</p></li><li><p>rm -rf  删除文件 r 目录 f 强制删除</p></li><li><p>cp -r old new 复制文件 r文件夹</p></li><li><p>scp -rq 跨主机  q 不显示复制细节</p></li><li><p>chmod u+x  xxx.sh 添加权限  777 最高权限  -r递归</p></li><li><p>cat -b 查看  -b带行号</p></li><li><p>more 分屏显示</p></li><li><p>tar zxcf  zxvf  压缩、解压</p><ul><li><p>z   是否同时具有 gzip 的属性？亦即是否需要用 gzip 压缩？</p><p>c   创建一个压缩文件的参数指令(create 的意思)；</p><p>x   解开一个压缩文件的参数指令！</p><p>v   压缩的过程中显示文件！</p><p>f   使用档案名字，这个参数是最后一个参数，后面只能接档案名</p></li></ul></li></ul></li><li><p>重要指令</p><ul><li><p>du  同价文件文件夹所占磁盘情况</p><ul><li>a  文件全部以及子目录下得文档等所有文件</li><li>h   文件全部以及子目录的所有文件</li><li>ch 添加total</li><li>sh  直接统计大小</li></ul></li><li><p>vi  </p><ul><li>dd  删除一行</li><li>yy p  复制粘贴</li><li>999 dd 删除所有</li></ul></li><li><p>i  进入编辑模式</p><ul><li>：wq  保存退出</li><li>：q! 不保存强制退出</li><li>/abc  查看目标所在位置 n下一个</li></ul></li><li><p>| grep  管道加过滤</p></li><li><p>wc  统计</p><ul><li>l  行数</li><li>w 单词数</li><li>c  字符数</li><li>啥也不加统计所有</li></ul></li><li><p>echo 输出 双引号不解析  单引号解析  -e解析转义字符</p></li><li><p>export  -p  列出当前所有环境变量  也可直接跟变量来临时设置环境变量</p></li><li><p>history  显示历史使用的命令  加数字显示条数 c 清除  w 保存至文件</p></li><li><p>ps  -ef  查看正在运行的进程</p></li><li><p>netstat -anp  监听的端口号</p></li><li><p>kill  加进程ID  -9 强制杀死</p></li><li><p>防火墙  临时  service iptables stop/start/status  关闭打开状态</p></li><li><p>永久 chkconfig iptables off/on 关闭打开   –list  iptables  状态</p></li><li><p>top  显示各种资源占用率</p><ul><li><p>P  按进程的CPU使用率排序</p><p>M  按进程的内存使用率排序</p></li></ul></li><li><p>df  -h  查看硬盘占用情况</p></li><li><p>who显示在线用户</p></li><li><p>uname -a  查看操作系统的版本</p></li><li><p>free 查看内存状态</p></li><li><p>clear 清屏</p></li><li><p>shutdown -h now  关机</p></li><li><p>reboot  -h now 重启</p></li><li><p>exit quit  退出当前状态</p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
